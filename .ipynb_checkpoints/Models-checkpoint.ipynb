{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spread</th>\n",
       "      <th>buys</th>\n",
       "      <th>sells</th>\n",
       "      <th>bids_distance_0</th>\n",
       "      <th>bids_distance_1</th>\n",
       "      <th>bids_distance_2</th>\n",
       "      <th>bids_distance_3</th>\n",
       "      <th>bids_distance_4</th>\n",
       "      <th>bids_distance_5</th>\n",
       "      <th>bids_distance_6</th>\n",
       "      <th>...</th>\n",
       "      <th>PreAvg</th>\n",
       "      <th>JV</th>\n",
       "      <th>PJ</th>\n",
       "      <th>SV</th>\n",
       "      <th>ASV</th>\n",
       "      <th>RQ</th>\n",
       "      <th>RQTri</th>\n",
       "      <th>RQQuad</th>\n",
       "      <th>NV</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>8.243388e+05</td>\n",
       "      <td>854362.503980</td>\n",
       "      <td>-8.890902e-08</td>\n",
       "      <td>-2.222725e-06</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000169</td>\n",
       "      <td>-0.000191</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>-0.000443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.677271e-08</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>4.678313e-07</td>\n",
       "      <td>2.214260e-08</td>\n",
       "      <td>5398.546583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>4.043096e+05</td>\n",
       "      <td>174798.367015</td>\n",
       "      <td>-8.893365e-08</td>\n",
       "      <td>-2.997064e-05</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000206</td>\n",
       "      <td>-0.000216</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.075970e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>4.678492e-07</td>\n",
       "      <td>2.212838e-08</td>\n",
       "      <td>5318.152883</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>7.976876e+05</td>\n",
       "      <td>245080.699183</td>\n",
       "      <td>-8.888435e-08</td>\n",
       "      <td>-4.328668e-05</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>-0.000160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.481803e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>4.508335e-07</td>\n",
       "      <td>2.206376e-08</td>\n",
       "      <td>5320.068883</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.30</td>\n",
       "      <td>8.938642e+05</td>\n",
       "      <td>504274.642389</td>\n",
       "      <td>-5.587871e-05</td>\n",
       "      <td>-9.135727e-05</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>-0.000265</td>\n",
       "      <td>-0.000267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.234156e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>4.508341e-07</td>\n",
       "      <td>2.210425e-08</td>\n",
       "      <td>4994.242080</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.28</td>\n",
       "      <td>1.904225e+06</td>\n",
       "      <td>765199.134667</td>\n",
       "      <td>-2.020032e-05</td>\n",
       "      <td>-1.072035e-04</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000158</td>\n",
       "      <td>-0.000189</td>\n",
       "      <td>-0.000189</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.186346e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>4.508435e-07</td>\n",
       "      <td>2.215744e-08</td>\n",
       "      <td>5112.644874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.95</td>\n",
       "      <td>9.091536e+05</td>\n",
       "      <td>221723.204484</td>\n",
       "      <td>-4.390375e-05</td>\n",
       "      <td>-4.408114e-05</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.830787e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>4.525566e-07</td>\n",
       "      <td>2.236083e-08</td>\n",
       "      <td>5143.441037</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.01</td>\n",
       "      <td>5.044661e+05</td>\n",
       "      <td>641358.955997</td>\n",
       "      <td>-8.876220e-08</td>\n",
       "      <td>-2.662866e-07</td>\n",
       "      <td>-0.000121</td>\n",
       "      <td>-0.000136</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>-0.000287</td>\n",
       "      <td>-0.000287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.506072e-08</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>4.522919e-07</td>\n",
       "      <td>2.264769e-08</td>\n",
       "      <td>5124.277662</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.49</td>\n",
       "      <td>8.263540e+05</td>\n",
       "      <td>106804.367844</td>\n",
       "      <td>-1.322219e-05</td>\n",
       "      <td>-1.339967e-05</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.325500e-08</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>4.524218e-07</td>\n",
       "      <td>2.263227e-08</td>\n",
       "      <td>5086.806623</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.17</td>\n",
       "      <td>6.349644e+05</td>\n",
       "      <td>359164.530708</td>\n",
       "      <td>-5.473651e-05</td>\n",
       "      <td>-5.491394e-05</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000132</td>\n",
       "      <td>-0.000137</td>\n",
       "      <td>-0.000167</td>\n",
       "      <td>-0.000167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.108180e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>4.449863e-07</td>\n",
       "      <td>2.210103e-08</td>\n",
       "      <td>5077.862008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3.457107e+05</td>\n",
       "      <td>747753.051473</td>\n",
       "      <td>-8.880740e-08</td>\n",
       "      <td>-8.969548e-06</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.407287e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>4.430576e-07</td>\n",
       "      <td>2.130308e-08</td>\n",
       "      <td>4858.697653</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   spread          buys          sells  bids_distance_0  bids_distance_1  \\\n",
       "0    0.01  8.243388e+05  854362.503980    -8.890902e-08    -2.222725e-06   \n",
       "1    0.01  4.043096e+05  174798.367015    -8.893365e-08    -2.997064e-05   \n",
       "2    0.01  7.976876e+05  245080.699183    -8.888435e-08    -4.328668e-05   \n",
       "3    6.30  8.938642e+05  504274.642389    -5.587871e-05    -9.135727e-05   \n",
       "4    2.28  1.904225e+06  765199.134667    -2.020032e-05    -1.072035e-04   \n",
       "5    4.95  9.091536e+05  221723.204484    -4.390375e-05    -4.408114e-05   \n",
       "6    0.01  5.044661e+05  641358.955997    -8.876220e-08    -2.662866e-07   \n",
       "7    1.49  8.263540e+05  106804.367844    -1.322219e-05    -1.339967e-05   \n",
       "8    6.17  6.349644e+05  359164.530708    -5.473651e-05    -5.491394e-05   \n",
       "9    0.01  3.457107e+05  747753.051473    -8.880740e-08    -8.969548e-06   \n",
       "\n",
       "   bids_distance_2  bids_distance_3  bids_distance_4  bids_distance_5  \\\n",
       "0        -0.000042        -0.000169        -0.000191        -0.000252   \n",
       "1        -0.000050        -0.000206        -0.000216        -0.000250   \n",
       "2        -0.000044        -0.000065        -0.000066        -0.000085   \n",
       "3        -0.000128        -0.000252        -0.000259        -0.000265   \n",
       "4        -0.000107        -0.000158        -0.000189        -0.000189   \n",
       "5        -0.000045        -0.000045        -0.000046        -0.000046   \n",
       "6        -0.000121        -0.000136        -0.000166        -0.000287   \n",
       "7        -0.000014        -0.000028        -0.000043        -0.000051   \n",
       "8        -0.000107        -0.000132        -0.000137        -0.000167   \n",
       "9        -0.000011        -0.000029        -0.000038        -0.000044   \n",
       "\n",
       "   bids_distance_6  ...    PreAvg   JV   PJ            SV       ASV        RQ  \\\n",
       "0        -0.000443  ...  0.001336  0.0  0.0  7.677271e-08  0.000003  0.000016   \n",
       "1        -0.000256  ...  0.001315  0.0  0.0  3.075970e-07  0.000003  0.000016   \n",
       "2        -0.000160  ...  0.001217  0.0  0.0  4.481803e-06  0.000003  0.000016   \n",
       "3        -0.000267  ...  0.001235  0.0  0.0  1.234156e-06  0.000003  0.000016   \n",
       "4        -0.000235  ...  0.001181  0.0  0.0  1.186346e-06  0.000003  0.000016   \n",
       "5        -0.000103  ...  0.001127  0.0  0.0  5.830787e-07  0.000003  0.000016   \n",
       "6        -0.000287  ...  0.001128  0.0  0.0  6.506072e-08  0.000003  0.000016   \n",
       "7        -0.000065  ...  0.001122  0.0  0.0  8.325500e-08  0.000003  0.000016   \n",
       "8        -0.000167  ...  0.001124  0.0  0.0  1.108180e-06  0.000003  0.000015   \n",
       "9        -0.000066  ...  0.001131  0.0  0.0  8.407287e-07  0.000003  0.000015   \n",
       "\n",
       "          RQTri        RQQuad           NV  y  \n",
       "0  4.678313e-07  2.214260e-08  5398.546583  0  \n",
       "1  4.678492e-07  2.212838e-08  5318.152883  2  \n",
       "2  4.508335e-07  2.206376e-08  5320.068883  2  \n",
       "3  4.508341e-07  2.210425e-08  4994.242080  2  \n",
       "4  4.508435e-07  2.215744e-08  5112.644874  1  \n",
       "5  4.525566e-07  2.236083e-08  5143.441037  1  \n",
       "6  4.522919e-07  2.264769e-08  5124.277662  0  \n",
       "7  4.524218e-07  2.263227e-08  5086.806623  0  \n",
       "8  4.449863e-07  2.210103e-08  5077.862008  1  \n",
       "9  4.430576e-07  2.130308e-08  4858.697653  1  \n",
       "\n",
       "[10 rows x 168 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_c = pd.read_csv(\"data/final/1min/BTC.csv\")\n",
    "data_c.drop(\"system_time\", axis = 1)\n",
    "data_c['Next_mid'] = data_c.midpoint.shift(-1)\n",
    "data_c['Price_move'] = (data_c.Next_mid - data_c.midpoint) / data_c.midpoint\n",
    "data_c.dropna(axis=0, inplace=True) #drop the last row which is now Nan\n",
    "\n",
    "data_c['y'] = 0\n",
    "data_c.loc[(data_c['Price_move'] < -0.0005), 'y'] = 1\n",
    "data_c.loc[(data_c['Price_move'] > 0.0005), 'y'] = 2\n",
    "data_c.drop(['Next_mid', 'midpoint', 'Price_move', \"system_time\", \"Return\"], axis=1, inplace=True)\n",
    "\n",
    "data_c.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data_c.pop(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data_c = data_c.iloc[:,1:153]\n",
    "bids = data_c.iloc[:,0:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "asks = data_c.iloc[:,78:93]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['spread', 'buys', 'sells', 'bids_distance_0', 'bids_distance_1',\n",
       "       'bids_distance_2', 'bids_distance_3', 'bids_distance_4',\n",
       "       'bids_distance_5', 'bids_distance_6', 'bids_distance_7',\n",
       "       'bids_distance_8', 'bids_distance_9', 'bids_distance_10',\n",
       "       'bids_distance_11', 'bids_distance_12', 'bids_distance_13',\n",
       "       'bids_distance_14'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bids.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['asks_distance_0', 'asks_distance_1', 'asks_distance_2',\n",
       "       'asks_distance_3', 'asks_distance_4', 'asks_distance_5',\n",
       "       'asks_distance_6', 'asks_distance_7', 'asks_distance_8',\n",
       "       'asks_distance_9', 'asks_distance_10', 'asks_distance_11',\n",
       "       'asks_distance_12', 'asks_distance_13', 'asks_distance_14'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['buys', 'sells', 'bids_distance_0', 'bids_distance_1',\n",
       "       'bids_distance_2', 'bids_distance_3', 'bids_distance_4',\n",
       "       'bids_distance_5', 'bids_distance_6', 'bids_distance_7',\n",
       "       ...\n",
       "       'asks_market_notional_5', 'asks_market_notional_6',\n",
       "       'asks_market_notional_7', 'asks_market_notional_8',\n",
       "       'asks_market_notional_9', 'asks_market_notional_10',\n",
       "       'asks_market_notional_11', 'asks_market_notional_12',\n",
       "       'asks_market_notional_13', 'asks_market_notional_14'],\n",
       "      dtype='object', length=152)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_c.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bid_ask  = pd.concat([bids.reset_index(drop=True), asks], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['spread', 'buys', 'sells', 'bids_distance_0', 'bids_distance_1',\n",
       "       'bids_distance_2', 'bids_distance_3', 'bids_distance_4',\n",
       "       'bids_distance_5', 'bids_distance_6', 'bids_distance_7',\n",
       "       'bids_distance_8', 'bids_distance_9', 'bids_distance_10',\n",
       "       'bids_distance_11', 'bids_distance_12', 'bids_distance_13',\n",
       "       'bids_distance_14', 'asks_distance_0', 'asks_distance_1',\n",
       "       'asks_distance_2', 'asks_distance_3', 'asks_distance_4',\n",
       "       'asks_distance_5', 'asks_distance_6', 'asks_distance_7',\n",
       "       'asks_distance_8', 'asks_distance_9', 'asks_distance_10',\n",
       "       'asks_distance_11', 'asks_distance_12', 'asks_distance_13',\n",
       "       'asks_distance_14'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bid_ask.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(10, 20)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(10,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, x = data_bid_ask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_std = data_bid_ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(60, r):\n",
    "    for j in range(x):\n",
    "        m = data_bid_ask.iloc[0:i,j].mean()\n",
    "        s = data_bid_ask.iloc[0:i,j].std()\n",
    "        data_std.iloc[i,j] = (data_bid_ask.iloc[i,j] - m) / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_std = data_std.iloc[60:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spread</th>\n",
       "      <th>buys</th>\n",
       "      <th>sells</th>\n",
       "      <th>bids_distance_0</th>\n",
       "      <th>bids_distance_1</th>\n",
       "      <th>bids_distance_2</th>\n",
       "      <th>bids_distance_3</th>\n",
       "      <th>bids_distance_4</th>\n",
       "      <th>bids_distance_5</th>\n",
       "      <th>bids_distance_6</th>\n",
       "      <th>...</th>\n",
       "      <th>asks_distance_5</th>\n",
       "      <th>asks_distance_6</th>\n",
       "      <th>asks_distance_7</th>\n",
       "      <th>asks_distance_8</th>\n",
       "      <th>asks_distance_9</th>\n",
       "      <th>asks_distance_10</th>\n",
       "      <th>asks_distance_11</th>\n",
       "      <th>asks_distance_12</th>\n",
       "      <th>asks_distance_13</th>\n",
       "      <th>asks_distance_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-0.378623</td>\n",
       "      <td>1.265239</td>\n",
       "      <td>-0.639718</td>\n",
       "      <td>0.378498</td>\n",
       "      <td>0.284553</td>\n",
       "      <td>0.479859</td>\n",
       "      <td>0.853283</td>\n",
       "      <td>0.297646</td>\n",
       "      <td>0.430123</td>\n",
       "      <td>0.482917</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.293745</td>\n",
       "      <td>-1.262288</td>\n",
       "      <td>-1.147634</td>\n",
       "      <td>-1.007928</td>\n",
       "      <td>-1.075343</td>\n",
       "      <td>-1.201923</td>\n",
       "      <td>-1.056785</td>\n",
       "      <td>-1.069151</td>\n",
       "      <td>-1.168725</td>\n",
       "      <td>-1.260513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-0.370205</td>\n",
       "      <td>-0.362857</td>\n",
       "      <td>0.598785</td>\n",
       "      <td>-0.127929</td>\n",
       "      <td>-0.127002</td>\n",
       "      <td>-0.126816</td>\n",
       "      <td>-0.128089</td>\n",
       "      <td>-0.127940</td>\n",
       "      <td>-0.127703</td>\n",
       "      <td>-0.127588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128315</td>\n",
       "      <td>0.128235</td>\n",
       "      <td>0.128295</td>\n",
       "      <td>0.128362</td>\n",
       "      <td>0.128216</td>\n",
       "      <td>0.128129</td>\n",
       "      <td>0.128680</td>\n",
       "      <td>0.128659</td>\n",
       "      <td>0.128619</td>\n",
       "      <td>0.128533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>-0.362130</td>\n",
       "      <td>-0.058555</td>\n",
       "      <td>2.033078</td>\n",
       "      <td>-0.079156</td>\n",
       "      <td>-0.062904</td>\n",
       "      <td>-0.089055</td>\n",
       "      <td>-0.106050</td>\n",
       "      <td>-0.066386</td>\n",
       "      <td>-0.085226</td>\n",
       "      <td>-0.090056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113353</td>\n",
       "      <td>0.112972</td>\n",
       "      <td>0.111486</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.110241</td>\n",
       "      <td>0.112098</td>\n",
       "      <td>0.109850</td>\n",
       "      <td>0.110064</td>\n",
       "      <td>0.111493</td>\n",
       "      <td>0.112585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-0.354376</td>\n",
       "      <td>-0.220463</td>\n",
       "      <td>-0.018849</td>\n",
       "      <td>-0.052578</td>\n",
       "      <td>-0.036347</td>\n",
       "      <td>-0.065361</td>\n",
       "      <td>-0.088872</td>\n",
       "      <td>-0.037342</td>\n",
       "      <td>-0.057810</td>\n",
       "      <td>-0.063612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100617</td>\n",
       "      <td>0.099934</td>\n",
       "      <td>0.097351</td>\n",
       "      <td>0.093540</td>\n",
       "      <td>0.095530</td>\n",
       "      <td>0.098601</td>\n",
       "      <td>0.094884</td>\n",
       "      <td>0.095289</td>\n",
       "      <td>0.097809</td>\n",
       "      <td>0.099719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-0.346923</td>\n",
       "      <td>-0.519071</td>\n",
       "      <td>0.987868</td>\n",
       "      <td>-0.035816</td>\n",
       "      <td>-0.021726</td>\n",
       "      <td>-0.047976</td>\n",
       "      <td>-0.074794</td>\n",
       "      <td>-0.022649</td>\n",
       "      <td>-0.041802</td>\n",
       "      <td>-0.047838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090730</td>\n",
       "      <td>0.089918</td>\n",
       "      <td>0.086809</td>\n",
       "      <td>0.082545</td>\n",
       "      <td>0.084820</td>\n",
       "      <td>0.088745</td>\n",
       "      <td>0.084301</td>\n",
       "      <td>0.084879</td>\n",
       "      <td>0.087865</td>\n",
       "      <td>0.090272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17043</th>\n",
       "      <td>-0.234365</td>\n",
       "      <td>2.013500</td>\n",
       "      <td>3.160840</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>-0.003717</td>\n",
       "      <td>-0.002680</td>\n",
       "      <td>-0.003441</td>\n",
       "      <td>-0.006187</td>\n",
       "      <td>-0.005172</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>0.002712</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.008936</td>\n",
       "      <td>0.007772</td>\n",
       "      <td>0.006409</td>\n",
       "      <td>0.005598</td>\n",
       "      <td>0.008106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17044</th>\n",
       "      <td>-0.234351</td>\n",
       "      <td>2.753293</td>\n",
       "      <td>1.479314</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.003374</td>\n",
       "      <td>-0.007370</td>\n",
       "      <td>-0.005969</td>\n",
       "      <td>-0.004670</td>\n",
       "      <td>-0.004418</td>\n",
       "      <td>-0.004463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.003696</td>\n",
       "      <td>0.003485</td>\n",
       "      <td>0.003308</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.005256</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.004927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17045</th>\n",
       "      <td>2.723833</td>\n",
       "      <td>1.640824</td>\n",
       "      <td>4.568396</td>\n",
       "      <td>-0.007730</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>0.002977</td>\n",
       "      <td>0.004225</td>\n",
       "      <td>0.002249</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003706</td>\n",
       "      <td>-0.004275</td>\n",
       "      <td>-0.005647</td>\n",
       "      <td>-0.004069</td>\n",
       "      <td>-0.005163</td>\n",
       "      <td>-0.006274</td>\n",
       "      <td>-0.003121</td>\n",
       "      <td>-0.003749</td>\n",
       "      <td>-0.003827</td>\n",
       "      <td>-0.003048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17046</th>\n",
       "      <td>0.925317</td>\n",
       "      <td>2.152914</td>\n",
       "      <td>0.876544</td>\n",
       "      <td>-0.002230</td>\n",
       "      <td>0.003268</td>\n",
       "      <td>-0.000268</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.003138</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>-0.000966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003912</td>\n",
       "      <td>-0.001427</td>\n",
       "      <td>-0.001509</td>\n",
       "      <td>-0.002672</td>\n",
       "      <td>-0.003656</td>\n",
       "      <td>-0.004128</td>\n",
       "      <td>-0.005087</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.006721</td>\n",
       "      <td>-0.007046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17047</th>\n",
       "      <td>-0.234412</td>\n",
       "      <td>7.860741</td>\n",
       "      <td>3.539566</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>-0.001803</td>\n",
       "      <td>-0.004718</td>\n",
       "      <td>-0.007786</td>\n",
       "      <td>-0.007286</td>\n",
       "      <td>-0.009211</td>\n",
       "      <td>-0.010657</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006874</td>\n",
       "      <td>-0.006623</td>\n",
       "      <td>-0.005471</td>\n",
       "      <td>-0.006447</td>\n",
       "      <td>-0.006409</td>\n",
       "      <td>-0.007191</td>\n",
       "      <td>-0.007313</td>\n",
       "      <td>-0.008457</td>\n",
       "      <td>-0.009388</td>\n",
       "      <td>-0.010080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16988 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         spread      buys     sells  bids_distance_0  bids_distance_1  \\\n",
       "60    -0.378623  1.265239 -0.639718         0.378498         0.284553   \n",
       "61    -0.370205 -0.362857  0.598785        -0.127929        -0.127002   \n",
       "62    -0.362130 -0.058555  2.033078        -0.079156        -0.062904   \n",
       "63    -0.354376 -0.220463 -0.018849        -0.052578        -0.036347   \n",
       "64    -0.346923 -0.519071  0.987868        -0.035816        -0.021726   \n",
       "...         ...       ...       ...              ...              ...   \n",
       "17043 -0.234365  2.013500  3.160840         0.001217         0.001127   \n",
       "17044 -0.234351  2.753293  1.479314         0.001205         0.003374   \n",
       "17045  2.723833  1.640824  4.568396        -0.007730        -0.000357   \n",
       "17046  0.925317  2.152914  0.876544        -0.002230         0.003268   \n",
       "17047 -0.234412  7.860741  3.539566         0.001285        -0.001803   \n",
       "\n",
       "       bids_distance_2  bids_distance_3  bids_distance_4  bids_distance_5  \\\n",
       "60            0.479859         0.853283         0.297646         0.430123   \n",
       "61           -0.126816        -0.128089        -0.127940        -0.127703   \n",
       "62           -0.089055        -0.106050        -0.066386        -0.085226   \n",
       "63           -0.065361        -0.088872        -0.037342        -0.057810   \n",
       "64           -0.047976        -0.074794        -0.022649        -0.041802   \n",
       "...                ...              ...              ...              ...   \n",
       "17043        -0.003717        -0.002680        -0.003441        -0.006187   \n",
       "17044        -0.007370        -0.005969        -0.004670        -0.004418   \n",
       "17045         0.001972         0.001745         0.002977         0.004225   \n",
       "17046        -0.000268         0.001824         0.003138         0.003599   \n",
       "17047        -0.004718        -0.007786        -0.007286        -0.009211   \n",
       "\n",
       "       bids_distance_6  ...  asks_distance_5  asks_distance_6  \\\n",
       "60            0.482917  ...        -1.293745        -1.262288   \n",
       "61           -0.127588  ...         0.128315         0.128235   \n",
       "62           -0.090056  ...         0.113353         0.112972   \n",
       "63           -0.063612  ...         0.100617         0.099934   \n",
       "64           -0.047838  ...         0.090730         0.089918   \n",
       "...                ...  ...              ...              ...   \n",
       "17043        -0.005172  ...        -0.000041         0.002712   \n",
       "17044        -0.004463  ...         0.003150         0.003696   \n",
       "17045         0.002249  ...        -0.003706        -0.004275   \n",
       "17046        -0.000966  ...        -0.003912        -0.001427   \n",
       "17047        -0.010657  ...        -0.006874        -0.006623   \n",
       "\n",
       "       asks_distance_7  asks_distance_8  asks_distance_9  asks_distance_10  \\\n",
       "60           -1.147634        -1.007928        -1.075343         -1.201923   \n",
       "61            0.128295         0.128362         0.128216          0.128129   \n",
       "62            0.111486         0.109192         0.110241          0.112098   \n",
       "63            0.097351         0.093540         0.095530          0.098601   \n",
       "64            0.086809         0.082545         0.084820          0.088745   \n",
       "...                ...              ...              ...               ...   \n",
       "17043         0.001239         0.002519         0.003728          0.008936   \n",
       "17044         0.003485         0.003308         0.002968          0.004200   \n",
       "17045        -0.005647        -0.004069        -0.005163         -0.006274   \n",
       "17046        -0.001509        -0.002672        -0.003656         -0.004128   \n",
       "17047        -0.005471        -0.006447        -0.006409         -0.007191   \n",
       "\n",
       "       asks_distance_11  asks_distance_12  asks_distance_13  asks_distance_14  \n",
       "60            -1.056785         -1.069151         -1.168725         -1.260513  \n",
       "61             0.128680          0.128659          0.128619          0.128533  \n",
       "62             0.109850          0.110064          0.111493          0.112585  \n",
       "63             0.094884          0.095289          0.097809          0.099719  \n",
       "64             0.084301          0.084879          0.087865          0.090272  \n",
       "...                 ...               ...               ...               ...  \n",
       "17043          0.007772          0.006409          0.005598          0.008106  \n",
       "17044          0.005256          0.003937          0.005307          0.004927  \n",
       "17045         -0.003121         -0.003749         -0.003827         -0.003048  \n",
       "17046         -0.005087         -0.005671         -0.006721         -0.007046  \n",
       "17047         -0.007313         -0.008457         -0.009388         -0.010080  \n",
       "\n",
       "[16988 rows x 33 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spread</th>\n",
       "      <th>buys</th>\n",
       "      <th>sells</th>\n",
       "      <th>bids_distance_0</th>\n",
       "      <th>bids_distance_1</th>\n",
       "      <th>bids_distance_2</th>\n",
       "      <th>bids_distance_3</th>\n",
       "      <th>bids_distance_4</th>\n",
       "      <th>bids_distance_5</th>\n",
       "      <th>bids_distance_6</th>\n",
       "      <th>...</th>\n",
       "      <th>RK</th>\n",
       "      <th>PreAvg</th>\n",
       "      <th>JV</th>\n",
       "      <th>PJ</th>\n",
       "      <th>SV</th>\n",
       "      <th>ASV</th>\n",
       "      <th>RQ</th>\n",
       "      <th>RQTri</th>\n",
       "      <th>RQQuad</th>\n",
       "      <th>NV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>8.243388e+05</td>\n",
       "      <td>854362.503980</td>\n",
       "      <td>-8.890902e-08</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000169</td>\n",
       "      <td>-0.000191</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>-0.000443</td>\n",
       "      <td>...</td>\n",
       "      <td>204347.899890</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.677271e-08</td>\n",
       "      <td>3.394687e-06</td>\n",
       "      <td>1.610209e-05</td>\n",
       "      <td>4.678313e-07</td>\n",
       "      <td>2.214260e-08</td>\n",
       "      <td>5398.546583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>4.043096e+05</td>\n",
       "      <td>174798.367015</td>\n",
       "      <td>-8.893365e-08</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000206</td>\n",
       "      <td>-0.000216</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>...</td>\n",
       "      <td>209182.242587</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.075970e-07</td>\n",
       "      <td>3.395898e-06</td>\n",
       "      <td>1.610211e-05</td>\n",
       "      <td>4.678492e-07</td>\n",
       "      <td>2.212838e-08</td>\n",
       "      <td>5318.152883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>7.976876e+05</td>\n",
       "      <td>245080.699183</td>\n",
       "      <td>-8.888435e-08</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>-0.000160</td>\n",
       "      <td>...</td>\n",
       "      <td>176708.439982</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.481803e-06</td>\n",
       "      <td>3.188057e-06</td>\n",
       "      <td>1.551465e-05</td>\n",
       "      <td>4.508335e-07</td>\n",
       "      <td>2.206376e-08</td>\n",
       "      <td>5320.068883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.30</td>\n",
       "      <td>8.938642e+05</td>\n",
       "      <td>504274.642389</td>\n",
       "      <td>-5.587871e-05</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>-0.000265</td>\n",
       "      <td>-0.000267</td>\n",
       "      <td>...</td>\n",
       "      <td>179160.891054</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.234156e-06</td>\n",
       "      <td>3.262733e-06</td>\n",
       "      <td>1.558696e-05</td>\n",
       "      <td>4.508341e-07</td>\n",
       "      <td>2.210425e-08</td>\n",
       "      <td>4994.242080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.28</td>\n",
       "      <td>1.904225e+06</td>\n",
       "      <td>765199.134667</td>\n",
       "      <td>-2.020032e-05</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000158</td>\n",
       "      <td>-0.000189</td>\n",
       "      <td>-0.000189</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>...</td>\n",
       "      <td>205604.442134</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.186346e-06</td>\n",
       "      <td>3.282080e-06</td>\n",
       "      <td>1.559243e-05</td>\n",
       "      <td>4.508435e-07</td>\n",
       "      <td>2.215744e-08</td>\n",
       "      <td>5112.644874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17043</th>\n",
       "      <td>0.01</td>\n",
       "      <td>8.791629e+04</td>\n",
       "      <td>107184.256354</td>\n",
       "      <td>-8.781911e-08</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>-0.000137</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>-0.000218</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>...</td>\n",
       "      <td>167445.192434</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.194484e-07</td>\n",
       "      <td>8.250538e-07</td>\n",
       "      <td>3.887417e-07</td>\n",
       "      <td>1.129160e-08</td>\n",
       "      <td>2.435251e-09</td>\n",
       "      <td>1332.005519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17044</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1.193864e+05</td>\n",
       "      <td>50993.869682</td>\n",
       "      <td>-8.788243e-08</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>-0.000177</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000221</td>\n",
       "      <td>...</td>\n",
       "      <td>158604.283378</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.015092e-08</td>\n",
       "      <td>7.759007e-07</td>\n",
       "      <td>3.464000e-07</td>\n",
       "      <td>1.003299e-08</td>\n",
       "      <td>2.446679e-09</td>\n",
       "      <td>1337.236962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17045</th>\n",
       "      <td>6.54</td>\n",
       "      <td>7.205687e+04</td>\n",
       "      <td>154209.154442</td>\n",
       "      <td>-5.749138e-05</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>-0.000101</td>\n",
       "      <td>-0.000110</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>...</td>\n",
       "      <td>168716.932274</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.344709e-06</td>\n",
       "      <td>7.722981e-07</td>\n",
       "      <td>3.461071e-07</td>\n",
       "      <td>1.002871e-08</td>\n",
       "      <td>2.448272e-09</td>\n",
       "      <td>1257.165735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17046</th>\n",
       "      <td>2.57</td>\n",
       "      <td>9.383907e+04</td>\n",
       "      <td>30850.792037</td>\n",
       "      <td>-2.256600e-05</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000088</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>-0.000183</td>\n",
       "      <td>...</td>\n",
       "      <td>174537.001541</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.553035e-06</td>\n",
       "      <td>7.902343e-07</td>\n",
       "      <td>3.523572e-07</td>\n",
       "      <td>1.004940e-08</td>\n",
       "      <td>2.452821e-09</td>\n",
       "      <td>1251.308490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17047</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3.366408e+05</td>\n",
       "      <td>119825.333954</td>\n",
       "      <td>-8.791493e-08</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>-0.000189</td>\n",
       "      <td>-0.000203</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>-0.000288</td>\n",
       "      <td>...</td>\n",
       "      <td>168434.916201</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.600798e-07</td>\n",
       "      <td>8.073408e-07</td>\n",
       "      <td>3.600416e-07</td>\n",
       "      <td>1.002105e-08</td>\n",
       "      <td>2.440030e-09</td>\n",
       "      <td>1280.336150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17048 rows × 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       spread          buys          sells  bids_distance_0  bids_distance_1  \\\n",
       "0        0.01  8.243388e+05  854362.503980    -8.890902e-08        -0.000002   \n",
       "1        0.01  4.043096e+05  174798.367015    -8.893365e-08        -0.000030   \n",
       "2        0.01  7.976876e+05  245080.699183    -8.888435e-08        -0.000043   \n",
       "3        6.30  8.938642e+05  504274.642389    -5.587871e-05        -0.000091   \n",
       "4        2.28  1.904225e+06  765199.134667    -2.020032e-05        -0.000107   \n",
       "...       ...           ...            ...              ...              ...   \n",
       "17043    0.01  8.791629e+04  107184.256354    -8.781911e-08        -0.000046   \n",
       "17044    0.01  1.193864e+05   50993.869682    -8.788243e-08        -0.000028   \n",
       "17045    6.54  7.205687e+04  154209.154442    -5.749138e-05        -0.000058   \n",
       "17046    2.57  9.383907e+04   30850.792037    -2.256600e-05        -0.000028   \n",
       "17047    0.01  3.366408e+05  119825.333954    -8.791493e-08        -0.000069   \n",
       "\n",
       "       bids_distance_2  bids_distance_3  bids_distance_4  bids_distance_5  \\\n",
       "0            -0.000042        -0.000169        -0.000191        -0.000252   \n",
       "1            -0.000050        -0.000206        -0.000216        -0.000250   \n",
       "2            -0.000044        -0.000065        -0.000066        -0.000085   \n",
       "3            -0.000128        -0.000252        -0.000259        -0.000265   \n",
       "4            -0.000107        -0.000158        -0.000189        -0.000189   \n",
       "...                ...              ...              ...              ...   \n",
       "17043        -0.000118        -0.000137        -0.000165        -0.000218   \n",
       "17044        -0.000151        -0.000171        -0.000177        -0.000200   \n",
       "17045        -0.000068        -0.000094        -0.000101        -0.000110   \n",
       "17046        -0.000088        -0.000093        -0.000100        -0.000116   \n",
       "17047        -0.000128        -0.000189        -0.000203        -0.000249   \n",
       "\n",
       "       bids_distance_6  ...             RK    PreAvg   JV   PJ            SV  \\\n",
       "0            -0.000443  ...  204347.899890  0.001336  0.0  0.0  7.677271e-08   \n",
       "1            -0.000256  ...  209182.242587  0.001315  0.0  0.0  3.075970e-07   \n",
       "2            -0.000160  ...  176708.439982  0.001217  0.0  0.0  4.481803e-06   \n",
       "3            -0.000267  ...  179160.891054  0.001235  0.0  0.0  1.234156e-06   \n",
       "4            -0.000235  ...  205604.442134  0.001181  0.0  0.0  1.186346e-06   \n",
       "...                ...  ...            ...       ...  ...  ...           ...   \n",
       "17043        -0.000229  ...  167445.192434  0.000300  0.0  0.0  5.194484e-07   \n",
       "17044        -0.000221  ...  158604.283378  0.000289  0.0  0.0  8.015092e-08   \n",
       "17045        -0.000149  ...  168716.932274  0.000288  0.0  0.0  1.344709e-06   \n",
       "17046        -0.000183  ...  174537.001541  0.000288  0.0  0.0  1.553035e-06   \n",
       "17047        -0.000288  ...  168434.916201  0.000278  0.0  0.0  8.600798e-07   \n",
       "\n",
       "                ASV            RQ         RQTri        RQQuad           NV  \n",
       "0      3.394687e-06  1.610209e-05  4.678313e-07  2.214260e-08  5398.546583  \n",
       "1      3.395898e-06  1.610211e-05  4.678492e-07  2.212838e-08  5318.152883  \n",
       "2      3.188057e-06  1.551465e-05  4.508335e-07  2.206376e-08  5320.068883  \n",
       "3      3.262733e-06  1.558696e-05  4.508341e-07  2.210425e-08  4994.242080  \n",
       "4      3.282080e-06  1.559243e-05  4.508435e-07  2.215744e-08  5112.644874  \n",
       "...             ...           ...           ...           ...          ...  \n",
       "17043  8.250538e-07  3.887417e-07  1.129160e-08  2.435251e-09  1332.005519  \n",
       "17044  7.759007e-07  3.464000e-07  1.003299e-08  2.446679e-09  1337.236962  \n",
       "17045  7.722981e-07  3.461071e-07  1.002871e-08  2.448272e-09  1257.165735  \n",
       "17046  7.902343e-07  3.523572e-07  1.004940e-08  2.452821e-09  1251.308490  \n",
       "17047  8.073408e-07  3.600416e-07  1.002105e-08  2.440030e-09  1280.336150  \n",
       "\n",
       "[17048 rows x 167 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bid_ask.iloc[1,1] = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123.0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bid_ask.iloc[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = data_c.iloc[0:60,j].mean()\n",
    "s = data_c.iloc[0:60,j].std()\n",
    "test = (data_c.iloc[60,1] - m) / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66340.18219522487"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1057184.957174722"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_c.iloc[60,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-0ea42dec2ecf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "### Reshape Data ###\n",
    "\n",
    "dat = np.zeros((5, x, r-5))\n",
    "\n",
    "for i in range(i-5):\n",
    "    dat[:,:,i] = data_c.iloc[i:i+5,:].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reshape Data ###\n",
    "\n",
    "dat = np.zeros((r-5, 5, x))\n",
    "\n",
    "for i in range(r-5):\n",
    "    dat[i,:,:] = data_c.iloc[i:i+5,:].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat[:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_c.iloc[1:5,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.Flatten(input_shape=[5, x]),\n",
    "keras.layers.Dense(128, activation=\"relu\"),\n",
    "keras.layers.Dense(64, activation=\"relu\"),\n",
    "keras.layers.Dense(32, activation=\"relu\"),\n",
    "keras.layers.Dense(16, activation=\"relu\"),\n",
    "keras.layers.Dense(8, activation=\"relu\"),\n",
    "keras.layers.Dense(4, activation=\"relu\"),\n",
    "keras.layers.Dense(3, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "533/533 [==============================] - 1s 815us/step - loss: 898.0717 - accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "533/533 [==============================] - 0s 727us/step - loss: 1.0163 - accuracy: 0.5344\n",
      "Epoch 3/30\n",
      "533/533 [==============================] - 0s 711us/step - loss: 1.0094 - accuracy: 0.5391\n",
      "Epoch 4/30\n",
      "533/533 [==============================] - 0s 708us/step - loss: 1.0105 - accuracy: 0.5380\n",
      "Epoch 5/30\n",
      "533/533 [==============================] - 0s 708us/step - loss: 1.0105 - accuracy: 0.5380\n",
      "Epoch 6/30\n",
      "533/533 [==============================] - 0s 720us/step - loss: 1.0096 - accuracy: 0.5392\n",
      "Epoch 7/30\n",
      "533/533 [==============================] - 0s 719us/step - loss: 1.0155 - accuracy: 0.5320\n",
      "Epoch 8/30\n",
      "533/533 [==============================] - 0s 737us/step - loss: 1.0054 - accuracy: 0.5440\n",
      "Epoch 9/30\n",
      "533/533 [==============================] - 0s 738us/step - loss: 1.0154 - accuracy: 0.5322\n",
      "Epoch 10/30\n",
      "533/533 [==============================] - 0s 743us/step - loss: 1.0170 - accuracy: 0.5303\n",
      "Epoch 11/30\n",
      "533/533 [==============================] - 0s 729us/step - loss: 1.0111 - accuracy: 0.5374\n",
      "Epoch 12/30\n",
      "  1/533 [..............................] - ETA: 0s - loss: 1.1246 - accuracy: 0.4062"
     ]
    }
   ],
   "source": [
    "history = model.fit(dat, Y[5:], epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.535551  , 0.23004037, 0.23440857],\n",
       "       [0.535551  , 0.23004037, 0.23440857],\n",
       "       [0.535551  , 0.23004037, 0.23440857],\n",
       "       ...,\n",
       "       [0.535551  , 0.23004037, 0.23440857],\n",
       "       [0.535551  , 0.23004037, 0.23440857],\n",
       "       [0.535551  , 0.23004037, 0.23440857]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17048"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.LSTM(128, return_sequences=True, input_shape=(r, x)),\n",
    "#keras.layers.LSTM(20, return_sequences=True),\n",
    "#keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17048, 167)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/martin/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/martin/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/martin/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/martin/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/martin/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/martin/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/martin/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /home/martin/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/martin/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:219 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 167)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-244bb75a7df1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/martin/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/martin/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/martin/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/martin/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/martin/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/martin/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/martin/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /home/martin/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/martin/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:219 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 167)\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(data_c, Y, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(r, x), return_sequences = True))\n",
    "model.add(Dense(3, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_std.values.reshape((1, r-60, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17048, 167)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_c.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.values.reshape((1,r-60,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_std = Y[60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60       1\n",
       "61       0\n",
       "62       2\n",
       "63       1\n",
       "64       2\n",
       "        ..\n",
       "17043    1\n",
       "17044    0\n",
       "17045    2\n",
       "17046    1\n",
       "17047    1\n",
       "Name: y, Length: 16988, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_std = Y_std.values.reshape((1,r-60,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 16988, 1)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9923 - accuracy: 0.5431\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9920 - accuracy: 0.5437\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9917 - accuracy: 0.5436\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9914 - accuracy: 0.5437\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9912 - accuracy: 0.5434\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9909 - accuracy: 0.5433\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9907 - accuracy: 0.5436\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9906 - accuracy: 0.5436\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9904 - accuracy: 0.5438\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9902 - accuracy: 0.5436\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9901 - accuracy: 0.5434\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9899 - accuracy: 0.5436\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9898 - accuracy: 0.5435\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9896 - accuracy: 0.5436\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9895 - accuracy: 0.5437\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9893 - accuracy: 0.5436\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9892 - accuracy: 0.5436\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9890 - accuracy: 0.5438\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9889 - accuracy: 0.5441\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9888 - accuracy: 0.5444\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9886 - accuracy: 0.5444\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9885 - accuracy: 0.5445\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9884 - accuracy: 0.5444\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9883 - accuracy: 0.5450\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9881 - accuracy: 0.5455\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9880 - accuracy: 0.5462\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9879 - accuracy: 0.5463\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9878 - accuracy: 0.5465\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9877 - accuracy: 0.5470\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9876 - accuracy: 0.5476\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9874 - accuracy: 0.5477\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9873 - accuracy: 0.5479\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9872 - accuracy: 0.5483\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9871 - accuracy: 0.5483\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9870 - accuracy: 0.5484\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9869 - accuracy: 0.5480\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9868 - accuracy: 0.5475\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9867 - accuracy: 0.5475\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9866 - accuracy: 0.5472\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9865 - accuracy: 0.5473\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9864 - accuracy: 0.5473\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9863 - accuracy: 0.5472\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9862 - accuracy: 0.5473\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9861 - accuracy: 0.5473\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9861 - accuracy: 0.5476\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9860 - accuracy: 0.5476\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9859 - accuracy: 0.5479\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9858 - accuracy: 0.5480\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9857 - accuracy: 0.5480\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9857 - accuracy: 0.5482\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(data, Y_std, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.24305972, 0.4709687 , 0.28597152],\n",
       "        [0.30859447, 0.38775894, 0.3036466 ],\n",
       "        [0.3421137 , 0.34179083, 0.31609547],\n",
       "        ...,\n",
       "        [0.5464941 , 0.21826649, 0.23523936],\n",
       "        [0.5684086 , 0.20636272, 0.22522867],\n",
       "        [0.5224499 , 0.22102912, 0.25652093]]], dtype=float32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 17048, 167)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a37286ee8571>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m167\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "x_train = data_c.reshape(-1, 1, 167)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
      "1   0.306285   0.000000   0.071992   0.034707   0.257399   0.998657   \n",
      "2   0.305031   0.000000   0.035241   0.007097   0.256278   0.979943   \n",
      "3   0.307541   0.000000   0.069660   0.009952   0.258521   0.970961   \n",
      "4   0.317133   0.039227   0.078075   0.020483   0.073151   0.938540   \n",
      "5   0.322175   0.014157   0.166478   0.031084   0.169730   0.927852   \n",
      "\n",
      "   var7(t-1)  var8(t-1)  var9(t-1)  var17(t-1)  ...  var160(t)  var161(t)  \\\n",
      "1   0.973670   0.894334   0.883123    0.813217  ...   0.010205   0.031305   \n",
      "2   0.968982   0.871123   0.867539    0.817103  ...   0.008576   0.028924   \n",
      "3   0.972897   0.959746   0.959995    0.936443  ...   0.008699   0.029364   \n",
      "4   0.920214   0.842514   0.841188    0.856505  ...   0.010025   0.028057   \n",
      "5   0.932960   0.901422   0.884025    0.839237  ...   0.012086   0.026770   \n",
      "\n",
      "   var162(t)  var163(t)  var164(t)  var165(t)  var166(t)  var167(t)  \\\n",
      "1        0.0        0.0   0.000229   0.034731   0.001532   0.001532   \n",
      "2        0.0        0.0   0.003334   0.032560   0.001476   0.001476   \n",
      "3        0.0        0.0   0.000918   0.033340   0.001483   0.001476   \n",
      "4        0.0        0.0   0.000882   0.033542   0.001484   0.001476   \n",
      "5        0.0        0.0   0.000434   0.033413   0.001483   0.001482   \n",
      "\n",
      "   var168(t)  var169(t)  \n",
      "1   0.000500   0.035838  \n",
      "2   0.000498   0.035851  \n",
      "3   0.000499   0.033605  \n",
      "4   0.000500   0.034421  \n",
      "5   0.000505   0.034633  \n",
      "\n",
      "[5 rows x 331 columns]\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    " \n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    " \n",
    "# load dataset\n",
    "dataset = read_csv(\"data/final/1min/BTC.csv\", header=0, index_col=0)\n",
    "#dataset = d\n",
    "values = dataset.values\n",
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "values[:,4] = encoder.fit_transform(values[:,4])\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis=1, inplace=True)\n",
    "print(reframed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 1, 330) (8760,) (8288, 1, 330) (8288,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 365 * 24\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "122/122 - 1s - loss: 0.0103 - val_loss: 0.0202\n",
      "Epoch 2/50\n",
      "122/122 - 0s - loss: 0.0068 - val_loss: 0.0148\n",
      "Epoch 3/50\n",
      "122/122 - 0s - loss: 0.0028 - val_loss: 0.0071\n",
      "Epoch 4/50\n",
      "122/122 - 0s - loss: 0.0031 - val_loss: 0.0073\n",
      "Epoch 5/50\n",
      "122/122 - 0s - loss: 0.0035 - val_loss: 0.0096\n",
      "Epoch 6/50\n",
      "122/122 - 0s - loss: 0.0041 - val_loss: 0.0059\n",
      "Epoch 7/50\n",
      "122/122 - 0s - loss: 0.0043 - val_loss: 0.0056\n",
      "Epoch 8/50\n",
      "122/122 - 0s - loss: 0.0018 - val_loss: 0.0061\n",
      "Epoch 9/50\n",
      "122/122 - 0s - loss: 0.0017 - val_loss: 0.0064\n",
      "Epoch 10/50\n",
      "122/122 - 0s - loss: 0.0022 - val_loss: 0.0065\n",
      "Epoch 11/50\n",
      "122/122 - 0s - loss: 0.0024 - val_loss: 0.0050\n",
      "Epoch 12/50\n",
      "122/122 - 0s - loss: 0.0027 - val_loss: 0.0058\n",
      "Epoch 13/50\n",
      "122/122 - 0s - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 14/50\n",
      "122/122 - 0s - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 15/50\n",
      "122/122 - 0s - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 16/50\n",
      "122/122 - 0s - loss: 0.0014 - val_loss: 0.0059\n",
      "Epoch 17/50\n",
      "122/122 - 0s - loss: 0.0021 - val_loss: 0.0056\n",
      "Epoch 18/50\n",
      "122/122 - 0s - loss: 0.0013 - val_loss: 0.0060\n",
      "Epoch 19/50\n",
      "122/122 - 0s - loss: 0.0017 - val_loss: 0.0066\n",
      "Epoch 20/50\n",
      "122/122 - 0s - loss: 0.0022 - val_loss: 0.0065\n",
      "Epoch 21/50\n",
      "122/122 - 0s - loss: 0.0021 - val_loss: 0.0062\n",
      "Epoch 22/50\n",
      "122/122 - 0s - loss: 0.0014 - val_loss: 0.0068\n",
      "Epoch 23/50\n",
      "122/122 - 0s - loss: 0.0023 - val_loss: 0.0081\n",
      "Epoch 24/50\n",
      "122/122 - 0s - loss: 0.0022 - val_loss: 0.0081\n",
      "Epoch 25/50\n",
      "122/122 - 0s - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 26/50\n",
      "122/122 - 0s - loss: 0.0015 - val_loss: 0.0059\n",
      "Epoch 27/50\n",
      "122/122 - 0s - loss: 0.0014 - val_loss: 0.0080\n",
      "Epoch 28/50\n",
      "122/122 - 0s - loss: 0.0020 - val_loss: 0.0056\n",
      "Epoch 29/50\n",
      "122/122 - 0s - loss: 0.0013 - val_loss: 0.0064\n",
      "Epoch 30/50\n",
      "122/122 - 0s - loss: 0.0011 - val_loss: 0.0061\n",
      "Epoch 31/50\n",
      "122/122 - 0s - loss: 0.0013 - val_loss: 0.0059\n",
      "Epoch 32/50\n",
      "122/122 - 0s - loss: 0.0013 - val_loss: 0.0075\n",
      "Epoch 33/50\n",
      "122/122 - 0s - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 34/50\n",
      "122/122 - 0s - loss: 0.0014 - val_loss: 0.0057\n",
      "Epoch 35/50\n",
      "122/122 - 0s - loss: 0.0012 - val_loss: 0.0057\n",
      "Epoch 36/50\n",
      "122/122 - 0s - loss: 0.0012 - val_loss: 0.0059\n",
      "Epoch 37/50\n",
      "122/122 - 0s - loss: 0.0012 - val_loss: 0.0071\n",
      "Epoch 38/50\n",
      "122/122 - 0s - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 39/50\n",
      "122/122 - 0s - loss: 0.0012 - val_loss: 0.0063\n",
      "Epoch 40/50\n",
      "122/122 - 0s - loss: 0.0011 - val_loss: 0.0063\n",
      "Epoch 41/50\n",
      "122/122 - 0s - loss: 0.0013 - val_loss: 0.0066\n",
      "Epoch 42/50\n",
      "122/122 - 0s - loss: 0.0014 - val_loss: 0.0062\n",
      "Epoch 43/50\n",
      "122/122 - 0s - loss: 0.0012 - val_loss: 0.0063\n",
      "Epoch 44/50\n",
      "122/122 - 0s - loss: 0.0013 - val_loss: 0.0069\n",
      "Epoch 45/50\n",
      "122/122 - 0s - loss: 0.0017 - val_loss: 0.0067\n",
      "Epoch 46/50\n",
      "122/122 - 0s - loss: 0.0016 - val_loss: 0.0080\n",
      "Epoch 47/50\n",
      "122/122 - 0s - loss: 0.0025 - val_loss: 0.0059\n",
      "Epoch 48/50\n",
      "122/122 - 0s - loss: 0.0014 - val_loss: 0.0065\n",
      "Epoch 49/50\n",
      "122/122 - 0s - loss: 0.0016 - val_loss: 0.0073\n",
      "Epoch 50/50\n",
      "122/122 - 0s - loss: 0.0016 - val_loss: 0.0071\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
