{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions to read files\n",
    "# Must be in .csv format\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "def get_list(folder,crypto):\n",
    "    file_list = os.listdir(folder)\n",
    "    r = re.compile(crypto)\n",
    "    crypto_list = list(filter(r.match, file_list))\n",
    "    return(crypto_list)\n",
    "\n",
    "def read_files(folder,crypto):\n",
    "    list_of_files = get_list(folder,crypto)\n",
    "    df = pd.read_csv((folder+'/'+list_of_files[0]))\n",
    "    for i in (list_of_files[1:]):\n",
    "        df = df.append(pd.read_csv((folder+'/'+i)))\n",
    "    df = df.sort_values('system_time')\n",
    "    df = df.reset_index(drop=True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'crypto-rl/data_recorder/database/data_exports/1min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data/raw/1sec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BTC_df = read_files(folder,'BTC')\n",
    "ETH_df = read_files(folder, 'ETH')\n",
    "ADA_df = read_files(folder, 'ADA')\n",
    "#LINK_df = read_files(folder,'LINK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'rep'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-99635335bf5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTester\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                 raise AttributeError(\"module {!r} has no attribute \"\n\u001b[0m\u001b[1;32m    215\u001b[0m                                      \"{!r}\".format(__name__, attr))\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'rep'"
     ]
    }
   ],
   "source": [
    "np.rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system_time</th>\n",
       "      <th>midpoint</th>\n",
       "      <th>spread</th>\n",
       "      <th>buys</th>\n",
       "      <th>sells</th>\n",
       "      <th>bids_distance_0</th>\n",
       "      <th>bids_distance_1</th>\n",
       "      <th>bids_distance_2</th>\n",
       "      <th>bids_distance_3</th>\n",
       "      <th>bids_distance_4</th>\n",
       "      <th>...</th>\n",
       "      <th>asks_market_notional_5</th>\n",
       "      <th>asks_market_notional_6</th>\n",
       "      <th>asks_market_notional_7</th>\n",
       "      <th>asks_market_notional_8</th>\n",
       "      <th>asks_market_notional_9</th>\n",
       "      <th>asks_market_notional_10</th>\n",
       "      <th>asks_market_notional_11</th>\n",
       "      <th>asks_market_notional_12</th>\n",
       "      <th>asks_market_notional_13</th>\n",
       "      <th>asks_market_notional_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-04-07 11:32:42.122161+00:00</td>\n",
       "      <td>56035.995</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.922836e-08</td>\n",
       "      <td>-2.676851e-07</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000245</td>\n",
       "      <td>-0.000288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-04-07 11:32:43.122161+00:00</td>\n",
       "      <td>56035.995</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.922836e-08</td>\n",
       "      <td>-2.676851e-07</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000245</td>\n",
       "      <td>-0.000288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-07 11:32:44.122161+00:00</td>\n",
       "      <td>56035.995</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.922836e-08</td>\n",
       "      <td>-2.676851e-07</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000245</td>\n",
       "      <td>-0.000288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-07 11:32:45.122161+00:00</td>\n",
       "      <td>56035.995</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.922836e-08</td>\n",
       "      <td>-2.676851e-07</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000245</td>\n",
       "      <td>-0.000288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-04-07 11:32:46.122161+00:00</td>\n",
       "      <td>56035.995</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.922836e-08</td>\n",
       "      <td>-2.676851e-07</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000245</td>\n",
       "      <td>-0.000288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030723</th>\n",
       "      <td>2021-04-19 09:54:18.386544+00:00</td>\n",
       "      <td>56863.725</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.792952e-08</td>\n",
       "      <td>-2.637886e-07</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030724</th>\n",
       "      <td>2021-04-19 09:54:19.386544+00:00</td>\n",
       "      <td>56863.725</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.792952e-08</td>\n",
       "      <td>-2.637886e-07</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030725</th>\n",
       "      <td>2021-04-19 09:54:20.386544+00:00</td>\n",
       "      <td>56863.725</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1506.866100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.792952e-08</td>\n",
       "      <td>-2.637886e-07</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030726</th>\n",
       "      <td>2021-04-19 09:54:21.386544+00:00</td>\n",
       "      <td>56863.725</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.792952e-08</td>\n",
       "      <td>-2.637886e-07</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>-0.000133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030727</th>\n",
       "      <td>2021-04-19 09:54:22.386544+00:00</td>\n",
       "      <td>56862.275</td>\n",
       "      <td>0.01</td>\n",
       "      <td>66.970689</td>\n",
       "      <td>5301.274335</td>\n",
       "      <td>-8.793176e-08</td>\n",
       "      <td>-9.136110e-05</td>\n",
       "      <td>-0.000179</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>-0.000281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030728 rows Ã— 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              system_time   midpoint  spread         buys  \\\n",
       "0        2021-04-07 11:32:42.122161+00:00  56035.995    0.01     0.000000   \n",
       "1        2021-04-07 11:32:43.122161+00:00  56035.995    0.01     0.000000   \n",
       "2        2021-04-07 11:32:44.122161+00:00  56035.995    0.01     0.000000   \n",
       "3        2021-04-07 11:32:45.122161+00:00  56035.995    0.01     0.000000   \n",
       "4        2021-04-07 11:32:46.122161+00:00  56035.995    0.01     0.000000   \n",
       "...                                   ...        ...     ...          ...   \n",
       "1030723  2021-04-19 09:54:18.386544+00:00  56863.725    0.01     0.000000   \n",
       "1030724  2021-04-19 09:54:19.386544+00:00  56863.725    0.01     0.000000   \n",
       "1030725  2021-04-19 09:54:20.386544+00:00  56863.725    0.01  1506.866100   \n",
       "1030726  2021-04-19 09:54:21.386544+00:00  56863.725    0.01     0.000000   \n",
       "1030727  2021-04-19 09:54:22.386544+00:00  56862.275    0.01    66.970689   \n",
       "\n",
       "               sells  bids_distance_0  bids_distance_1  bids_distance_2  \\\n",
       "0           0.000000    -8.922836e-08    -2.676851e-07        -0.000050   \n",
       "1           0.000000    -8.922836e-08    -2.676851e-07        -0.000050   \n",
       "2           0.000000    -8.922836e-08    -2.676851e-07        -0.000050   \n",
       "3           0.000000    -8.922836e-08    -2.676851e-07        -0.000050   \n",
       "4           0.000000    -8.922836e-08    -2.676851e-07        -0.000050   \n",
       "...              ...              ...              ...              ...   \n",
       "1030723     0.000000    -8.792952e-08    -2.637886e-07        -0.000025   \n",
       "1030724     0.000000    -8.792952e-08    -2.637886e-07        -0.000026   \n",
       "1030725     0.000000    -8.792952e-08    -2.637886e-07        -0.000026   \n",
       "1030726     0.000000    -8.792952e-08    -2.637886e-07        -0.000026   \n",
       "1030727  5301.274335    -8.793176e-08    -9.136110e-05        -0.000179   \n",
       "\n",
       "         bids_distance_3  bids_distance_4  ...  asks_market_notional_5  \\\n",
       "0              -0.000245        -0.000288  ...                     0.0   \n",
       "1              -0.000245        -0.000288  ...                     0.0   \n",
       "2              -0.000245        -0.000288  ...                     0.0   \n",
       "3              -0.000245        -0.000288  ...                     0.0   \n",
       "4              -0.000245        -0.000288  ...                     0.0   \n",
       "...                  ...              ...  ...                     ...   \n",
       "1030723        -0.000026        -0.000031  ...                     0.0   \n",
       "1030724        -0.000031        -0.000034  ...                     0.0   \n",
       "1030725        -0.000034        -0.000103  ...                     0.0   \n",
       "1030726        -0.000034        -0.000133  ...                     0.0   \n",
       "1030727        -0.000213        -0.000281  ...                     0.0   \n",
       "\n",
       "         asks_market_notional_6  asks_market_notional_7  \\\n",
       "0                           0.0                     0.0   \n",
       "1                           0.0                     0.0   \n",
       "2                           0.0                     0.0   \n",
       "3                           0.0                     0.0   \n",
       "4                           0.0                     0.0   \n",
       "...                         ...                     ...   \n",
       "1030723                     0.0                     0.0   \n",
       "1030724                     0.0                     0.0   \n",
       "1030725                     0.0                     0.0   \n",
       "1030726                     0.0                     0.0   \n",
       "1030727                     0.0                     0.0   \n",
       "\n",
       "         asks_market_notional_8  asks_market_notional_9  \\\n",
       "0                           0.0                     0.0   \n",
       "1                           0.0                     0.0   \n",
       "2                           0.0                     0.0   \n",
       "3                           0.0                     0.0   \n",
       "4                           0.0                     0.0   \n",
       "...                         ...                     ...   \n",
       "1030723                     0.0                     0.0   \n",
       "1030724                     0.0                     0.0   \n",
       "1030725                     0.0                     0.0   \n",
       "1030726                     0.0                     0.0   \n",
       "1030727                     0.0                     0.0   \n",
       "\n",
       "         asks_market_notional_10  asks_market_notional_11  \\\n",
       "0                            0.0                      0.0   \n",
       "1                            0.0                      0.0   \n",
       "2                            0.0                      0.0   \n",
       "3                            0.0                      0.0   \n",
       "4                            0.0                      0.0   \n",
       "...                          ...                      ...   \n",
       "1030723                      0.0                      0.0   \n",
       "1030724                      0.0                      0.0   \n",
       "1030725                      0.0                      0.0   \n",
       "1030726                      0.0                      0.0   \n",
       "1030727                      0.0                      0.0   \n",
       "\n",
       "         asks_market_notional_12  asks_market_notional_13  \\\n",
       "0                            0.0                      0.0   \n",
       "1                            0.0                      0.0   \n",
       "2                            0.0                      0.0   \n",
       "3                            0.0                      0.0   \n",
       "4                            0.0                      0.0   \n",
       "...                          ...                      ...   \n",
       "1030723                      0.0                      0.0   \n",
       "1030724                      0.0                      0.0   \n",
       "1030725                      0.0                      0.0   \n",
       "1030726                      0.0                      0.0   \n",
       "1030727                      0.0                      0.0   \n",
       "\n",
       "         asks_market_notional_14  \n",
       "0                            0.0  \n",
       "1                            0.0  \n",
       "2                            0.0  \n",
       "3                            0.0  \n",
       "4                            0.0  \n",
       "...                          ...  \n",
       "1030723                      0.0  \n",
       "1030724                      0.0  \n",
       "1030725                      0.0  \n",
       "1030726                      0.0  \n",
       "1030727                      0.0  \n",
       "\n",
       "[1030728 rows x 155 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BTC_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_missing(df, freq):\n",
    "    time = df['system_time']\n",
    "    t = pd.to_datetime(time[:(len(time)-1)]).reset_index(drop=True)\n",
    "    t_1 = pd.to_datetime(time[1:]).reset_index(drop=True)\n",
    "    diff = (t_1-t) / freq\n",
    "    \n",
    "    errors = np.sum(diff != '0 days 00:00:01')\n",
    "    \n",
    "    \n",
    "        \n",
    "    return(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_for_missing(ADA_df, freq = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1030533"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ADA_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering \n",
    "\n",
    "We are interested Econometric features: \n",
    "\n",
    "Statistical features: \n",
    "- Mid-price\n",
    "- Financial Duration\n",
    "- Average Mid-Price Financial Duration\n",
    "- Log-Returns\n",
    "\n",
    "Volatility MEasures: \n",
    "- Realized Volatility\n",
    "- Realized Kernel\n",
    "- Realized Pre-Averaged Varianced\n",
    "- Realized Semi-Variance\n",
    "- Realized Bipower Variation\n",
    "- Realized Bipower Variation (lag 2)\n",
    "- Realized Bipower Semi-Variance\n",
    "- Jump Variation\n",
    "- Spot Volatility\n",
    "- Average Spot Volatility\n",
    "\n",
    "Noise and Uncertainty Measures\n",
    "- Realized Quarticity \n",
    "- Realized Quarticity Tripower\n",
    "- Realized Quarticity Quadpower\n",
    "- Noise Variance (42)\n",
    "- Noise Variance (57)\n",
    "\n",
    "Price Discovery Features: \n",
    "- Weighted mid-price by order imbalance\n",
    "- Volume Imbalance\n",
    "- Bid-Ask Spread\n",
    "- Normalized Bid-Ask Spread\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation: \n",
    "Y = Midpoint,\n",
    "X = Log(Midpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log-returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Returns(df):\n",
    "    df[\"Return\"] = np.nan\n",
    "    #df[\"Return\"] = np.diff(df[\"midpoint\"]) / df[\"midpoint\"][:(len(df)-1)]\n",
    "    rt = diff(np.log(df[\"midpoint\"]))\n",
    "    df = df[:-1]\n",
    "    df[\"Return\"] = rt\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realized Voaltility: \n",
    "$$RV_n = \\sum_{i=1}^n(X_{i/n}- X_{(i-1)/n}) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RealizedVolatility(df, freq):\n",
    "    df[\"RV\"] = np.nan\n",
    "    for i in trange((len(df)-freq)):\n",
    "        df['RV'][(i+freq)] = sum(df['Return'][i:(freq+i)]**2)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realized Semivariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RealizedSemiVariance(df,freq):\n",
    "    df[\"RSV_pos\"] = np.nan\n",
    "    df[\"RSV_neg\"] = np.nan\n",
    "    \n",
    "    for i in trange((len(df)) - freq): \n",
    "        X = df['Return'][i:(freq+i)].reset_index(drop = True)\n",
    "        \n",
    "        X_pos = X[X > 0]\n",
    "        df[\"RSV_pos\"][(i+1+freq)] = sum(X_pos**2)\n",
    "        \n",
    "        X_neg = X[X < 0]\n",
    "        df[\"RSV_neg\"][(i+1+freq)]  = sum(X_neg**2)\n",
    "        \n",
    "        \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realized Bipower Variation: \n",
    "\n",
    "$$BV_n =  \\frac{2}{\\pi}\\sum_{i=1}^{n-1}\\vert X_{\\frac{i}{n}}- X_{\\frac{i-1}{n}}\\vert \\vert X_{\\frac{i+1}{n}}- X_{\\frac{i}{n}} \\vert$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BipowerVariation(df,freq):\n",
    "    df[\"BiV\"] = np.nan\n",
    "    c = np.pi/2\n",
    "    for i in trange((len(df)) - freq): \n",
    "        df[\"BiV\"][(i+1+freq)] = c*sum(np.abs(df['Return'][i:(freq+i)])\n",
    "                                    *np.abs(df['Return'][(i+1):(freq+i+1)]))\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realized Bipower Variation (lag 2): \n",
    "\n",
    "$$BV_n =  \\frac{2}{\\pi}\\sum_{i=2}^{n-1}\\vert X_{\\frac{i-1}{n}}- X_{\\frac{i-2}{n}}\\vert \\vert X_{\\frac{i+1}{n}}- X_{\\frac{i}{n}} \\vert$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BipowerVariation_lag2(df,freq):\n",
    "    df[\"BiV_2\"] = np.nan\n",
    "    c = np.pi/2\n",
    "    for i in trange((len(df)) - freq): \n",
    "        df[\"BiV_2\"][(i+2+freq)] = c*sum(np.abs(df['Return'][i:(freq+i)])\n",
    "                                    *np.abs(df['Return'][(i+2):(freq+i+2)]))\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realized bipower semivariance(+,-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BipowerSemiVariance(df,freq):\n",
    "    df[\"BiV_pos\"] = np.nan\n",
    "    df[\"BiV_neg\"] = np.nan\n",
    "    \n",
    "\n",
    "    c = np.pi/2\n",
    "    for i in trange((len(df)) - freq): \n",
    "        X = df['Return'][i:(freq+i)].reset_index(drop = True)\n",
    "        X_1 = df['Return'][(i+1):(freq+i+1)].reset_index(drop=True)\n",
    "        X_pos = X[X_1 > 0]\n",
    "        X_1_pos = X_1[X_1 > 0]\n",
    "        df[\"BiV_pos\"][(i+1+freq)] = c*sum(np.abs(X_pos)*np.abs(X_1_pos))\n",
    "        X_neg = X[X_1 < 0]\n",
    "        X_1_neg = X_1[X_1 < 0]\n",
    "        df[\"BiV_neg\"][(i+1+freq)]  = c*sum(np.abs(X_neg)*np.abs(X_1_neg))\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    return(df)\n",
    "    \n",
    "   # df[\"BiV_pos\"][df[\"Return\"] > 0] = df[\"BiV\"]\n",
    "   # df[\"BiV_pos\"][df[\"Return\"] <= 0] = 0\n",
    "    \n",
    "   # df[\"BiV_neg\"][df[\"Return\"] > 0] = 0\n",
    "   # df[\"BiV_neg\"][df[\"Return\"] <= 0] = df[\"BiV\"]\n",
    "\n",
    "   # return(df)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realized Quarticity:\n",
    "\n",
    "$$RQ_n = n\\sum_{i=1}^n \\vert X_{\\frac{i}{n}}-X_{\\frac{i-1}{n}} \\vert^4$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RealizedQuarticity(df, freq):\n",
    "    df[\"RQ\"] = np.nan\n",
    "    for i in trange((len(df)-freq)):\n",
    "        df['RQ'][(i+freq)] = sum(np.abs(np.sqrt(freq)*df['Return'][i:(freq+i)])**4)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realized Quarticity Tripower: \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RealizedQuarticityTri(df,freq):\n",
    "    mu_p = 0.8308478**(-3) # Approximation\n",
    "    n = freq\n",
    "    p = 4/3\n",
    "    r = df[\"Return\"]\n",
    "    \n",
    "    df[\"RQTri\"] = np.nan\n",
    "    \n",
    "\n",
    "    \n",
    "    for i in trange(len(df)-freq-2):\n",
    "        lag_2 = r[i:freq+i]\n",
    "        lag_1 = r[i+1:freq+1+i]\n",
    "        lag_0 = r[i+2:freq+2+i]\n",
    "        \n",
    "        df[\"RQTri\"][i+freq+2] = n*mu_p*sum(np.abs(lag_0)**p*np.abs(lag_1)**p\n",
    "                                            *np.abs(lag_2)**p)    \n",
    "        \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realized Quarticity Quadpower: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RealizedQuarticityQuad(df, freq):\n",
    "    mu_p = 0.7978469**(-4) # Approximation\n",
    "    n = freq\n",
    "    r = df[\"Return\"]\n",
    "    df[\"RQQuad\"] = np.nan\n",
    "    \n",
    "    \n",
    "    for i in trange(len(df)-freq-3):\n",
    "        lag_3 = r[i:freq+i].reset_index(drop = True)\n",
    "        lag_2 = r[i+1:freq+1+i].reset_index(drop = True)\n",
    "        lag_1 = r[i+2:freq+2+i].reset_index(drop = True)\n",
    "        lag_0 = r[i+3:freq+3+i].reset_index(drop = True)\n",
    "        \n",
    "        df[\"RQQuad\"][i+freq+3] = n*mu_p*sum(np.abs(lag_0)*np.abs(lag_1)\n",
    "                                            *np.abs(lag_2)*np.abs(lag_3))   \n",
    "    return(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realized Kernel:\n",
    "\n",
    "\n",
    "$$RK_n = \\gamma_0(Y) + 2\\sum_{h=1}^{H-1}k(\\frac{h}{H})\\gamma_n(h)$$\n",
    "\n",
    "Here $\\gamma_h(Y)$ is the realized autocorrelation:\n",
    "\n",
    "$$ \\gamma_n(h) = \\sum_{i=h+1}^{n}\\vert Y_{i/n}- Y_{(i-1)/n}\\vert \\vert Y_{i-h/n}- Y_{(i-h-1)/n} $$\n",
    "\n",
    "\n",
    "Examples of kernels:\n",
    "\n",
    "Bartlett kernel:\n",
    "$$k(x) = 1 - x$$\n",
    "Cubic kernel:\n",
    "$$k(x) = 1 - 3x^2  + 2x^3$$\n",
    "\n",
    "Parzen Kernel:\n",
    "\n",
    "\\[\n",
    "    k(x)= \n",
    "\\begin{cases}\n",
    "    1-6x^2 + 6x^3,& \\text{if } 0 \\le x\\le 1/2\\\\\n",
    "    2(1-x)^3,              & \\text{if } 1/2 \\le x \\le 1\n",
    "\\end{cases}\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RealizedKernel(df, H, kernel_type,freq):\n",
    "    df[\"RK\"] = np.nan\n",
    "\n",
    "    def kernel(x, kernel_type):\n",
    "        if kernel_type == \"bartlett\":\n",
    "            return(1-x)\n",
    "        if kernel_type == \"cubic\":\n",
    "            return(1-3*x**2+2*x**3)\n",
    "        if kernel_type == \"parzen\":\n",
    "            if 0 <= x <= 0.5:\n",
    "                return(1 - 6*x**2 + 6*x**3)\n",
    "            elif 0.5 < x <= 1:\n",
    "                return(2*(1-x)**3)\n",
    "            else: \n",
    "                print(\"ERROR\")\n",
    "        \n",
    "    Y = df[\"midpoint\"]\n",
    "\n",
    "    def gamma_h(Y,h):\n",
    "        Y = Y.reset_index(drop = True)\n",
    "        gamma = np.zeros(len(Y)-h-1)\n",
    "        for i in range(len(Y)-h-1):\n",
    "            gamma[i] = (Y[i+h+1] - Y[i+h])*(Y[i+1]-Y[i])\n",
    "        return(sum(gamma))\n",
    "\n",
    "\n",
    "    def RK_n(Y):\n",
    "        gamma_0 = gamma_h(Y,0)\n",
    "        k_gamma_n = np.zeros(H-2)\n",
    "        for i in range(H-2):\n",
    "            k_gamma_n[i] = kernel((i+1)/H, kernel_type)*gamma_h(Y,i+1)\n",
    "        RK_n = gamma_0 + 2*sum(k_gamma_n)\n",
    "        return(RK_n)\n",
    "\n",
    "\n",
    "    for i in trange(len(df)-freq):\n",
    "            df[\"RK\"][i+freq] = RK_n(Y[i:i+freq])\n",
    "\n",
    "    return(df)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realized Pre-Averaged Variance: \n",
    "\n",
    "\n",
    "$$ P_n = \\frac{n}{(n-k_n+2)k_n\\psi_2^n} \\sum_{i=0}^{n-k_n+1}\\bar{Y}^2_{\\frac{i}{n}}-\\frac{n\\psi_1^n}{k_n^2\\psi_2^n}\\hat{\\omega}^2_n $$\n",
    "\n",
    "\n",
    "$$\\hat{\\omega}^2_n \\frac{1}{2n} = \\sum_{i=1}^{n}(Y_{\\frac{i}{n}} -Y_{\\frac{i-1}{n}})^2 $$\n",
    "\n",
    "$$\\psi_1^n = \\sum_{j=0}^{k_n-1}(g(\\frac{j+1}{k_n})-g(\\frac{j}{k_n}))^2$$\n",
    "\n",
    "$$\\psi_2^n = \\frac{1}{k_n}\\sum_{j=1}^{k_n-1}g^2(\\frac{j}{k_n})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreAvg(df, freq, k):\n",
    "    \n",
    "    K = k\n",
    "    df[\"PreAvg\"] = np.nan\n",
    "    \n",
    "    Y = df[\"Return\"]\n",
    "    \n",
    "    def kernel(x):\n",
    "        m = min(x,1-x)\n",
    "        return(m)\n",
    "    \n",
    "    def Pre_n(Y,k):\n",
    "        \n",
    "        r = Y \n",
    "        \n",
    "        n = len(r)\n",
    "        r_pa = 0\n",
    "        \n",
    "        for i in range(K-1):\n",
    "            r_pa = r_pa + kernel(i/k)*r[i:(len(r)+i-(k-1))]\n",
    "    \n",
    "        idx = array(range(k))/k\n",
    "        \n",
    "        g = np.zeros(shape=len(idx))\n",
    "        \n",
    "        for i in range(len(idx)):\n",
    "            g[i] = kernel(idx[i])\n",
    "        \n",
    "        dg = diff(g)\n",
    "        psi1 = sum(dg**2)*k\n",
    "        psi2 = sum(g**2)/k\n",
    "        \n",
    "        P = sum(r_pa**2)\n",
    "        P = P*n/((n-k+2)*k*psi2)\n",
    "        P = P-sum(r**2)*psi1/(2*psi2*k**2)\n",
    "        \n",
    "        return(P)\n",
    "    \n",
    "    for i in trange(len(df)-freq):\n",
    "        df[\"PreAvg\"][i+freq] = Pre_n(Y[i:i+freq],k) #### We only use 60 observations in total, maybe use more?\n",
    "        \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jump Variation: \n",
    "\n",
    "$$JV_n = RV_n - BV_n$$\n",
    "\n",
    "Jump Proportion: \n",
    "\n",
    "$$PJ = 1 - \\frac{BV_n}{RV_n}   $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JumpVariation(df):\n",
    "    df[\"JV\"] = df[\"RV\"]-df[\"BiV\"] # Can this be nagative?\n",
    "    df[\"JV\"][df[\"JV\"] < 0] = 0 # Truncate negative values to 0\n",
    "    df[\"PJ\"] = 1- df[\"BiV\"] / df[\"RV\"] # Proportion of jumps\n",
    "    df[\"PJ\"][df[\"PJ\"]<0] = 0\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spot volatility: \n",
    "\n",
    "$SV_t = Y_t^2$ -  Not sure about this one. go check\n",
    "\n",
    "Average Spot Volatility: \n",
    "\n",
    "$ASV = \\frac{1}{n}\\sum{i=1}^n Y_t^2$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpotVolatility(df,freq):\n",
    "    df[\"SV\"] = df[\"Return\"]**2\n",
    "    \n",
    "    df[\"ASV\"] = np.nan\n",
    "    \n",
    "    for i in trange(len(df)):\n",
    "        df[\"ASV\"][i+freq] = mean(df[\"SV\"][i:(i+freq)])\n",
    "        \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noise Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NoiseVariance(df,freq):\n",
    "    df[\"NV\"] = np.nan\n",
    "    Y = df[\"midpoint\"].reset_index(drop = True)\n",
    "    \n",
    "    for i in trange(len(df)-freq-1):\n",
    "        Y_0 = Y[i+1:i+freq+1].reset_index(drop=True)\n",
    "        Y_1 = Y[i:i+freq].reset_index(drop=True)\n",
    "        df[\"NV\"][i+freq+1] = 1/(2*freq)*sum((Y_0-Y_1)**2)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateFeatures(df, freq):\n",
    "    # Statistical Features\n",
    "    \n",
    "    df = Returns(df)\n",
    "    print(\"Returns Done\")\n",
    "    \n",
    "\n",
    "    \n",
    "    # Volatility Measures\n",
    "    df = RealizedVolatility(df, freq)\n",
    "    print(\"RV Done\")\n",
    "    df = RealizedSemiVariance(df,freq)\n",
    "    print(\"RSV Done\")\n",
    "    df = BipowerVariation(df, freq) # Maybe 59 in freq here? \n",
    "    print(\"BV Done\")\n",
    "    df = RealizedKernel(df, 10, \"cubic\", freq)\n",
    "    print(\"RK Done\")\n",
    "    df = PreAvg(df, freq, 10)\n",
    "    print(\"PreAvg DOne\")\n",
    "    df = JumpVariation(df)\n",
    "    print(\"Jump Var Done\")\n",
    "    df = SpotVolatility(df, freq)\n",
    "    print(\"Spot Var Done\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Noise and uncertainty measures\n",
    "    df = RealizedQuarticity(df, freq)\n",
    "    print(\"RQ Done\")\n",
    "    DF = RealizedQuarticityTri(df,freq)\n",
    "    print(\"RQTri Done\")\n",
    "    df = RealizedQuarticityQuad(df,freq)\n",
    "    print(\"RQQuad Done\")\n",
    "    df = NoiseVariance(df, freq)\n",
    "    print(\"Noise Variance Done\")\n",
    "    \n",
    "    df = df.dropna()\n",
    "    \n",
    "   # df = df.drop(\"system_time\", axis = 1)\n",
    "    \n",
    "    return(df)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returns Done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04b5355cb7e445780e197de1c23bea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1030472.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RV Done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f7d712f98c454a9d65b60085332e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1030472.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RSV Done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189b37a1043344ff992a10b167778d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1030472.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BV Done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de0bf360499142aeb402e6c3faf3ecb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1030472.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RK Done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc80d6eddfb4b30b4fcb0902f36f739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1030472.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PreAvg DOne\n",
      "Jump Var Done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80872adaf39b4264a3e8add657a9873f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1030532.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Spot Var Done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a80d94b0bdd4915886488b8facc166e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1030472.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RQ Done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d9e0ba101b472fbeb863f310ee38c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1030470.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RQTri Done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77b58e34956430da02674c1c21dccec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1030469.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RQQuad Done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00978cbdafb8432783b50512156e9a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1030471.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Noise Variance Done\n",
      "CPU times: user 4h 14min 54s, sys: 3min 28s, total: 4h 18min 22s\n",
      "Wall time: 4h 8min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "#Feature_df = GenerateFeatures(BTC_df,60)\n",
    "#Feature_df.to_csv(\"BTC_5_df_final.csv\", index = False)\n",
    "#Feature_df = GenerateFeatures(ETH_df,60)\n",
    "#Feature_df.to_csv(\"ETH_5_df_final.csv\", index = False)\n",
    "Feature_df = GenerateFeatures(ADA_df,60)\n",
    "Feature_df.to_csv(\"ADA_5_df_final.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature_df.to_csv(\"BTC_df_new.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# fit scaler on data\n",
    "scaler.fit(BTC_train_x)\n",
    "# apply transform\n",
    "standardized = scaler.transform(BTC_train_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_y = (BTC_train_y - np.mean(BTC_train_y)) / np.std(BTC_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55272.29983273051"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(BTC_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.std of 0       57152.415\n",
       "1       57165.325\n",
       "2       57246.105\n",
       "3       57323.785\n",
       "4       57323.005\n",
       "          ...    \n",
       "1101    53858.425\n",
       "1102    53923.135\n",
       "1103    53900.005\n",
       "1104    54123.500\n",
       "1105    54130.405\n",
       "Name: Y, Length: 1106, dtype: float64>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BTC_train_y.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.59517785,  1.58351505,  0.01783049, ..., -0.24758814,\n",
       "        -0.72635342, -0.2973385 ],\n",
       "       [ 1.50453079, -0.78490942, -0.24008746, ..., -0.24741272,\n",
       "        -0.72516837, -0.30451312],\n",
       "       [ 1.5148774 , -0.78490942,  0.16092535, ..., -0.24740813,\n",
       "        -0.72495243, -0.21652222],\n",
       "       ...,\n",
       "       [-1.08354868, -0.78490942, -0.48841119, ..., -0.86888887,\n",
       "        -0.62550217, -0.90375173],\n",
       "       [-1.10208603, -0.78490942, -0.63129689, ..., -0.86862775,\n",
       "        -0.62503023, -0.92168919],\n",
       "       [-0.92296783,  3.1471351 ,  1.33562128, ..., -0.86540311,\n",
       "        -0.61419786, -0.91867869]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    57165.325\n",
       "2    57246.105\n",
       "3    57323.785\n",
       "4    57323.005\n",
       "5    57279.215\n",
       "6    57222.305\n",
       "7    57240.555\n",
       "8    57225.005\n",
       "9    57204.620\n",
       "Name: Y, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BTC_train_y[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1106, 169)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BTC_train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(169, input_dim = 169, kernel_initializer = \"normal\", activation = \"relu\"))\n",
    "model.add(Dense(1, kernel_initializer = \"normal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim = 1, kernel_initializer = \"normal\"))\n",
    "#model.add(Dense(1, kernel_initializer = \"normal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate = 0.01),\n",
    "    loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2858215424.0000 - val_loss: 2788084736.0000\n",
      "Epoch 2/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2171803648.0000 - val_loss: 2383913472.0000\n",
      "Epoch 3/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1687796992.0000 - val_loss: 2071241984.0000\n",
      "Epoch 4/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1369279616.0000 - val_loss: 1842051456.0000\n",
      "Epoch 5/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1146385024.0000 - val_loss: 1673803776.0000\n",
      "Epoch 6/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 985536128.0000 - val_loss: 1531564928.0000\n",
      "Epoch 7/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 863447552.0000 - val_loss: 1408157824.0000\n",
      "Epoch 8/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 765856512.0000 - val_loss: 1308780800.0000\n",
      "Epoch 9/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 687771200.0000 - val_loss: 1225032960.0000\n",
      "Epoch 10/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 622668928.0000 - val_loss: 1148852224.0000\n",
      "Epoch 11/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 567822272.0000 - val_loss: 1084425600.0000\n",
      "Epoch 12/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 520382816.0000 - val_loss: 1028108608.0000\n",
      "Epoch 13/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 479570304.0000 - val_loss: 974868544.0000\n",
      "Epoch 14/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 443454784.0000 - val_loss: 924558912.0000\n",
      "Epoch 15/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 411478368.0000 - val_loss: 878693696.0000\n",
      "Epoch 16/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 383238336.0000 - val_loss: 839533312.0000\n",
      "Epoch 17/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 357422848.0000 - val_loss: 801394944.0000\n",
      "Epoch 18/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 334288192.0000 - val_loss: 764553536.0000\n",
      "Epoch 19/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 313387328.0000 - val_loss: 732075136.0000\n",
      "Epoch 20/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 294215648.0000 - val_loss: 701217216.0000\n",
      "Epoch 21/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 276845792.0000 - val_loss: 672121600.0000\n",
      "Epoch 22/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 260970672.0000 - val_loss: 645284160.0000\n",
      "Epoch 23/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 246067920.0000 - val_loss: 619527680.0000\n",
      "Epoch 24/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 232525280.0000 - val_loss: 595529344.0000\n",
      "Epoch 25/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 219835024.0000 - val_loss: 573350976.0000\n",
      "Epoch 26/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 208166480.0000 - val_loss: 551790208.0000\n",
      "Epoch 27/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 197370048.0000 - val_loss: 530999168.0000\n",
      "Epoch 28/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 187166464.0000 - val_loss: 511118880.0000\n",
      "Epoch 29/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 177745936.0000 - val_loss: 493045728.0000\n",
      "Epoch 30/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 168808112.0000 - val_loss: 475727328.0000\n",
      "Epoch 31/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 160605840.0000 - val_loss: 459217760.0000\n",
      "Epoch 32/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 152816128.0000 - val_loss: 442802976.0000\n",
      "Epoch 33/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 145507840.0000 - val_loss: 427997888.0000\n",
      "Epoch 34/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 138606048.0000 - val_loss: 413155328.0000\n",
      "Epoch 35/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 132169424.0000 - val_loss: 399314624.0000\n",
      "Epoch 36/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 126010344.0000 - val_loss: 386083360.0000\n",
      "Epoch 37/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 120231912.0000 - val_loss: 373467424.0000\n",
      "Epoch 38/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 114786104.0000 - val_loss: 361049184.0000\n",
      "Epoch 39/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 109621752.0000 - val_loss: 349710656.0000\n",
      "Epoch 40/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 104743664.0000 - val_loss: 338423520.0000\n",
      "Epoch 41/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 100067832.0000 - val_loss: 328017504.0000\n",
      "Epoch 42/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 95726376.0000 - val_loss: 317488832.0000\n",
      "Epoch 43/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 91526216.0000 - val_loss: 307544480.0000\n",
      "Epoch 44/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 87572440.0000 - val_loss: 298161472.0000\n",
      "Epoch 45/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 83807032.0000 - val_loss: 288830944.0000\n",
      "Epoch 46/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 80249000.0000 - val_loss: 279805568.0000\n",
      "Epoch 47/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 76786600.0000 - val_loss: 271579712.0000\n",
      "Epoch 48/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 73554136.0000 - val_loss: 263389664.0000\n",
      "Epoch 49/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 70461800.0000 - val_loss: 255704368.0000\n",
      "Epoch 50/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 67544136.0000 - val_loss: 247995456.0000\n",
      "Epoch 51/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 64699080.0000 - val_loss: 240630048.0000\n",
      "Epoch 52/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 62040444.0000 - val_loss: 233506304.0000\n",
      "Epoch 53/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 59445328.0000 - val_loss: 226860352.0000\n",
      "Epoch 54/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 57025820.0000 - val_loss: 220320192.0000\n",
      "Epoch 55/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 54699208.0000 - val_loss: 213991184.0000\n",
      "Epoch 56/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 52452984.0000 - val_loss: 207957536.0000\n",
      "Epoch 57/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 50329832.0000 - val_loss: 202064320.0000\n",
      "Epoch 58/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 48284684.0000 - val_loss: 196410272.0000\n",
      "Epoch 59/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 46337852.0000 - val_loss: 190983392.0000\n",
      "Epoch 60/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 44485668.0000 - val_loss: 185588048.0000\n",
      "Epoch 61/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 42691828.0000 - val_loss: 180512080.0000\n",
      "Epoch 62/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 40986060.0000 - val_loss: 175526688.0000\n",
      "Epoch 63/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 39352876.0000 - val_loss: 170789184.0000\n",
      "Epoch 64/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 37782840.0000 - val_loss: 166169072.0000\n",
      "Epoch 65/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 36299108.0000 - val_loss: 161651648.0000\n",
      "Epoch 66/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 34844880.0000 - val_loss: 157396480.0000\n",
      "Epoch 67/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 33482346.0000 - val_loss: 153181744.0000\n",
      "Epoch 68/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 32170728.0000 - val_loss: 149102912.0000\n",
      "Epoch 69/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 30887260.0000 - val_loss: 145261648.0000\n",
      "Epoch 70/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 29686948.0000 - val_loss: 141459360.0000\n",
      "Epoch 71/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 28518148.0000 - val_loss: 137779552.0000\n",
      "Epoch 72/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 27404802.0000 - val_loss: 134194280.0000\n",
      "Epoch 73/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 26341256.0000 - val_loss: 130731136.0000\n",
      "Epoch 74/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 25317270.0000 - val_loss: 127406488.0000\n",
      "Epoch 75/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 24333628.0000 - val_loss: 124238264.0000\n",
      "Epoch 76/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 23391950.0000 - val_loss: 121210840.0000\n",
      "Epoch 77/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 22491980.0000 - val_loss: 118133472.0000\n",
      "Epoch 78/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 21619678.0000 - val_loss: 115161624.0000\n",
      "Epoch 79/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 20797398.0000 - val_loss: 112338520.0000\n",
      "Epoch 80/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 19995952.0000 - val_loss: 109553256.0000\n",
      "Epoch 81/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 19227184.0000 - val_loss: 106891392.0000\n",
      "Epoch 82/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 18488190.0000 - val_loss: 104313880.0000\n",
      "Epoch 83/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 17788784.0000 - val_loss: 101763816.0000\n",
      "Epoch 84/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 17111134.0000 - val_loss: 99366192.0000\n",
      "Epoch 85/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 16452709.0000 - val_loss: 96975392.0000\n",
      "Epoch 86/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 15833476.0000 - val_loss: 94692856.0000\n",
      "Epoch 87/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 15233387.0000 - val_loss: 92450816.0000\n",
      "Epoch 88/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 14655365.0000 - val_loss: 90313056.0000\n",
      "Epoch 89/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 14105192.0000 - val_loss: 88249984.0000\n",
      "Epoch 90/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 13580902.0000 - val_loss: 86154288.0000\n",
      "Epoch 91/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 13071230.0000 - val_loss: 84224568.0000\n",
      "Epoch 92/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 12577775.0000 - val_loss: 82325224.0000\n",
      "Epoch 93/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 12115934.0000 - val_loss: 80449608.0000\n",
      "Epoch 94/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 11665030.0000 - val_loss: 78658752.0000\n",
      "Epoch 95/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 11230926.0000 - val_loss: 76965480.0000\n",
      "Epoch 96/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 10823919.0000 - val_loss: 75243304.0000\n",
      "Epoch 97/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 10424968.0000 - val_loss: 73581568.0000\n",
      "Epoch 98/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 10042429.0000 - val_loss: 71991336.0000\n",
      "Epoch 99/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 9681496.0000 - val_loss: 70407296.0000\n",
      "Epoch 100/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 9328306.0000 - val_loss: 68927616.0000\n",
      "Epoch 101/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 8995820.0000 - val_loss: 67451888.0000\n",
      "Epoch 102/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 8675362.0000 - val_loss: 66027792.0000\n",
      "Epoch 103/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 8368769.0000 - val_loss: 64648292.0000\n",
      "Epoch 104/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 8067539.0000 - val_loss: 63318168.0000\n",
      "Epoch 105/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 7791031.5000 - val_loss: 61999900.0000\n",
      "Epoch 106/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 7519060.0000 - val_loss: 60733632.0000\n",
      "Epoch 107/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 7261556.0000 - val_loss: 59511248.0000\n",
      "Epoch 108/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 7014693.0000 - val_loss: 58282656.0000\n",
      "Epoch 109/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 6776323.5000 - val_loss: 57155656.0000\n",
      "Epoch 110/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 6549360.5000 - val_loss: 56039884.0000\n",
      "Epoch 111/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 6334981.0000 - val_loss: 54930556.0000\n",
      "Epoch 112/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 6124833.0000 - val_loss: 53900460.0000\n",
      "Epoch 113/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 5931515.5000 - val_loss: 52845892.0000\n",
      "Epoch 114/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 5738590.5000 - val_loss: 51840764.0000\n",
      "Epoch 115/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 5556657.0000 - val_loss: 50889072.0000\n",
      "Epoch 116/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 5385480.5000 - val_loss: 49907748.0000\n",
      "Epoch 117/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 5217350.0000 - val_loss: 49000688.0000\n",
      "Epoch 118/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 5058351.5000 - val_loss: 48118036.0000\n",
      "Epoch 119/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4909857.5000 - val_loss: 47217572.0000\n",
      "Epoch 120/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4761950.5000 - val_loss: 46377524.0000\n",
      "Epoch 121/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4620310.5000 - val_loss: 45587880.0000\n",
      "Epoch 122/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4490727.0000 - val_loss: 44790044.0000\n",
      "Epoch 123/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4364334.0000 - val_loss: 43992932.0000\n",
      "Epoch 124/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4242682.0000 - val_loss: 43259124.0000\n",
      "Epoch 125/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4126767.0000 - val_loss: 42514908.0000\n",
      "Epoch 126/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4013365.0000 - val_loss: 41813604.0000\n",
      "Epoch 127/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3907560.2500 - val_loss: 41122724.0000\n",
      "Epoch 128/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3805092.2500 - val_loss: 40448004.0000\n",
      "Epoch 129/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3707719.2500 - val_loss: 39782572.0000\n",
      "Epoch 130/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3614900.2500 - val_loss: 39131468.0000\n",
      "Epoch 131/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3524628.5000 - val_loss: 38520556.0000\n",
      "Epoch 132/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3440621.2500 - val_loss: 37912488.0000\n",
      "Epoch 133/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 3357032.5000 - val_loss: 37321348.0000\n",
      "Epoch 134/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 3277934.0000 - val_loss: 36760248.0000\n",
      "Epoch 135/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 3203279.0000 - val_loss: 36220676.0000\n",
      "Epoch 136/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 3130067.5000 - val_loss: 35660540.0000\n",
      "Epoch 137/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3062232.5000 - val_loss: 35125108.0000\n",
      "Epoch 138/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2993610.2500 - val_loss: 34621980.0000\n",
      "Epoch 139/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2930031.7500 - val_loss: 34128268.0000\n",
      "Epoch 140/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2868671.5000 - val_loss: 33636208.0000\n",
      "Epoch 141/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2808386.0000 - val_loss: 33182224.0000\n",
      "Epoch 142/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2753109.5000 - val_loss: 32726346.0000\n",
      "Epoch 143/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2697506.0000 - val_loss: 32270678.0000\n",
      "Epoch 144/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 7ms/step - loss: 2644264.5000 - val_loss: 31838778.0000\n",
      "Epoch 145/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2593839.0000 - val_loss: 31407586.0000\n",
      "Epoch 146/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2544127.7500 - val_loss: 30988588.0000\n",
      "Epoch 147/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2496466.0000 - val_loss: 30597372.0000\n",
      "Epoch 148/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2451825.0000 - val_loss: 30190920.0000\n",
      "Epoch 149/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2408169.0000 - val_loss: 29807920.0000\n",
      "Epoch 150/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2364613.0000 - val_loss: 29435910.0000\n",
      "Epoch 151/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2323459.5000 - val_loss: 29068344.0000\n",
      "Epoch 152/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2282817.2500 - val_loss: 28711822.0000\n",
      "Epoch 153/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2245793.5000 - val_loss: 28359984.0000\n",
      "Epoch 154/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2207572.5000 - val_loss: 28026628.0000\n",
      "Epoch 155/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2171317.2500 - val_loss: 27685226.0000\n",
      "Epoch 156/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2136537.5000 - val_loss: 27355618.0000\n",
      "Epoch 157/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2102474.2500 - val_loss: 27028992.0000\n",
      "Epoch 158/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2069139.7500 - val_loss: 26718224.0000\n",
      "Epoch 159/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2037022.2500 - val_loss: 26416270.0000\n",
      "Epoch 160/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2005533.0000 - val_loss: 26138860.0000\n",
      "Epoch 161/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1975275.5000 - val_loss: 25832190.0000\n",
      "Epoch 162/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1946417.1250 - val_loss: 25544512.0000\n",
      "Epoch 163/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1916910.5000 - val_loss: 25255842.0000\n",
      "Epoch 164/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1888406.7500 - val_loss: 24990872.0000\n",
      "Epoch 165/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1861551.5000 - val_loss: 24709314.0000\n",
      "Epoch 166/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1834300.0000 - val_loss: 24458260.0000\n",
      "Epoch 167/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1808771.6250 - val_loss: 24199494.0000\n",
      "Epoch 168/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1783046.5000 - val_loss: 23939620.0000\n",
      "Epoch 169/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1757367.7500 - val_loss: 23703610.0000\n",
      "Epoch 170/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1734215.2500 - val_loss: 23454986.0000\n",
      "Epoch 171/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1710234.2500 - val_loss: 23201088.0000\n",
      "Epoch 172/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1686814.1250 - val_loss: 22961164.0000\n",
      "Epoch 173/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1664192.2500 - val_loss: 22739616.0000\n",
      "Epoch 174/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1641873.3750 - val_loss: 22500710.0000\n",
      "Epoch 175/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1620693.7500 - val_loss: 22267092.0000\n",
      "Epoch 176/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1598934.6250 - val_loss: 22053666.0000\n",
      "Epoch 177/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1577906.8750 - val_loss: 21833566.0000\n",
      "Epoch 178/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1557830.1250 - val_loss: 21618112.0000\n",
      "Epoch 179/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1537323.8750 - val_loss: 21424856.0000\n",
      "Epoch 180/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1518344.8750 - val_loss: 21218290.0000\n",
      "Epoch 181/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1499107.5000 - val_loss: 21020264.0000\n",
      "Epoch 182/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1479324.1250 - val_loss: 20832270.0000\n",
      "Epoch 183/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1461571.0000 - val_loss: 20628162.0000\n",
      "Epoch 184/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1442520.8750 - val_loss: 20450666.0000\n",
      "Epoch 185/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1425049.5000 - val_loss: 20265608.0000\n",
      "Epoch 186/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1407310.2500 - val_loss: 20079738.0000\n",
      "Epoch 187/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1391314.8750 - val_loss: 19877912.0000\n",
      "Epoch 188/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1372714.0000 - val_loss: 19705214.0000\n",
      "Epoch 189/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1356260.7500 - val_loss: 19529146.0000\n",
      "Epoch 190/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1340081.1250 - val_loss: 19356144.0000\n",
      "Epoch 191/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1324332.8750 - val_loss: 19175884.0000\n",
      "Epoch 192/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1308030.8750 - val_loss: 19012896.0000\n",
      "Epoch 193/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1292875.1250 - val_loss: 18837992.0000\n",
      "Epoch 194/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1276852.8750 - val_loss: 18685664.0000\n",
      "Epoch 195/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1261891.1250 - val_loss: 18530752.0000\n",
      "Epoch 196/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1247374.8750 - val_loss: 18377392.0000\n",
      "Epoch 197/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1233293.6250 - val_loss: 18200484.0000\n",
      "Epoch 198/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1218481.5000 - val_loss: 18038430.0000\n",
      "Epoch 199/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1204112.1250 - val_loss: 17885826.0000\n",
      "Epoch 200/2000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1190428.0000 - val_loss: 17737836.0000\n",
      "Epoch 201/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1176992.7500 - val_loss: 17584506.0000\n",
      "Epoch 202/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1162778.8750 - val_loss: 17446976.0000\n",
      "Epoch 203/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1149989.8750 - val_loss: 17286532.0000\n",
      "Epoch 204/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1136799.7500 - val_loss: 17157894.0000\n",
      "Epoch 205/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1123740.3750 - val_loss: 17007478.0000\n",
      "Epoch 206/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1111000.1250 - val_loss: 16861858.0000\n",
      "Epoch 207/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1098074.1250 - val_loss: 16720586.0000\n",
      "Epoch 208/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1085853.3750 - val_loss: 16590722.0000\n",
      "Epoch 209/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1073604.5000 - val_loss: 16455629.0000\n",
      "Epoch 210/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1061568.2500 - val_loss: 16321672.0000\n",
      "Epoch 211/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1049882.2500 - val_loss: 16188436.0000\n",
      "Epoch 212/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1038353.0625 - val_loss: 16043715.0000\n",
      "Epoch 213/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1026237.5625 - val_loss: 15913040.0000\n",
      "Epoch 214/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1014946.6250 - val_loss: 15792205.0000\n",
      "Epoch 215/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1003502.8125 - val_loss: 15679655.0000\n",
      "Epoch 216/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 992491.2500 - val_loss: 15548614.0000\n",
      "Epoch 217/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 981585.4375 - val_loss: 15423041.0000\n",
      "Epoch 218/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 970643.6250 - val_loss: 15300343.0000\n",
      "Epoch 219/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 960065.0000 - val_loss: 15174800.0000\n",
      "Epoch 220/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 949382.0000 - val_loss: 15047806.0000\n",
      "Epoch 221/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 939206.3750 - val_loss: 14929456.0000\n",
      "Epoch 222/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 928476.0000 - val_loss: 14808961.0000\n",
      "Epoch 223/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 918489.5000 - val_loss: 14693506.0000\n",
      "Epoch 224/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 908617.2500 - val_loss: 14577045.0000\n",
      "Epoch 225/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 898790.6875 - val_loss: 14483583.0000\n",
      "Epoch 226/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 889400.3750 - val_loss: 14368603.0000\n",
      "Epoch 227/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 879469.1250 - val_loss: 14245031.0000\n",
      "Epoch 228/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 869796.8750 - val_loss: 14132161.0000\n",
      "Epoch 229/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 860540.6250 - val_loss: 14021886.0000\n",
      "Epoch 230/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 851065.1875 - val_loss: 13920371.0000\n",
      "Epoch 231/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 842024.3125 - val_loss: 13805046.0000\n",
      "Epoch 232/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 833379.3750 - val_loss: 13702348.0000\n",
      "Epoch 233/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 823789.0625 - val_loss: 13605178.0000\n",
      "Epoch 234/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 815555.6875 - val_loss: 13497573.0000\n",
      "Epoch 235/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 806874.6250 - val_loss: 13399001.0000\n",
      "Epoch 236/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 798280.2500 - val_loss: 13288916.0000\n",
      "Epoch 237/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 789323.3750 - val_loss: 13190835.0000\n",
      "Epoch 238/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 780896.3750 - val_loss: 13096973.0000\n",
      "Epoch 239/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 772731.0625 - val_loss: 12995911.0000\n",
      "Epoch 240/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 764762.0625 - val_loss: 12900075.0000\n",
      "Epoch 241/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 756358.7500 - val_loss: 12797665.0000\n",
      "Epoch 242/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 748151.4375 - val_loss: 12702590.0000\n",
      "Epoch 243/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 740382.6250 - val_loss: 12612099.0000\n",
      "Epoch 244/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 732716.4375 - val_loss: 12522787.0000\n",
      "Epoch 245/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 724895.1875 - val_loss: 12431410.0000\n",
      "Epoch 246/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 717243.0000 - val_loss: 12338031.0000\n",
      "Epoch 247/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 709512.5625 - val_loss: 12251918.0000\n",
      "Epoch 248/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 702083.1250 - val_loss: 12169703.0000\n",
      "Epoch 249/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 694663.6250 - val_loss: 12077369.0000\n",
      "Epoch 250/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 687589.5000 - val_loss: 11985737.0000\n",
      "Epoch 251/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 680011.5625 - val_loss: 11900325.0000\n",
      "Epoch 252/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 673167.1250 - val_loss: 11805535.0000\n",
      "Epoch 253/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 666061.5625 - val_loss: 11716648.0000\n",
      "Epoch 254/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 659076.7500 - val_loss: 11634433.0000\n",
      "Epoch 255/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 652303.8125 - val_loss: 11544288.0000\n",
      "Epoch 256/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 645147.6250 - val_loss: 11469417.0000\n",
      "Epoch 257/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 638901.1250 - val_loss: 11397435.0000\n",
      "Epoch 258/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 632067.3750 - val_loss: 11310548.0000\n",
      "Epoch 259/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 625319.8125 - val_loss: 11230032.0000\n",
      "Epoch 260/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 619007.2500 - val_loss: 11151942.0000\n",
      "Epoch 261/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 612882.5625 - val_loss: 11067513.0000\n",
      "Epoch 262/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 606307.3750 - val_loss: 10990711.0000\n",
      "Epoch 263/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 599949.5625 - val_loss: 10912736.0000\n",
      "Epoch 264/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 593962.8125 - val_loss: 10831960.0000\n",
      "Epoch 265/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 587771.2500 - val_loss: 10765162.0000\n",
      "Epoch 266/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 581745.3750 - val_loss: 10688435.0000\n",
      "Epoch 267/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 575822.9375 - val_loss: 10609651.0000\n",
      "Epoch 268/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 569757.8125 - val_loss: 10531556.0000\n",
      "Epoch 269/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 564151.6875 - val_loss: 10463257.0000\n",
      "Epoch 270/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 558659.4375 - val_loss: 10376611.0000\n",
      "Epoch 271/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 552628.1875 - val_loss: 10308058.0000\n",
      "Epoch 272/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 547070.1250 - val_loss: 10238401.0000\n",
      "Epoch 273/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 541585.4375 - val_loss: 10169172.0000\n",
      "Epoch 274/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 535989.3125 - val_loss: 10099961.0000\n",
      "Epoch 275/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 530552.5625 - val_loss: 10033135.0000\n",
      "Epoch 276/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 525333.1250 - val_loss: 9959560.0000\n",
      "Epoch 277/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 520145.6562 - val_loss: 9885939.0000\n",
      "Epoch 278/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 514672.9375 - val_loss: 9830304.0000\n",
      "Epoch 279/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 509740.7188 - val_loss: 9755432.0000\n",
      "Epoch 280/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 504680.3125 - val_loss: 9678330.0000\n",
      "Epoch 281/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 499599.4688 - val_loss: 9624071.0000\n",
      "Epoch 282/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 494589.5625 - val_loss: 9557995.0000\n",
      "Epoch 283/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 489701.5312 - val_loss: 9487683.0000\n",
      "Epoch 284/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 484753.3125 - val_loss: 9416198.0000\n",
      "Epoch 285/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 479828.4062 - val_loss: 9356561.0000\n",
      "Epoch 286/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 475196.5938 - val_loss: 9289718.0000\n",
      "Epoch 287/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 470414.2500 - val_loss: 9220611.0000\n",
      "Epoch 288/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 465674.7188 - val_loss: 9162276.0000\n",
      "Epoch 289/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 6ms/step - loss: 461421.7500 - val_loss: 9107708.0000\n",
      "Epoch 290/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 456584.9062 - val_loss: 9046234.0000\n",
      "Epoch 291/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 452215.7188 - val_loss: 8980986.0000\n",
      "Epoch 292/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 447651.7500 - val_loss: 8920709.0000\n",
      "Epoch 293/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 443553.8750 - val_loss: 8862385.0000\n",
      "Epoch 294/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 438943.0312 - val_loss: 8797209.0000\n",
      "Epoch 295/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 434692.3438 - val_loss: 8742639.0000\n",
      "Epoch 296/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 430396.3750 - val_loss: 8690689.0000\n",
      "Epoch 297/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 426150.3438 - val_loss: 8630120.0000\n",
      "Epoch 298/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 422015.8125 - val_loss: 8570418.0000\n",
      "Epoch 299/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 418097.4375 - val_loss: 8504231.0000\n",
      "Epoch 300/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 413905.0000 - val_loss: 8450028.0000\n",
      "Epoch 301/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 409765.9375 - val_loss: 8388006.0000\n",
      "Epoch 302/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 405939.1875 - val_loss: 8331668.0000\n",
      "Epoch 303/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 402069.0625 - val_loss: 8275303.0000\n",
      "Epoch 304/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 398089.5312 - val_loss: 8229005.5000\n",
      "Epoch 305/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 394473.2188 - val_loss: 8165074.5000\n",
      "Epoch 306/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 390526.1875 - val_loss: 8115937.5000\n",
      "Epoch 307/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 386753.2188 - val_loss: 8057369.5000\n",
      "Epoch 308/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 383051.8750 - val_loss: 8003414.0000\n",
      "Epoch 309/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 379554.7812 - val_loss: 7950692.5000\n",
      "Epoch 310/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 375838.8750 - val_loss: 7907039.5000\n",
      "Epoch 311/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 372309.0938 - val_loss: 7852540.0000\n",
      "Epoch 312/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 368738.4375 - val_loss: 7803201.5000\n",
      "Epoch 313/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 365418.2188 - val_loss: 7748074.0000\n",
      "Epoch 314/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 361958.4375 - val_loss: 7693328.5000\n",
      "Epoch 315/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 358432.0000 - val_loss: 7639391.5000\n",
      "Epoch 316/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 355015.9688 - val_loss: 7593699.0000\n",
      "Epoch 317/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 351695.2188 - val_loss: 7550321.5000\n",
      "Epoch 318/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 348558.8125 - val_loss: 7496004.5000\n",
      "Epoch 319/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 345278.9375 - val_loss: 7443609.0000\n",
      "Epoch 320/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 342105.0625 - val_loss: 7392530.5000\n",
      "Epoch 321/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 338873.4375 - val_loss: 7345648.0000\n",
      "Epoch 322/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 335874.2812 - val_loss: 7302809.0000\n",
      "Epoch 323/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 332628.9375 - val_loss: 7250854.5000\n",
      "Epoch 324/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 329627.2500 - val_loss: 7204315.5000\n",
      "Epoch 325/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 326508.0938 - val_loss: 7157672.5000\n",
      "Epoch 326/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 323720.9688 - val_loss: 7117804.0000\n",
      "Epoch 327/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 320544.7188 - val_loss: 7068544.0000\n",
      "Epoch 328/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 317806.1250 - val_loss: 7020975.5000\n",
      "Epoch 329/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 315013.0938 - val_loss: 6970428.0000\n",
      "Epoch 330/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 312022.3750 - val_loss: 6928866.0000\n",
      "Epoch 331/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 309042.7500 - val_loss: 6884731.0000\n",
      "Epoch 332/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 306381.9688 - val_loss: 6846415.5000\n",
      "Epoch 333/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 303493.3125 - val_loss: 6803784.5000\n",
      "Epoch 334/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 300745.8438 - val_loss: 6762511.0000\n",
      "Epoch 335/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 298122.1250 - val_loss: 6715894.0000\n",
      "Epoch 336/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 295403.0625 - val_loss: 6674584.0000\n",
      "Epoch 337/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 292669.3125 - val_loss: 6632415.5000\n",
      "Epoch 338/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 290293.2188 - val_loss: 6586525.5000\n",
      "Epoch 339/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 287522.2500 - val_loss: 6543481.0000\n",
      "Epoch 340/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 284943.4062 - val_loss: 6500471.0000\n",
      "Epoch 341/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 282425.4062 - val_loss: 6462935.0000\n",
      "Epoch 342/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 279873.0000 - val_loss: 6420724.0000\n",
      "Epoch 343/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 277409.5312 - val_loss: 6381157.0000\n",
      "Epoch 344/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 274989.2812 - val_loss: 6339669.0000\n",
      "Epoch 345/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 272487.7188 - val_loss: 6304159.5000\n",
      "Epoch 346/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 270193.6875 - val_loss: 6262531.0000\n",
      "Epoch 347/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 267685.8750 - val_loss: 6227389.0000\n",
      "Epoch 348/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 265412.6562 - val_loss: 6187314.0000\n",
      "Epoch 349/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 263096.2500 - val_loss: 6149202.0000\n",
      "Epoch 350/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 260866.2656 - val_loss: 6114225.0000\n",
      "Epoch 351/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 258499.7812 - val_loss: 6072534.0000\n",
      "Epoch 352/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 256212.9062 - val_loss: 6033094.0000\n",
      "Epoch 353/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 253921.5625 - val_loss: 5998148.5000\n",
      "Epoch 354/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 251769.0469 - val_loss: 5961230.0000\n",
      "Epoch 355/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 249589.5625 - val_loss: 5924376.0000\n",
      "Epoch 356/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 247417.5156 - val_loss: 5883768.0000\n",
      "Epoch 357/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 245352.5938 - val_loss: 5841734.0000\n",
      "Epoch 358/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 243182.5938 - val_loss: 5814410.5000\n",
      "Epoch 359/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 241081.5000 - val_loss: 5778934.0000\n",
      "Epoch 360/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 239128.6406 - val_loss: 5740857.0000\n",
      "Epoch 361/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 236920.3438 - val_loss: 5706523.5000\n",
      "Epoch 362/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 235021.9062 - val_loss: 5670489.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 363/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 233200.7812 - val_loss: 5629930.0000\n",
      "Epoch 364/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 231002.3594 - val_loss: 5603685.5000\n",
      "Epoch 365/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 229067.2656 - val_loss: 5569123.5000\n",
      "Epoch 366/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 227091.2812 - val_loss: 5531275.5000\n",
      "Epoch 367/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 225219.7344 - val_loss: 5501921.5000\n",
      "Epoch 368/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 223324.8906 - val_loss: 5465196.5000\n",
      "Epoch 369/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 221485.5625 - val_loss: 5428631.0000\n",
      "Epoch 370/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 219547.4062 - val_loss: 5397137.5000\n",
      "Epoch 371/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 217712.5000 - val_loss: 5366038.5000\n",
      "Epoch 372/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 215867.0000 - val_loss: 5337140.5000\n",
      "Epoch 373/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 214188.0938 - val_loss: 5299613.0000\n",
      "Epoch 374/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 212420.3750 - val_loss: 5273840.0000\n",
      "Epoch 375/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 210551.5156 - val_loss: 5247122.0000\n",
      "Epoch 376/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 208934.0156 - val_loss: 5214605.5000\n",
      "Epoch 377/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 207180.0938 - val_loss: 5182627.5000\n",
      "Epoch 378/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 205585.9531 - val_loss: 5143841.5000\n",
      "Epoch 379/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 203702.2656 - val_loss: 5119116.5000\n",
      "Epoch 380/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 202064.9062 - val_loss: 5096431.5000\n",
      "Epoch 381/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 200484.9375 - val_loss: 5067783.5000\n",
      "Epoch 382/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 198791.5312 - val_loss: 5032656.5000\n",
      "Epoch 383/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 197220.1875 - val_loss: 5006785.0000\n",
      "Epoch 384/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 195600.4688 - val_loss: 4977436.5000\n",
      "Epoch 385/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 194097.4531 - val_loss: 4946609.5000\n",
      "Epoch 386/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 192418.8281 - val_loss: 4912877.0000\n",
      "Epoch 387/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 190883.8906 - val_loss: 4891988.0000\n",
      "Epoch 388/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 189385.9062 - val_loss: 4860576.5000\n",
      "Epoch 389/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 187965.4688 - val_loss: 4825335.5000\n",
      "Epoch 390/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 186494.4844 - val_loss: 4795798.0000\n",
      "Epoch 391/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 184888.3750 - val_loss: 4779183.5000\n",
      "Epoch 392/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 183450.1250 - val_loss: 4747864.0000\n",
      "Epoch 393/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 182029.6719 - val_loss: 4716273.5000\n",
      "Epoch 394/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 180469.1250 - val_loss: 4687341.0000\n",
      "Epoch 395/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 179129.0469 - val_loss: 4658494.5000\n",
      "Epoch 396/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 177643.9844 - val_loss: 4629664.5000\n",
      "Epoch 397/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 176253.5781 - val_loss: 4606807.0000\n",
      "Epoch 398/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 174828.1250 - val_loss: 4580749.0000\n",
      "Epoch 399/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 173474.4375 - val_loss: 4557897.5000\n",
      "Epoch 400/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 172085.3594 - val_loss: 4532853.5000\n",
      "Epoch 401/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 170733.5781 - val_loss: 4510719.0000\n",
      "Epoch 402/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 169443.8906 - val_loss: 4482950.5000\n",
      "Epoch 403/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 168109.8594 - val_loss: 4458357.5000\n",
      "Epoch 404/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 166753.8594 - val_loss: 4431875.5000\n",
      "Epoch 405/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 165583.7344 - val_loss: 4399319.0000\n",
      "Epoch 406/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 164269.7969 - val_loss: 4378690.5000\n",
      "Epoch 407/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 162985.3906 - val_loss: 4352078.0000\n",
      "Epoch 408/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 161724.7656 - val_loss: 4336793.5000\n",
      "Epoch 409/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 160492.1875 - val_loss: 4310283.0000\n",
      "Epoch 410/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 159214.2969 - val_loss: 4281437.5000\n",
      "Epoch 411/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 157991.1719 - val_loss: 4259490.5000\n",
      "Epoch 412/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 157008.1875 - val_loss: 4237336.5000\n",
      "Epoch 413/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 155580.4844 - val_loss: 4215225.5000\n",
      "Epoch 414/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 154405.0469 - val_loss: 4187096.7500\n",
      "Epoch 415/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 153227.8750 - val_loss: 4166313.5000\n",
      "Epoch 416/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 152069.5938 - val_loss: 4140500.7500\n",
      "Epoch 417/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 151040.3438 - val_loss: 4121734.2500\n",
      "Epoch 418/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 149789.6875 - val_loss: 4098780.0000\n",
      "Epoch 419/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 148612.0000 - val_loss: 4073141.0000\n",
      "Epoch 420/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 147572.4531 - val_loss: 4041949.7500\n",
      "Epoch 421/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 146416.7812 - val_loss: 4028883.2500\n",
      "Epoch 422/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 145242.0000 - val_loss: 4008747.0000\n",
      "Epoch 423/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 144224.3594 - val_loss: 3980742.0000\n",
      "Epoch 424/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 143096.5938 - val_loss: 3957571.2500\n",
      "Epoch 425/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 142021.9688 - val_loss: 3939727.5000\n",
      "Epoch 426/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 140944.3125 - val_loss: 3914538.0000\n",
      "Epoch 427/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 139879.0000 - val_loss: 3896969.2500\n",
      "Epoch 428/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 138931.0625 - val_loss: 3871646.5000\n",
      "Epoch 429/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 137764.7188 - val_loss: 3857564.7500\n",
      "Epoch 430/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 136740.8906 - val_loss: 3842407.2500\n",
      "Epoch 431/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 135686.2188 - val_loss: 3815975.2500\n",
      "Epoch 432/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 134693.8594 - val_loss: 3791120.2500\n",
      "Epoch 433/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 133734.8438 - val_loss: 3774064.7500\n",
      "Epoch 434/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 132690.4375 - val_loss: 3755271.0000\n",
      "Epoch 435/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 131738.7344 - val_loss: 3730405.5000\n",
      "Epoch 436/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 130739.0625 - val_loss: 3710662.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 437/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 129770.1172 - val_loss: 3688904.2500\n",
      "Epoch 438/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 128886.9141 - val_loss: 3669346.0000\n",
      "Epoch 439/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 127875.7578 - val_loss: 3656290.2500\n",
      "Epoch 440/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 126971.6094 - val_loss: 3632640.2500\n",
      "Epoch 441/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 126000.6875 - val_loss: 3613307.0000\n",
      "Epoch 442/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 125064.5469 - val_loss: 3595656.0000\n",
      "Epoch 443/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 124137.6797 - val_loss: 3579918.5000\n",
      "Epoch 444/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 123231.4766 - val_loss: 3560600.0000\n",
      "Epoch 445/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 122333.3750 - val_loss: 3539624.2500\n",
      "Epoch 446/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 121462.3359 - val_loss: 3520920.0000\n",
      "Epoch 447/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 120552.0234 - val_loss: 3499114.0000\n",
      "Epoch 448/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 119645.6484 - val_loss: 3482506.0000\n",
      "Epoch 449/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 118785.9844 - val_loss: 3467939.2500\n",
      "Epoch 450/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 117943.6328 - val_loss: 3443602.5000\n",
      "Epoch 451/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 117074.9297 - val_loss: 3425671.2500\n",
      "Epoch 452/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 116201.3516 - val_loss: 3407591.7500\n",
      "Epoch 453/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 115421.9531 - val_loss: 3387597.2500\n",
      "Epoch 454/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 114564.8984 - val_loss: 3370204.7500\n",
      "Epoch 455/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 113705.4219 - val_loss: 3359689.2500\n",
      "Epoch 456/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 112872.4375 - val_loss: 3341925.2500\n",
      "Epoch 457/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 112131.8516 - val_loss: 3328475.7500\n",
      "Epoch 458/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 111339.2969 - val_loss: 3306889.2500\n",
      "Epoch 459/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 110533.7188 - val_loss: 3284297.7500\n",
      "Epoch 460/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 109667.7500 - val_loss: 3269082.7500\n",
      "Epoch 461/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 108933.1953 - val_loss: 3255860.2500\n",
      "Epoch 462/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 108120.7812 - val_loss: 3241829.0000\n",
      "Epoch 463/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 107346.9844 - val_loss: 3222245.2500\n",
      "Epoch 464/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 106620.5234 - val_loss: 3203307.5000\n",
      "Epoch 465/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 105890.0469 - val_loss: 3184484.5000\n",
      "Epoch 466/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 105103.4922 - val_loss: 3169859.0000\n",
      "Epoch 467/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 104406.6406 - val_loss: 3151613.7500\n",
      "Epoch 468/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 103618.7656 - val_loss: 3138684.5000\n",
      "Epoch 469/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 102884.6094 - val_loss: 3126484.0000\n",
      "Epoch 470/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 102145.0625 - val_loss: 3113447.5000\n",
      "Epoch 471/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 101453.1250 - val_loss: 3096400.7500\n",
      "Epoch 472/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 100727.6016 - val_loss: 3082755.2500\n",
      "Epoch 473/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 100032.9141 - val_loss: 3061572.0000\n",
      "Epoch 474/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 99349.8984 - val_loss: 3047258.7500\n",
      "Epoch 475/2000\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 98583.0469 - val_loss: 3030174.5000\n",
      "Epoch 476/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 97920.7656 - val_loss: 3015060.7500\n",
      "Epoch 477/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 97275.7578 - val_loss: 2998974.0000\n",
      "Epoch 478/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 96561.9219 - val_loss: 2991362.2500\n",
      "Epoch 479/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 95931.4062 - val_loss: 2974483.2500\n",
      "Epoch 480/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 95302.0156 - val_loss: 2959316.0000\n",
      "Epoch 481/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 94619.5781 - val_loss: 2942690.2500\n",
      "Epoch 482/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 93943.9922 - val_loss: 2928750.7500\n",
      "Epoch 483/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 93302.4141 - val_loss: 2916136.2500\n",
      "Epoch 484/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 92644.3672 - val_loss: 2901182.7500\n",
      "Epoch 485/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 92032.5703 - val_loss: 2887000.5000\n",
      "Epoch 486/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 91406.6797 - val_loss: 2872257.7500\n",
      "Epoch 487/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 90781.1797 - val_loss: 2859216.7500\n",
      "Epoch 488/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 90109.4531 - val_loss: 2847993.7500\n",
      "Epoch 489/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 89541.8047 - val_loss: 2836890.2500\n",
      "Epoch 490/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 88944.4688 - val_loss: 2818073.0000\n",
      "Epoch 491/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 88323.5234 - val_loss: 2804964.5000\n",
      "Epoch 492/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 87673.4219 - val_loss: 2793197.0000\n",
      "Epoch 493/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 87132.9531 - val_loss: 2777660.0000\n",
      "Epoch 494/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 86534.8750 - val_loss: 2765534.0000\n",
      "Epoch 495/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 85910.0938 - val_loss: 2755235.2500\n",
      "Epoch 496/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 85318.0703 - val_loss: 2742270.5000\n",
      "Epoch 497/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 84751.4844 - val_loss: 2731899.7500\n",
      "Epoch 498/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 84214.0469 - val_loss: 2712227.7500\n",
      "Epoch 499/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 83617.4062 - val_loss: 2699751.5000\n",
      "Epoch 500/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 83044.2500 - val_loss: 2685546.0000\n",
      "Epoch 501/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 82458.3203 - val_loss: 2672437.0000\n",
      "Epoch 502/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 81890.9062 - val_loss: 2665376.0000\n",
      "Epoch 503/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 81367.2578 - val_loss: 2652612.5000\n",
      "Epoch 504/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 80860.9609 - val_loss: 2643380.7500\n",
      "Epoch 505/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 80298.1250 - val_loss: 2631276.5000\n",
      "Epoch 506/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 79767.3047 - val_loss: 2614213.5000\n",
      "Epoch 507/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 79124.7344 - val_loss: 2602880.5000\n",
      "Epoch 508/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 78733.6094 - val_loss: 2587236.2500\n",
      "Epoch 509/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 78122.1172 - val_loss: 2580271.7500\n",
      "Epoch 510/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 77603.1562 - val_loss: 2569436.0000\n",
      "Epoch 511/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 8ms/step - loss: 77090.1016 - val_loss: 2554944.0000\n",
      "Epoch 512/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 76575.8047 - val_loss: 2541250.5000\n",
      "Epoch 513/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 76043.5078 - val_loss: 2531508.2500\n",
      "Epoch 514/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 75535.4141 - val_loss: 2523193.0000\n",
      "Epoch 515/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 75052.8672 - val_loss: 2510267.7500\n",
      "Epoch 516/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 74555.7188 - val_loss: 2500254.7500\n",
      "Epoch 517/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 74022.1719 - val_loss: 2488368.7500\n",
      "Epoch 518/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 73567.0781 - val_loss: 2473176.0000\n",
      "Epoch 519/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 73117.9219 - val_loss: 2461669.2500\n",
      "Epoch 520/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 72592.5938 - val_loss: 2455381.2500\n",
      "Epoch 521/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 72097.2812 - val_loss: 2447263.2500\n",
      "Epoch 522/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 71583.4766 - val_loss: 2432569.2500\n",
      "Epoch 523/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 71132.5547 - val_loss: 2419996.7500\n",
      "Epoch 524/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 70651.9453 - val_loss: 2404889.7500\n",
      "Epoch 525/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 70206.8125 - val_loss: 2394164.2500\n",
      "Epoch 526/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 69712.8359 - val_loss: 2386477.0000\n",
      "Epoch 527/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 69260.1797 - val_loss: 2377622.0000\n",
      "Epoch 528/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 68783.5078 - val_loss: 2367562.7500\n",
      "Epoch 529/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 68347.6172 - val_loss: 2357430.7500\n",
      "Epoch 530/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 67893.0234 - val_loss: 2346197.0000\n",
      "Epoch 531/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 67436.1016 - val_loss: 2335407.7500\n",
      "Epoch 532/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 67017.1016 - val_loss: 2326504.7500\n",
      "Epoch 533/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 66649.2422 - val_loss: 2308947.0000\n",
      "Epoch 534/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 66196.1562 - val_loss: 2308010.0000\n",
      "Epoch 535/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 65737.0469 - val_loss: 2295077.0000\n",
      "Epoch 536/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 65277.5664 - val_loss: 2283925.0000\n",
      "Epoch 537/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 64833.6680 - val_loss: 2271887.2500\n",
      "Epoch 538/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 64407.1914 - val_loss: 2264677.2500\n",
      "Epoch 539/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 63986.7148 - val_loss: 2255844.5000\n",
      "Epoch 540/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 63649.7109 - val_loss: 2245095.2500\n",
      "Epoch 541/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 63193.3047 - val_loss: 2234372.7500\n",
      "Epoch 542/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 62780.2539 - val_loss: 2226813.5000\n",
      "Epoch 543/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 62362.4453 - val_loss: 2217629.2500\n",
      "Epoch 544/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 61958.3672 - val_loss: 2207943.7500\n",
      "Epoch 545/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 61506.3047 - val_loss: 2197694.7500\n",
      "Epoch 546/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 61211.8555 - val_loss: 2189945.5000\n",
      "Epoch 547/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 60795.6680 - val_loss: 2178510.5000\n",
      "Epoch 548/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 60383.0664 - val_loss: 2165977.0000\n",
      "Epoch 549/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 59991.8633 - val_loss: 2160352.0000\n",
      "Epoch 550/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 59559.6367 - val_loss: 2150672.5000\n",
      "Epoch 551/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 59193.3789 - val_loss: 2145291.2500\n",
      "Epoch 552/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 58831.8477 - val_loss: 2133652.0000\n",
      "Epoch 553/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 58412.7500 - val_loss: 2124646.7500\n",
      "Epoch 554/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 58062.2500 - val_loss: 2120206.5000\n",
      "Epoch 555/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 57748.8594 - val_loss: 2109531.7500\n",
      "Epoch 556/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 57309.0898 - val_loss: 2094212.0000\n",
      "Epoch 557/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 56978.0938 - val_loss: 2089478.6250\n",
      "Epoch 558/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 56577.5938 - val_loss: 2079798.5000\n",
      "Epoch 559/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 56252.5469 - val_loss: 2075560.8750\n",
      "Epoch 560/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 55900.5430 - val_loss: 2064460.1250\n",
      "Epoch 561/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 55573.1406 - val_loss: 2052842.3750\n",
      "Epoch 562/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 55176.4492 - val_loss: 2047450.0000\n",
      "Epoch 563/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 54796.4922 - val_loss: 2039594.3750\n",
      "Epoch 564/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 54502.8789 - val_loss: 2029712.8750\n",
      "Epoch 565/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 54126.4688 - val_loss: 2020918.0000\n",
      "Epoch 566/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 53799.0234 - val_loss: 2018313.2500\n",
      "Epoch 567/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 53384.4336 - val_loss: 2009300.0000\n",
      "Epoch 568/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 53082.8008 - val_loss: 1995919.1250\n",
      "Epoch 569/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 52781.2461 - val_loss: 1987972.1250\n",
      "Epoch 570/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 52423.5430 - val_loss: 1986624.7500\n",
      "Epoch 571/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 52153.8555 - val_loss: 1973827.5000\n",
      "Epoch 572/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 51797.3750 - val_loss: 1969927.3750\n",
      "Epoch 573/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 51465.7070 - val_loss: 1957431.1250\n",
      "Epoch 574/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 51053.9492 - val_loss: 1950214.8750\n",
      "Epoch 575/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 50800.7539 - val_loss: 1944877.0000\n",
      "Epoch 576/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 50464.6484 - val_loss: 1935736.2500\n",
      "Epoch 577/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 50121.3945 - val_loss: 1929624.2500\n",
      "Epoch 578/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 49826.0039 - val_loss: 1919521.8750\n",
      "Epoch 579/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 49506.1133 - val_loss: 1914990.5000\n",
      "Epoch 580/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 49161.1367 - val_loss: 1907157.7500\n",
      "Epoch 581/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 48862.2344 - val_loss: 1899440.0000\n",
      "Epoch 582/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 48524.7617 - val_loss: 1890653.3750\n",
      "Epoch 583/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 48257.8359 - val_loss: 1882007.6250\n",
      "Epoch 584/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 47957.9062 - val_loss: 1873513.3750\n",
      "Epoch 585/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 47696.1758 - val_loss: 1866049.0000\n",
      "Epoch 586/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 47347.2461 - val_loss: 1861234.5000\n",
      "Epoch 587/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 47080.9062 - val_loss: 1858232.6250\n",
      "Epoch 588/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 46768.5508 - val_loss: 1845085.7500\n",
      "Epoch 589/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 46482.4180 - val_loss: 1839721.2500\n",
      "Epoch 590/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 46181.6367 - val_loss: 1835639.5000\n",
      "Epoch 591/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 45883.6289 - val_loss: 1826816.7500\n",
      "Epoch 592/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 45587.8828 - val_loss: 1818306.0000\n",
      "Epoch 593/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 45375.5469 - val_loss: 1812159.7500\n",
      "Epoch 594/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 45022.4531 - val_loss: 1802818.0000\n",
      "Epoch 595/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 44711.0312 - val_loss: 1798862.2500\n",
      "Epoch 596/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 44441.2891 - val_loss: 1789490.1250\n",
      "Epoch 597/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 44172.4492 - val_loss: 1785683.1250\n",
      "Epoch 598/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 43898.7227 - val_loss: 1778951.1250\n",
      "Epoch 599/2000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 43654.5039 - val_loss: 1768573.2500\n",
      "Epoch 600/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 43385.9531 - val_loss: 1763854.0000\n",
      "Epoch 601/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 43092.2109 - val_loss: 1761219.5000\n",
      "Epoch 602/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 42821.8672 - val_loss: 1756243.6250\n",
      "Epoch 603/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 42547.0977 - val_loss: 1744099.1250\n",
      "Epoch 604/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 42262.2188 - val_loss: 1737778.5000\n",
      "Epoch 605/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 41997.5430 - val_loss: 1728012.1250\n",
      "Epoch 606/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 41757.7148 - val_loss: 1728504.3750\n",
      "Epoch 607/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 41479.9375 - val_loss: 1719592.1250\n",
      "Epoch 608/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 41226.8633 - val_loss: 1712080.3750\n",
      "Epoch 609/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 40959.9609 - val_loss: 1704545.0000\n",
      "Epoch 610/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 40690.6641 - val_loss: 1699447.2500\n",
      "Epoch 611/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 40460.9023 - val_loss: 1693017.6250\n",
      "Epoch 612/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 40213.6875 - val_loss: 1689983.8750\n",
      "Epoch 613/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 39970.0273 - val_loss: 1684622.8750\n",
      "Epoch 614/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 39743.6172 - val_loss: 1674460.3750\n",
      "Epoch 615/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 39473.1602 - val_loss: 1671841.8750\n",
      "Epoch 616/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 39239.7266 - val_loss: 1661940.3750\n",
      "Epoch 617/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 38985.5195 - val_loss: 1656682.7500\n",
      "Epoch 618/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 38751.7891 - val_loss: 1645289.6250\n",
      "Epoch 619/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 38516.6758 - val_loss: 1643748.6250\n",
      "Epoch 620/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 38248.7227 - val_loss: 1637366.2500\n",
      "Epoch 621/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 38002.2227 - val_loss: 1635233.6250\n",
      "Epoch 622/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 37758.1836 - val_loss: 1628495.2500\n",
      "Epoch 623/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 37560.3477 - val_loss: 1619444.0000\n",
      "Epoch 624/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 37308.8828 - val_loss: 1615870.3750\n",
      "Epoch 625/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 37089.1602 - val_loss: 1613645.0000\n",
      "Epoch 626/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 36844.8359 - val_loss: 1604616.5000\n",
      "Epoch 627/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 36659.5625 - val_loss: 1601205.5000\n",
      "Epoch 628/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 36383.4219 - val_loss: 1592484.7500\n",
      "Epoch 629/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 36187.2344 - val_loss: 1589699.0000\n",
      "Epoch 630/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 35944.8477 - val_loss: 1585212.1250\n",
      "Epoch 631/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 35756.4219 - val_loss: 1571889.8750\n",
      "Epoch 632/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 35503.0664 - val_loss: 1571076.0000\n",
      "Epoch 633/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 35261.1758 - val_loss: 1566077.0000\n",
      "Epoch 634/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 35063.8672 - val_loss: 1563596.3750\n",
      "Epoch 635/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 34847.5156 - val_loss: 1555419.8750\n",
      "Epoch 636/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 34595.5898 - val_loss: 1548349.1250\n",
      "Epoch 637/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 34386.4844 - val_loss: 1544268.6250\n",
      "Epoch 638/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 34197.6406 - val_loss: 1541089.0000\n",
      "Epoch 639/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 33970.1484 - val_loss: 1536873.7500\n",
      "Epoch 640/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 33734.1172 - val_loss: 1529304.3750\n",
      "Epoch 641/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 33629.2773 - val_loss: 1525150.2500\n",
      "Epoch 642/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 33344.9453 - val_loss: 1518283.6250\n",
      "Epoch 643/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 33215.0078 - val_loss: 1514987.8750\n",
      "Epoch 644/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 32914.3320 - val_loss: 1507312.7500\n",
      "Epoch 645/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 32713.4805 - val_loss: 1502323.0000\n",
      "Epoch 646/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 32553.4727 - val_loss: 1496738.1250\n",
      "Epoch 647/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 32342.4844 - val_loss: 1497831.3750\n",
      "Epoch 648/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 32121.6465 - val_loss: 1489386.5000\n",
      "Epoch 649/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 31948.6387 - val_loss: 1480058.5000\n",
      "Epoch 650/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 31767.0000 - val_loss: 1482743.8750\n",
      "Epoch 651/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 31544.7090 - val_loss: 1476231.3750\n",
      "Epoch 652/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 31301.8613 - val_loss: 1466279.1250\n",
      "Epoch 653/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 31191.1836 - val_loss: 1460839.5000\n",
      "Epoch 654/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 30955.7227 - val_loss: 1462292.8750\n",
      "Epoch 655/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 30755.6621 - val_loss: 1457174.3750\n",
      "Epoch 656/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 30567.7051 - val_loss: 1451814.7500\n",
      "Epoch 657/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 30403.7910 - val_loss: 1442708.0000\n",
      "Epoch 658/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 30160.7422 - val_loss: 1440827.6250\n",
      "Epoch 659/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 7ms/step - loss: 30016.5312 - val_loss: 1440463.0000\n",
      "Epoch 660/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 29798.3711 - val_loss: 1434784.0000\n",
      "Epoch 661/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 29609.3691 - val_loss: 1429284.1250\n",
      "Epoch 662/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 29465.7422 - val_loss: 1420234.3750\n",
      "Epoch 663/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 29284.6523 - val_loss: 1417107.5000\n",
      "Epoch 664/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 29099.8672 - val_loss: 1417704.1250\n",
      "Epoch 665/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 28884.4609 - val_loss: 1411719.6250\n",
      "Epoch 666/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 28713.8965 - val_loss: 1405085.1250\n",
      "Epoch 667/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 28546.3047 - val_loss: 1400056.8750\n",
      "Epoch 668/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 28355.5684 - val_loss: 1396727.2500\n",
      "Epoch 669/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 28218.9375 - val_loss: 1396559.1250\n",
      "Epoch 670/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 28033.4023 - val_loss: 1384580.7500\n",
      "Epoch 671/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 27837.7832 - val_loss: 1383656.6250\n",
      "Epoch 672/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 27674.3008 - val_loss: 1380605.7500\n",
      "Epoch 673/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 27495.7305 - val_loss: 1373783.7500\n",
      "Epoch 674/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 27310.9375 - val_loss: 1370719.1250\n",
      "Epoch 675/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 27128.6387 - val_loss: 1367505.5000\n",
      "Epoch 676/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 26988.6484 - val_loss: 1367699.1250\n",
      "Epoch 677/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 26804.4121 - val_loss: 1359812.8750\n",
      "Epoch 678/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 26691.6738 - val_loss: 1354481.7500\n",
      "Epoch 679/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 26496.0957 - val_loss: 1350085.3750\n",
      "Epoch 680/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 26326.1914 - val_loss: 1347272.6250\n",
      "Epoch 681/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 26141.1172 - val_loss: 1344953.7500\n",
      "Epoch 682/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 25971.5898 - val_loss: 1337702.2500\n",
      "Epoch 683/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 25884.7188 - val_loss: 1333745.0000\n",
      "Epoch 684/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 25653.5234 - val_loss: 1334632.1250\n",
      "Epoch 685/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 25525.2539 - val_loss: 1330830.1250\n",
      "Epoch 686/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 25340.1465 - val_loss: 1320904.1250\n",
      "Epoch 687/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 25204.1113 - val_loss: 1317020.1250\n",
      "Epoch 688/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 25043.2402 - val_loss: 1316720.0000\n",
      "Epoch 689/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 24865.3809 - val_loss: 1312811.1250\n",
      "Epoch 690/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 24723.1484 - val_loss: 1305824.2500\n",
      "Epoch 691/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 24555.0957 - val_loss: 1306269.5000\n",
      "Epoch 692/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 24430.2305 - val_loss: 1304267.8750\n",
      "Epoch 693/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 24277.6387 - val_loss: 1294135.8750\n",
      "Epoch 694/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 24131.9941 - val_loss: 1293257.6250\n",
      "Epoch 695/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 23933.0332 - val_loss: 1291129.5000\n",
      "Epoch 696/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 23825.3262 - val_loss: 1286285.5000\n",
      "Epoch 697/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 23662.3535 - val_loss: 1279604.3750\n",
      "Epoch 698/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 23497.8047 - val_loss: 1279331.0000\n",
      "Epoch 699/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 23358.6992 - val_loss: 1276247.6250\n",
      "Epoch 700/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 23206.2188 - val_loss: 1271891.7500\n",
      "Epoch 701/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 23082.0879 - val_loss: 1268151.6250\n",
      "Epoch 702/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 22923.3242 - val_loss: 1263899.5000\n",
      "Epoch 703/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 22792.4434 - val_loss: 1258763.8750\n",
      "Epoch 704/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 22648.6914 - val_loss: 1257789.7500\n",
      "Epoch 705/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 22522.1582 - val_loss: 1256588.0000\n",
      "Epoch 706/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 22374.4043 - val_loss: 1251658.0000\n",
      "Epoch 707/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 22243.9336 - val_loss: 1244113.7500\n",
      "Epoch 708/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 22109.7305 - val_loss: 1247291.5000\n",
      "Epoch 709/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 21970.1094 - val_loss: 1240493.1250\n",
      "Epoch 710/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 21821.8203 - val_loss: 1235372.2500\n",
      "Epoch 711/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 21693.5547 - val_loss: 1236810.0000\n",
      "Epoch 712/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 21513.8848 - val_loss: 1227863.1250\n",
      "Epoch 713/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 21406.0469 - val_loss: 1228342.6250\n",
      "Epoch 714/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 21250.9434 - val_loss: 1221493.2500\n",
      "Epoch 715/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 21121.5488 - val_loss: 1220114.7500\n",
      "Epoch 716/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 21002.8281 - val_loss: 1217266.1250\n",
      "Epoch 717/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 20841.4297 - val_loss: 1214482.8750\n",
      "Epoch 718/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 20746.4824 - val_loss: 1211587.1250\n",
      "Epoch 719/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 20592.1602 - val_loss: 1207824.3750\n",
      "Epoch 720/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 20451.0527 - val_loss: 1204058.6250\n",
      "Epoch 721/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 20331.6543 - val_loss: 1200147.0000\n",
      "Epoch 722/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 20214.9277 - val_loss: 1198059.5000\n",
      "Epoch 723/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 20108.6113 - val_loss: 1194820.8750\n",
      "Epoch 724/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 19950.4512 - val_loss: 1191181.6250\n",
      "Epoch 725/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 19810.0039 - val_loss: 1189188.2500\n",
      "Epoch 726/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 19711.5527 - val_loss: 1183301.6250\n",
      "Epoch 727/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 19583.2168 - val_loss: 1179253.0000\n",
      "Epoch 728/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 19441.7227 - val_loss: 1179530.7500\n",
      "Epoch 729/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 19316.0742 - val_loss: 1174936.2500\n",
      "Epoch 730/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 19191.9961 - val_loss: 1174083.6250\n",
      "Epoch 731/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 19064.9102 - val_loss: 1168252.6250\n",
      "Epoch 732/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 18956.4414 - val_loss: 1165406.1250\n",
      "Epoch 733/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 18861.4160 - val_loss: 1161844.5000\n",
      "Epoch 734/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 18735.0293 - val_loss: 1159357.6250\n",
      "Epoch 735/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 18596.8535 - val_loss: 1156392.1250\n",
      "Epoch 736/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 18464.2363 - val_loss: 1154255.1250\n",
      "Epoch 737/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 18391.0703 - val_loss: 1149705.1250\n",
      "Epoch 738/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 18227.3418 - val_loss: 1148586.5000\n",
      "Epoch 739/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 18159.7656 - val_loss: 1144883.1250\n",
      "Epoch 740/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 18026.6348 - val_loss: 1142970.7500\n",
      "Epoch 741/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 17888.3203 - val_loss: 1135101.8750\n",
      "Epoch 742/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 17799.7344 - val_loss: 1135252.6250\n",
      "Epoch 743/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 17643.0254 - val_loss: 1134458.6250\n",
      "Epoch 744/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 17600.5234 - val_loss: 1131836.2500\n",
      "Epoch 745/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 17431.8457 - val_loss: 1123536.3750\n",
      "Epoch 746/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 17313.0215 - val_loss: 1124458.2500\n",
      "Epoch 747/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 17204.7188 - val_loss: 1123162.5000\n",
      "Epoch 748/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 17099.8887 - val_loss: 1117403.1250\n",
      "Epoch 749/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 16988.0586 - val_loss: 1113229.8750\n",
      "Epoch 750/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 16885.8848 - val_loss: 1110998.3750\n",
      "Epoch 751/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 16783.6367 - val_loss: 1110418.5000\n",
      "Epoch 752/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 16667.4375 - val_loss: 1107133.8750\n",
      "Epoch 753/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 16572.8633 - val_loss: 1104540.2500\n",
      "Epoch 754/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 16510.5039 - val_loss: 1099344.2500\n",
      "Epoch 755/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 16370.6582 - val_loss: 1101120.1250\n",
      "Epoch 756/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 16245.3350 - val_loss: 1093559.1250\n",
      "Epoch 757/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 16141.5986 - val_loss: 1092211.0000\n",
      "Epoch 758/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 16044.8008 - val_loss: 1091115.3750\n",
      "Epoch 759/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 15915.5127 - val_loss: 1087734.3750\n",
      "Epoch 760/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 15878.3711 - val_loss: 1082373.3750\n",
      "Epoch 761/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 15745.1270 - val_loss: 1081774.1250\n",
      "Epoch 762/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 15655.3564 - val_loss: 1081330.0000\n",
      "Epoch 763/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 15517.4424 - val_loss: 1077203.6250\n",
      "Epoch 764/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 15428.2051 - val_loss: 1075375.3750\n",
      "Epoch 765/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 15327.4727 - val_loss: 1072936.8750\n",
      "Epoch 766/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 15234.0361 - val_loss: 1066750.2500\n",
      "Epoch 767/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 15128.0410 - val_loss: 1068812.7500\n",
      "Epoch 768/2000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 15030.6270 - val_loss: 1061216.6250\n",
      "Epoch 769/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 14922.2773 - val_loss: 1061603.8750\n",
      "Epoch 770/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 14841.8291 - val_loss: 1061163.8750\n",
      "Epoch 771/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 14715.0156 - val_loss: 1055248.3750\n",
      "Epoch 772/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 14665.7949 - val_loss: 1053723.5000\n",
      "Epoch 773/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 14575.8477 - val_loss: 1051084.8750\n",
      "Epoch 774/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 14483.1738 - val_loss: 1052337.5000\n",
      "Epoch 775/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 14367.2148 - val_loss: 1045330.6875\n",
      "Epoch 776/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 14243.1787 - val_loss: 1043782.3125\n",
      "Epoch 777/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 14162.2266 - val_loss: 1042844.6875\n",
      "Epoch 778/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 14074.4453 - val_loss: 1038743.0625\n",
      "Epoch 779/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 13972.7959 - val_loss: 1034403.9375\n",
      "Epoch 780/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 13876.8623 - val_loss: 1033965.2500\n",
      "Epoch 781/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 13804.9580 - val_loss: 1031292.8750\n",
      "Epoch 782/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 13696.7090 - val_loss: 1028394.8125\n",
      "Epoch 783/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 13582.2451 - val_loss: 1024320.3125\n",
      "Epoch 784/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 13555.0615 - val_loss: 1027552.6250\n",
      "Epoch 785/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 13426.2168 - val_loss: 1022588.2500\n",
      "Epoch 786/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 13342.5713 - val_loss: 1018412.0625\n",
      "Epoch 787/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 13298.1445 - val_loss: 1016228.3125\n",
      "Epoch 788/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 13215.2920 - val_loss: 1017031.3750\n",
      "Epoch 789/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 13072.9424 - val_loss: 1013194.9375\n",
      "Epoch 790/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 12983.2734 - val_loss: 1010936.5625\n",
      "Epoch 791/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 12887.2920 - val_loss: 1008318.7500\n",
      "Epoch 792/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 12803.5830 - val_loss: 1005514.3125\n",
      "Epoch 793/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 12753.8125 - val_loss: 1002678.0000\n",
      "Epoch 794/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 12657.3193 - val_loss: 1001707.8125\n",
      "Epoch 795/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 12568.2783 - val_loss: 1002692.6250\n",
      "Epoch 796/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 12471.5088 - val_loss: 998380.3750\n",
      "Epoch 797/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 12414.0234 - val_loss: 991244.3125\n",
      "Epoch 798/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 12319.6270 - val_loss: 993918.1875\n",
      "Epoch 799/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 12245.7871 - val_loss: 991661.1250\n",
      "Epoch 800/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 12176.7998 - val_loss: 983873.8750\n",
      "Epoch 801/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 12078.0449 - val_loss: 989212.8125\n",
      "Epoch 802/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 12023.8203 - val_loss: 983071.8125\n",
      "Epoch 803/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 11965.5439 - val_loss: 984639.6875\n",
      "Epoch 804/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 11854.0986 - val_loss: 984383.8125\n",
      "Epoch 805/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 11752.4756 - val_loss: 976162.8125\n",
      "Epoch 806/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 11688.4209 - val_loss: 973513.8750\n",
      "Epoch 807/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 7ms/step - loss: 11610.8457 - val_loss: 976857.0625\n",
      "Epoch 808/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 11518.7295 - val_loss: 972595.4375\n",
      "Epoch 809/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 11436.4561 - val_loss: 968148.2500\n",
      "Epoch 810/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 11344.5361 - val_loss: 967135.9375\n",
      "Epoch 811/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 11267.7627 - val_loss: 965122.5000\n",
      "Epoch 812/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 11221.4121 - val_loss: 962612.3125\n",
      "Epoch 813/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 11123.5703 - val_loss: 961041.7500\n",
      "Epoch 814/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 11033.4297 - val_loss: 958338.2500\n",
      "Epoch 815/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 10978.7207 - val_loss: 960055.5625\n",
      "Epoch 816/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 10896.3232 - val_loss: 954455.3750\n",
      "Epoch 817/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 10813.3330 - val_loss: 954565.3750\n",
      "Epoch 818/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 10749.2686 - val_loss: 952204.3125\n",
      "Epoch 819/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 10686.0195 - val_loss: 951655.4375\n",
      "Epoch 820/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 10593.5615 - val_loss: 946056.8750\n",
      "Epoch 821/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 10519.4541 - val_loss: 943425.8750\n",
      "Epoch 822/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 10465.2949 - val_loss: 943226.7500\n",
      "Epoch 823/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 10382.9785 - val_loss: 941068.4375\n",
      "Epoch 824/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 10328.8848 - val_loss: 941154.6875\n",
      "Epoch 825/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 10261.3545 - val_loss: 941221.5625\n",
      "Epoch 826/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 10207.8428 - val_loss: 934128.5625\n",
      "Epoch 827/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 10107.6807 - val_loss: 933606.8750\n",
      "Epoch 828/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 10032.0684 - val_loss: 934152.5625\n",
      "Epoch 829/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 9978.0283 - val_loss: 927787.3125\n",
      "Epoch 830/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 9896.1016 - val_loss: 928800.9375\n",
      "Epoch 831/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 9842.4873 - val_loss: 927965.5625\n",
      "Epoch 832/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 9796.0586 - val_loss: 923080.5000\n",
      "Epoch 833/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 9701.0596 - val_loss: 925259.1875\n",
      "Epoch 834/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 9659.2266 - val_loss: 922306.4375\n",
      "Epoch 835/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 9567.4277 - val_loss: 917295.3750\n",
      "Epoch 836/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 9511.0283 - val_loss: 919428.0625\n",
      "Epoch 837/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 9445.5410 - val_loss: 914943.5000\n",
      "Epoch 838/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 9399.5244 - val_loss: 915785.5625\n",
      "Epoch 839/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 9313.7979 - val_loss: 911447.5000\n",
      "Epoch 840/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 9256.6162 - val_loss: 909566.5000\n",
      "Epoch 841/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 9194.3574 - val_loss: 908851.3125\n",
      "Epoch 842/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 9136.0527 - val_loss: 906599.1875\n",
      "Epoch 843/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 9057.4541 - val_loss: 906975.6250\n",
      "Epoch 844/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 8991.2422 - val_loss: 903798.1875\n",
      "Epoch 845/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 8943.9189 - val_loss: 901713.0000\n",
      "Epoch 846/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 8851.8691 - val_loss: 898065.7500\n",
      "Epoch 847/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 8831.8223 - val_loss: 900024.0625\n",
      "Epoch 848/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 8753.1084 - val_loss: 894656.6250\n",
      "Epoch 849/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 8690.3262 - val_loss: 895935.5625\n",
      "Epoch 850/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 8616.4170 - val_loss: 893164.7500\n",
      "Epoch 851/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 8553.9521 - val_loss: 891629.1250\n",
      "Epoch 852/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 8510.2861 - val_loss: 890350.0000\n",
      "Epoch 853/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 8454.3164 - val_loss: 890613.9375\n",
      "Epoch 854/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 8395.6484 - val_loss: 884592.1875\n",
      "Epoch 855/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 8377.2363 - val_loss: 888866.8125\n",
      "Epoch 856/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 8283.9775 - val_loss: 880507.9375\n",
      "Epoch 857/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 8195.9814 - val_loss: 883112.5625\n",
      "Epoch 858/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 8180.6865 - val_loss: 878144.9375\n",
      "Epoch 859/2000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 8092.8140 - val_loss: 881793.2500\n",
      "Epoch 860/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 8040.8364 - val_loss: 875935.5000\n",
      "Epoch 861/2000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 7975.3618 - val_loss: 876364.1250\n",
      "Epoch 862/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 7938.0029 - val_loss: 873139.3750\n",
      "Epoch 863/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 7894.9141 - val_loss: 873246.4375\n",
      "Epoch 864/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 7811.9077 - val_loss: 871337.4375\n",
      "Epoch 865/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 7743.1616 - val_loss: 867520.1250\n",
      "Epoch 866/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 7675.5542 - val_loss: 868485.1875\n",
      "Epoch 867/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 7637.3389 - val_loss: 866999.9375\n",
      "Epoch 868/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 7590.3574 - val_loss: 864254.2500\n",
      "Epoch 869/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 7529.1001 - val_loss: 862832.1250\n",
      "Epoch 870/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 7482.3403 - val_loss: 860014.1875\n",
      "Epoch 871/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 7409.8208 - val_loss: 861804.4375\n",
      "Epoch 872/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 7376.8687 - val_loss: 860501.1875\n",
      "Epoch 873/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 7284.6699 - val_loss: 857599.9375\n",
      "Epoch 874/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 7258.0771 - val_loss: 854494.1250\n",
      "Epoch 875/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 7202.1577 - val_loss: 853859.1250\n",
      "Epoch 876/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 7160.1538 - val_loss: 853246.4375\n",
      "Epoch 877/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 7095.0859 - val_loss: 851395.0000\n",
      "Epoch 878/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 7072.1260 - val_loss: 849467.1875\n",
      "Epoch 879/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 7022.2295 - val_loss: 845303.6875\n",
      "Epoch 880/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 7014.1333 - val_loss: 848297.0000\n",
      "Epoch 881/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 6903.9829 - val_loss: 844594.8125\n",
      "Epoch 882/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 6868.1499 - val_loss: 844289.3750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 883/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 6797.7363 - val_loss: 840177.0000\n",
      "Epoch 884/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 6739.1792 - val_loss: 838474.5000\n",
      "Epoch 885/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 6696.3271 - val_loss: 840292.3125\n",
      "Epoch 886/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 6637.1040 - val_loss: 836212.5625\n",
      "Epoch 887/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 6604.5610 - val_loss: 834596.1250\n",
      "Epoch 888/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 6575.4990 - val_loss: 835824.3750\n",
      "Epoch 889/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 6545.6504 - val_loss: 831924.3750\n",
      "Epoch 890/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 6467.9692 - val_loss: 834735.6875\n",
      "Epoch 891/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 6405.1108 - val_loss: 830502.6875\n",
      "Epoch 892/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 6372.0679 - val_loss: 828315.0000\n",
      "Epoch 893/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 6314.1177 - val_loss: 829527.5000\n",
      "Epoch 894/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 6301.6226 - val_loss: 826381.6875\n",
      "Epoch 895/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 6235.5371 - val_loss: 826193.8125\n",
      "Epoch 896/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 6164.3486 - val_loss: 825595.1250\n",
      "Epoch 897/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 6141.0405 - val_loss: 822425.2500\n",
      "Epoch 898/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 6052.8999 - val_loss: 822871.6250\n",
      "Epoch 899/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 6041.7959 - val_loss: 819445.0625\n",
      "Epoch 900/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 6004.5361 - val_loss: 820707.3750\n",
      "Epoch 901/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 5968.1929 - val_loss: 814694.4375\n",
      "Epoch 902/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 5904.8999 - val_loss: 816765.1875\n",
      "Epoch 903/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 5844.6670 - val_loss: 815362.8125\n",
      "Epoch 904/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 5818.4189 - val_loss: 813874.8750\n",
      "Epoch 905/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 5786.1382 - val_loss: 814967.1250\n",
      "Epoch 906/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 5745.8892 - val_loss: 810406.7500\n",
      "Epoch 907/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 5675.3950 - val_loss: 811384.8125\n",
      "Epoch 908/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 5625.3511 - val_loss: 805756.0625\n",
      "Epoch 909/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 5580.6562 - val_loss: 806747.3750\n",
      "Epoch 910/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 5541.2578 - val_loss: 805711.6250\n",
      "Epoch 911/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 5501.7500 - val_loss: 805752.5000\n",
      "Epoch 912/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 5469.6035 - val_loss: 801345.3750\n",
      "Epoch 913/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 5414.3320 - val_loss: 805193.8750\n",
      "Epoch 914/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 5368.3823 - val_loss: 800841.5000\n",
      "Epoch 915/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 5326.5815 - val_loss: 799088.0625\n",
      "Epoch 916/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 5291.5522 - val_loss: 798301.9375\n",
      "Epoch 917/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 5250.9614 - val_loss: 796096.1875\n",
      "Epoch 918/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 5232.5962 - val_loss: 797482.7500\n",
      "Epoch 919/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 5168.1187 - val_loss: 793474.7500\n",
      "Epoch 920/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 5157.2012 - val_loss: 795819.8750\n",
      "Epoch 921/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 5092.7095 - val_loss: 790669.0000\n",
      "Epoch 922/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 5047.1401 - val_loss: 790250.6250\n",
      "Epoch 923/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 5035.6416 - val_loss: 789948.7500\n",
      "Epoch 924/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4990.5239 - val_loss: 785861.1250\n",
      "Epoch 925/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4926.2070 - val_loss: 789116.6250\n",
      "Epoch 926/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4900.5776 - val_loss: 785791.1250\n",
      "Epoch 927/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4860.7070 - val_loss: 785830.7500\n",
      "Epoch 928/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 4856.8247 - val_loss: 783746.3125\n",
      "Epoch 929/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 4787.5718 - val_loss: 784524.3750\n",
      "Epoch 930/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 4748.1128 - val_loss: 780682.3750\n",
      "Epoch 931/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4718.1465 - val_loss: 780837.3750\n",
      "Epoch 932/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 4702.5776 - val_loss: 779887.5000\n",
      "Epoch 933/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4633.6250 - val_loss: 778349.1875\n",
      "Epoch 934/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4607.0884 - val_loss: 776787.9375\n",
      "Epoch 935/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4576.8716 - val_loss: 773588.3125\n",
      "Epoch 936/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 4548.7861 - val_loss: 774898.6250\n",
      "Epoch 937/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4534.1562 - val_loss: 773963.3125\n",
      "Epoch 938/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 4474.3760 - val_loss: 772516.5625\n",
      "Epoch 939/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4431.8394 - val_loss: 771528.9375\n",
      "Epoch 940/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4402.9141 - val_loss: 770178.6250\n",
      "Epoch 941/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 4382.8730 - val_loss: 768148.8125\n",
      "Epoch 942/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4330.4429 - val_loss: 767770.2500\n",
      "Epoch 943/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 4306.5459 - val_loss: 767166.8750\n",
      "Epoch 944/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 4257.1782 - val_loss: 764646.2500\n",
      "Epoch 945/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4239.8301 - val_loss: 767118.5625\n",
      "Epoch 946/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4196.1514 - val_loss: 763265.3750\n",
      "Epoch 947/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 4149.6074 - val_loss: 761781.8125\n",
      "Epoch 948/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4134.8594 - val_loss: 761905.3750\n",
      "Epoch 949/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4094.2070 - val_loss: 760944.8750\n",
      "Epoch 950/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 4048.1787 - val_loss: 757212.2500\n",
      "Epoch 951/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4031.7053 - val_loss: 756228.6875\n",
      "Epoch 952/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 3995.0308 - val_loss: 756579.1250\n",
      "Epoch 953/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 3956.9167 - val_loss: 754843.4375\n",
      "Epoch 954/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3958.7104 - val_loss: 755668.3750\n",
      "Epoch 955/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 3911.6143 - val_loss: 755227.1250\n",
      "Epoch 956/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3872.3264 - val_loss: 750296.1875\n",
      "Epoch 957/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 3835.7600 - val_loss: 748906.4375\n",
      "Epoch 958/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3816.5493 - val_loss: 751183.1250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 959/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3786.3088 - val_loss: 749972.3750\n",
      "Epoch 960/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3773.7002 - val_loss: 749449.0625\n",
      "Epoch 961/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3712.9619 - val_loss: 743321.0000\n",
      "Epoch 962/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3698.3711 - val_loss: 746492.3125\n",
      "Epoch 963/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 3670.4700 - val_loss: 745862.7500\n",
      "Epoch 964/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3632.6477 - val_loss: 743459.6250\n",
      "Epoch 965/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 3600.0735 - val_loss: 744125.1250\n",
      "Epoch 966/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3580.3262 - val_loss: 742291.0000\n",
      "Epoch 967/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3566.3826 - val_loss: 741068.8125\n",
      "Epoch 968/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3528.4773 - val_loss: 737616.8750\n",
      "Epoch 969/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 3485.5737 - val_loss: 740454.6875\n",
      "Epoch 970/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3484.1863 - val_loss: 738297.4375\n",
      "Epoch 971/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 3443.6628 - val_loss: 734823.0000\n",
      "Epoch 972/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 3395.2925 - val_loss: 734871.4375\n",
      "Epoch 973/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 3411.7471 - val_loss: 734999.8125\n",
      "Epoch 974/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3376.6145 - val_loss: 733093.1875\n",
      "Epoch 975/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3359.1504 - val_loss: 733278.3125\n",
      "Epoch 976/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3330.9412 - val_loss: 729017.8125\n",
      "Epoch 977/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3267.8645 - val_loss: 733051.6250\n",
      "Epoch 978/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3241.0317 - val_loss: 729073.4375\n",
      "Epoch 979/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3232.7820 - val_loss: 730019.1875\n",
      "Epoch 980/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 3189.5198 - val_loss: 727457.7500\n",
      "Epoch 981/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3157.8118 - val_loss: 727170.8750\n",
      "Epoch 982/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3132.0090 - val_loss: 725193.1250\n",
      "Epoch 983/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3106.0481 - val_loss: 725834.0000\n",
      "Epoch 984/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3076.4683 - val_loss: 723830.6875\n",
      "Epoch 985/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3066.4875 - val_loss: 723713.6875\n",
      "Epoch 986/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3049.6797 - val_loss: 721468.8750\n",
      "Epoch 987/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3014.2832 - val_loss: 720314.7500\n",
      "Epoch 988/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2992.7434 - val_loss: 721635.3125\n",
      "Epoch 989/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2963.0146 - val_loss: 718358.6875\n",
      "Epoch 990/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2936.3845 - val_loss: 718918.3125\n",
      "Epoch 991/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2919.4211 - val_loss: 718251.3125\n",
      "Epoch 992/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2898.9197 - val_loss: 716062.8750\n",
      "Epoch 993/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2874.3413 - val_loss: 715496.3750\n",
      "Epoch 994/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2846.7214 - val_loss: 715607.9375\n",
      "Epoch 995/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2830.6069 - val_loss: 712696.6250\n",
      "Epoch 996/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2807.1924 - val_loss: 713778.6250\n",
      "Epoch 997/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2777.4629 - val_loss: 712621.1875\n",
      "Epoch 998/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2755.5850 - val_loss: 709149.5625\n",
      "Epoch 999/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2718.6011 - val_loss: 710867.3750\n",
      "Epoch 1000/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2709.7085 - val_loss: 710070.7500\n",
      "Epoch 1001/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2685.5605 - val_loss: 706732.8125\n",
      "Epoch 1002/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2663.3555 - val_loss: 707954.3125\n",
      "Epoch 1003/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2644.9880 - val_loss: 705520.0625\n",
      "Epoch 1004/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2622.1641 - val_loss: 706002.6250\n",
      "Epoch 1005/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2600.5496 - val_loss: 705510.1875\n",
      "Epoch 1006/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2572.4783 - val_loss: 702751.9375\n",
      "Epoch 1007/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2551.2554 - val_loss: 702670.1250\n",
      "Epoch 1008/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2533.2878 - val_loss: 702098.9375\n",
      "Epoch 1009/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2523.4407 - val_loss: 702205.0000\n",
      "Epoch 1010/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2494.6165 - val_loss: 703297.9375\n",
      "Epoch 1011/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2469.9873 - val_loss: 699149.5625\n",
      "Epoch 1012/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2477.9424 - val_loss: 698688.1250\n",
      "Epoch 1013/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2454.8071 - val_loss: 698312.3125\n",
      "Epoch 1014/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2419.3271 - val_loss: 696153.6875\n",
      "Epoch 1015/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2416.0288 - val_loss: 693183.5625\n",
      "Epoch 1016/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2433.1309 - val_loss: 695025.4375\n",
      "Epoch 1017/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2392.6721 - val_loss: 696045.1250\n",
      "Epoch 1018/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2377.5681 - val_loss: 692494.1250\n",
      "Epoch 1019/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2308.6179 - val_loss: 694281.2500\n",
      "Epoch 1020/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2316.3093 - val_loss: 690875.6875\n",
      "Epoch 1021/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2273.4224 - val_loss: 693149.3750\n",
      "Epoch 1022/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2257.6531 - val_loss: 690702.1875\n",
      "Epoch 1023/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2230.4443 - val_loss: 688700.3125\n",
      "Epoch 1024/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2209.6423 - val_loss: 689439.1250\n",
      "Epoch 1025/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2197.0879 - val_loss: 687520.5625\n",
      "Epoch 1026/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2171.8279 - val_loss: 686791.5625\n",
      "Epoch 1027/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2153.9480 - val_loss: 686990.5000\n",
      "Epoch 1028/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2150.0608 - val_loss: 684393.8750\n",
      "Epoch 1029/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2117.4124 - val_loss: 684141.5625\n",
      "Epoch 1030/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2106.1650 - val_loss: 682002.3125\n",
      "Epoch 1031/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2091.7993 - val_loss: 683000.0000\n",
      "Epoch 1032/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2073.1780 - val_loss: 682809.0625\n",
      "Epoch 1033/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2056.7166 - val_loss: 678996.2500\n",
      "Epoch 1034/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2043.7854 - val_loss: 679055.5000\n",
      "Epoch 1035/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2030.1814 - val_loss: 680410.0625\n",
      "Epoch 1036/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2010.8657 - val_loss: 679075.1250\n",
      "Epoch 1037/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2002.7689 - val_loss: 676227.1250\n",
      "Epoch 1038/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1987.3040 - val_loss: 677129.3125\n",
      "Epoch 1039/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1969.1206 - val_loss: 676961.1250\n",
      "Epoch 1040/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1936.7708 - val_loss: 675604.6250\n",
      "Epoch 1041/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1937.4077 - val_loss: 672041.3125\n",
      "Epoch 1042/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1933.5693 - val_loss: 677007.5000\n",
      "Epoch 1043/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1910.0125 - val_loss: 671795.6250\n",
      "Epoch 1044/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1893.5092 - val_loss: 672783.8750\n",
      "Epoch 1045/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1869.8129 - val_loss: 670187.4375\n",
      "Epoch 1046/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1846.3719 - val_loss: 670103.9375\n",
      "Epoch 1047/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1856.0427 - val_loss: 669334.1250\n",
      "Epoch 1048/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1830.3047 - val_loss: 668911.5000\n",
      "Epoch 1049/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1797.0793 - val_loss: 669116.8750\n",
      "Epoch 1050/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1810.1617 - val_loss: 666820.1250\n",
      "Epoch 1051/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1769.3328 - val_loss: 667133.3750\n",
      "Epoch 1052/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1758.7190 - val_loss: 663877.0000\n",
      "Epoch 1053/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1754.9917 - val_loss: 667024.8125\n",
      "Epoch 1054/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1731.8917 - val_loss: 665109.3125\n",
      "Epoch 1055/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1700.4381 - val_loss: 663257.5625\n",
      "Epoch 1056/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1693.1355 - val_loss: 663752.8750\n",
      "Epoch 1057/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1691.1639 - val_loss: 661604.5625\n",
      "Epoch 1058/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1692.9734 - val_loss: 663456.3750\n",
      "Epoch 1059/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1663.0609 - val_loss: 660163.6250\n",
      "Epoch 1060/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1669.9954 - val_loss: 659610.9375\n",
      "Epoch 1061/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1650.5234 - val_loss: 657922.5000\n",
      "Epoch 1062/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1620.0621 - val_loss: 660421.1875\n",
      "Epoch 1063/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1610.7152 - val_loss: 655902.7500\n",
      "Epoch 1064/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1596.6654 - val_loss: 657737.6875\n",
      "Epoch 1065/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1570.1946 - val_loss: 655906.4375\n",
      "Epoch 1066/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1557.1964 - val_loss: 655115.0000\n",
      "Epoch 1067/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1545.2440 - val_loss: 654514.0000\n",
      "Epoch 1068/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1521.4580 - val_loss: 652840.0000\n",
      "Epoch 1069/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1501.4247 - val_loss: 653558.8750\n",
      "Epoch 1070/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1487.3911 - val_loss: 653542.2500\n",
      "Epoch 1071/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1482.5286 - val_loss: 649713.8125\n",
      "Epoch 1072/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1465.6066 - val_loss: 651196.2500\n",
      "Epoch 1073/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1463.3768 - val_loss: 649348.0625\n",
      "Epoch 1074/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1459.7526 - val_loss: 651337.8750\n",
      "Epoch 1075/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1436.0875 - val_loss: 648425.0625\n",
      "Epoch 1076/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1441.9489 - val_loss: 650376.8750\n",
      "Epoch 1077/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1411.1287 - val_loss: 645034.2500\n",
      "Epoch 1078/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1413.0830 - val_loss: 647777.5625\n",
      "Epoch 1079/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1400.7635 - val_loss: 644454.7500\n",
      "Epoch 1080/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1373.9008 - val_loss: 645772.1875\n",
      "Epoch 1081/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1357.7883 - val_loss: 643907.7500\n",
      "Epoch 1082/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1364.3325 - val_loss: 646939.3750\n",
      "Epoch 1083/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1344.2628 - val_loss: 644166.0000\n",
      "Epoch 1084/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1325.9750 - val_loss: 641589.0625\n",
      "Epoch 1085/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1313.1187 - val_loss: 644681.0625\n",
      "Epoch 1086/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1295.3828 - val_loss: 640315.6875\n",
      "Epoch 1087/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1290.2982 - val_loss: 642418.4375\n",
      "Epoch 1088/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1292.7230 - val_loss: 636920.7500\n",
      "Epoch 1089/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1269.5807 - val_loss: 641668.2500\n",
      "Epoch 1090/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1275.8186 - val_loss: 638482.9375\n",
      "Epoch 1091/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1264.1697 - val_loss: 637871.0625\n",
      "Epoch 1092/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1301.2467 - val_loss: 639305.5625\n",
      "Epoch 1093/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1279.3264 - val_loss: 636111.2500\n",
      "Epoch 1094/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1254.7893 - val_loss: 637580.6250\n",
      "Epoch 1095/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1249.5922 - val_loss: 636766.6250\n",
      "Epoch 1096/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1237.4213 - val_loss: 635540.6875\n",
      "Epoch 1097/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1204.4141 - val_loss: 632536.0000\n",
      "Epoch 1098/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1236.8704 - val_loss: 633094.5625\n",
      "Epoch 1099/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1229.3876 - val_loss: 632664.1250\n",
      "Epoch 1100/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1167.5233 - val_loss: 634099.8125\n",
      "Epoch 1101/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1128.0581 - val_loss: 630958.5625\n",
      "Epoch 1102/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1140.3931 - val_loss: 628031.2500\n",
      "Epoch 1103/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1135.8314 - val_loss: 630476.3750\n",
      "Epoch 1104/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1146.5980 - val_loss: 630029.6250\n",
      "Epoch 1105/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1201.1345 - val_loss: 629388.8750\n",
      "Epoch 1106/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1138.9639 - val_loss: 628117.7500\n",
      "Epoch 1107/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1137.2173 - val_loss: 627911.3750\n",
      "Epoch 1108/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1238.3071 - val_loss: 627664.5625\n",
      "Epoch 1109/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 7ms/step - loss: 1142.0858 - val_loss: 626490.1875\n",
      "Epoch 1110/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1062.2335 - val_loss: 627256.5000\n",
      "Epoch 1111/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1038.7091 - val_loss: 625664.5625\n",
      "Epoch 1112/2000\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 1055.1031 - val_loss: 626200.0000\n",
      "Epoch 1113/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1050.6063 - val_loss: 622524.6250\n",
      "Epoch 1114/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1309.5425 - val_loss: 623562.2500\n",
      "Epoch 1115/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1387.9321 - val_loss: 622321.5000\n",
      "Epoch 1116/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1919.7012 - val_loss: 620911.6875\n",
      "Epoch 1117/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1589.7098 - val_loss: 621989.5000\n",
      "Epoch 1118/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1181.6903 - val_loss: 621326.6875\n",
      "Epoch 1119/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1044.1987 - val_loss: 622356.4375\n",
      "Epoch 1120/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1091.1901 - val_loss: 617178.0625\n",
      "Epoch 1121/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 990.2166 - val_loss: 621873.8125\n",
      "Epoch 1122/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1153.1688 - val_loss: 619619.2500\n",
      "Epoch 1123/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 974.4349 - val_loss: 616562.8125\n",
      "Epoch 1124/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1047.5581 - val_loss: 618981.0000\n",
      "Epoch 1125/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 941.1320 - val_loss: 616026.1875\n",
      "Epoch 1126/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1013.1019 - val_loss: 615274.2500\n",
      "Epoch 1127/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 954.3723 - val_loss: 616773.6250\n",
      "Epoch 1128/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 883.3954 - val_loss: 614309.0625\n",
      "Epoch 1129/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 876.3550 - val_loss: 616087.0625\n",
      "Epoch 1130/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 866.2966 - val_loss: 615218.8750\n",
      "Epoch 1131/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 864.7044 - val_loss: 611299.8125\n",
      "Epoch 1132/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 853.9572 - val_loss: 612856.1875\n",
      "Epoch 1133/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 833.7548 - val_loss: 611214.1875\n",
      "Epoch 1134/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 835.2440 - val_loss: 610165.6875\n",
      "Epoch 1135/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 830.2911 - val_loss: 612851.9375\n",
      "Epoch 1136/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 817.6876 - val_loss: 608295.1875\n",
      "Epoch 1137/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 852.0856 - val_loss: 609291.5625\n",
      "Epoch 1138/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 861.0934 - val_loss: 611270.5625\n",
      "Epoch 1139/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 850.4214 - val_loss: 606897.4375\n",
      "Epoch 1140/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 837.1970 - val_loss: 606767.4375\n",
      "Epoch 1141/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 791.3240 - val_loss: 608893.8125\n",
      "Epoch 1142/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 851.7012 - val_loss: 606046.0625\n",
      "Epoch 1143/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 868.3030 - val_loss: 607934.1875\n",
      "Epoch 1144/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 932.5663 - val_loss: 602872.6875\n",
      "Epoch 1145/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 862.5423 - val_loss: 607659.8125\n",
      "Epoch 1146/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 773.8845 - val_loss: 604289.1250\n",
      "Epoch 1147/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 773.9302 - val_loss: 602357.3750\n",
      "Epoch 1148/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 781.2339 - val_loss: 604814.1875\n",
      "Epoch 1149/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 802.9838 - val_loss: 602739.1875\n",
      "Epoch 1150/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 791.1065 - val_loss: 602423.6875\n",
      "Epoch 1151/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 842.8492 - val_loss: 601163.3750\n",
      "Epoch 1152/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 769.1802 - val_loss: 601211.6250\n",
      "Epoch 1153/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1523.3955 - val_loss: 598254.2500\n",
      "Epoch 1154/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1163.4590 - val_loss: 598781.1250\n",
      "Epoch 1155/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 881.5976 - val_loss: 603879.8750\n",
      "Epoch 1156/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1099.1700 - val_loss: 596302.6875\n",
      "Epoch 1157/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 985.9085 - val_loss: 599465.3125\n",
      "Epoch 1158/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 769.7133 - val_loss: 602461.3750\n",
      "Epoch 1159/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 923.1199 - val_loss: 596692.0625\n",
      "Epoch 1160/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 854.1107 - val_loss: 593925.9375\n",
      "Epoch 1161/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1040.4690 - val_loss: 597092.8125\n",
      "Epoch 1162/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 965.5347 - val_loss: 596430.9375\n",
      "Epoch 1163/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1000.5920 - val_loss: 595566.0000\n",
      "Epoch 1164/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 773.8660 - val_loss: 593787.6250\n",
      "Epoch 1165/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1069.1707 - val_loss: 590628.4375\n",
      "Epoch 1166/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 728.2893 - val_loss: 593789.8750\n",
      "Epoch 1167/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1034.4908 - val_loss: 594219.2500\n",
      "Epoch 1168/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1130.4243 - val_loss: 592189.8125\n",
      "Epoch 1169/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 903.4034 - val_loss: 593176.6250\n",
      "Epoch 1170/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 661.1179 - val_loss: 591170.5000\n",
      "Epoch 1171/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 680.0164 - val_loss: 589936.5000\n",
      "Epoch 1172/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 670.4523 - val_loss: 588139.1875\n",
      "Epoch 1173/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 607.5349 - val_loss: 592282.0625\n",
      "Epoch 1174/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 742.5481 - val_loss: 588539.6250\n",
      "Epoch 1175/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 808.4138 - val_loss: 588743.3750\n",
      "Epoch 1176/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 851.9537 - val_loss: 591777.3750\n",
      "Epoch 1177/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 756.7814 - val_loss: 586557.6875\n",
      "Epoch 1178/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 853.7106 - val_loss: 586718.9375\n",
      "Epoch 1179/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 649.0472 - val_loss: 587179.6250\n",
      "Epoch 1180/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 800.4681 - val_loss: 587502.3750\n",
      "Epoch 1181/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 724.2206 - val_loss: 586107.8125\n",
      "Epoch 1182/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 713.2394 - val_loss: 586641.0625\n",
      "Epoch 1183/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 774.7371 - val_loss: 584237.0625\n",
      "Epoch 1184/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 796.5296 - val_loss: 588453.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1185/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 840.9290 - val_loss: 581144.5000\n",
      "Epoch 1186/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 700.3934 - val_loss: 583291.0000\n",
      "Epoch 1187/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1151.5507 - val_loss: 583535.6250\n",
      "Epoch 1188/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1103.3766 - val_loss: 584072.3125\n",
      "Epoch 1189/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 725.3947 - val_loss: 581587.3125\n",
      "Epoch 1190/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 622.8806 - val_loss: 582740.8750\n",
      "Epoch 1191/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 504.7121 - val_loss: 582921.3125\n",
      "Epoch 1192/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 572.6227 - val_loss: 580832.5625\n",
      "Epoch 1193/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 551.2178 - val_loss: 580637.8750\n",
      "Epoch 1194/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 541.6048 - val_loss: 578306.8750\n",
      "Epoch 1195/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 538.2202 - val_loss: 580297.3125\n",
      "Epoch 1196/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 517.3223 - val_loss: 578513.7500\n",
      "Epoch 1197/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 531.0238 - val_loss: 578225.9375\n",
      "Epoch 1198/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 500.7776 - val_loss: 577262.5000\n",
      "Epoch 1199/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 519.5581 - val_loss: 576655.8125\n",
      "Epoch 1200/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 516.9512 - val_loss: 576889.0625\n",
      "Epoch 1201/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 548.8021 - val_loss: 575392.9375\n",
      "Epoch 1202/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 463.3647 - val_loss: 577212.1250\n",
      "Epoch 1203/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 541.2704 - val_loss: 576361.0625\n",
      "Epoch 1204/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 619.3631 - val_loss: 574778.6875\n",
      "Epoch 1205/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 455.2514 - val_loss: 575164.3125\n",
      "Epoch 1206/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 838.9559 - val_loss: 576674.0000\n",
      "Epoch 1207/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1279.8488 - val_loss: 574735.4375\n",
      "Epoch 1208/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 804.4147 - val_loss: 575571.8750\n",
      "Epoch 1209/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4425.3945 - val_loss: 571714.3125\n",
      "Epoch 1210/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2173.4177 - val_loss: 575109.5000\n",
      "Epoch 1211/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 683.2165 - val_loss: 570443.0000\n",
      "Epoch 1212/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 776.2576 - val_loss: 568545.2500\n",
      "Epoch 1213/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 467.1333 - val_loss: 574556.8125\n",
      "Epoch 1214/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 522.5345 - val_loss: 570868.4375\n",
      "Epoch 1215/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 512.6548 - val_loss: 565599.1875\n",
      "Epoch 1216/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 889.4219 - val_loss: 574009.3125\n",
      "Epoch 1217/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 567.1960 - val_loss: 569926.9375\n",
      "Epoch 1218/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1769.9073 - val_loss: 565399.1250\n",
      "Epoch 1219/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1113.7880 - val_loss: 572685.0000\n",
      "Epoch 1220/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 776.8952 - val_loss: 569046.3750\n",
      "Epoch 1221/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 712.0064 - val_loss: 564543.1875\n",
      "Epoch 1222/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 609.6943 - val_loss: 565363.5625\n",
      "Epoch 1223/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 594.0211 - val_loss: 570066.7500\n",
      "Epoch 1224/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 463.1586 - val_loss: 566086.4375\n",
      "Epoch 1225/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 886.3242 - val_loss: 569622.4375\n",
      "Epoch 1226/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 732.8719 - val_loss: 562185.0625\n",
      "Epoch 1227/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1197.2113 - val_loss: 566155.7500\n",
      "Epoch 1228/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1513.4181 - val_loss: 564872.1875\n",
      "Epoch 1229/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1182.0740 - val_loss: 559843.6250\n",
      "Epoch 1230/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 707.7534 - val_loss: 564201.0000\n",
      "Epoch 1231/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 678.3844 - val_loss: 564506.4375\n",
      "Epoch 1232/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 514.1074 - val_loss: 562387.8125\n",
      "Epoch 1233/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 634.1496 - val_loss: 563379.2500\n",
      "Epoch 1234/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 684.5026 - val_loss: 563598.4375\n",
      "Epoch 1235/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 449.7625 - val_loss: 560360.7500\n",
      "Epoch 1236/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 377.4262 - val_loss: 559945.5000\n",
      "Epoch 1237/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 378.0645 - val_loss: 562840.1875\n",
      "Epoch 1238/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 335.9956 - val_loss: 563250.4375\n",
      "Epoch 1239/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 358.9583 - val_loss: 559627.9375\n",
      "Epoch 1240/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 360.2441 - val_loss: 558648.6250\n",
      "Epoch 1241/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 331.9680 - val_loss: 557424.4375\n",
      "Epoch 1242/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 318.4678 - val_loss: 559072.2500\n",
      "Epoch 1243/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 297.7290 - val_loss: 560369.1875\n",
      "Epoch 1244/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 295.8262 - val_loss: 557052.9375\n",
      "Epoch 1245/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 293.3394 - val_loss: 556391.9375\n",
      "Epoch 1246/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 330.2536 - val_loss: 557808.7500\n",
      "Epoch 1247/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 326.2669 - val_loss: 552690.7500\n",
      "Epoch 1248/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 294.3860 - val_loss: 555729.1250\n",
      "Epoch 1249/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 368.2820 - val_loss: 556307.8125\n",
      "Epoch 1250/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 326.4795 - val_loss: 557082.5625\n",
      "Epoch 1251/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 286.2404 - val_loss: 554630.5000\n",
      "Epoch 1252/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 287.2079 - val_loss: 556887.1875\n",
      "Epoch 1253/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 304.1174 - val_loss: 555007.6875\n",
      "Epoch 1254/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 312.4337 - val_loss: 551698.2500\n",
      "Epoch 1255/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 289.4761 - val_loss: 553772.1250\n",
      "Epoch 1256/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 398.0803 - val_loss: 554731.9375\n",
      "Epoch 1257/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 567.9032 - val_loss: 549558.6250\n",
      "Epoch 1258/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 414.2976 - val_loss: 554080.6250\n",
      "Epoch 1259/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 805.9916 - val_loss: 551700.9375\n",
      "Epoch 1260/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 762.9871 - val_loss: 547216.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1261/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 536.2908 - val_loss: 553741.5000\n",
      "Epoch 1262/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 518.9836 - val_loss: 556810.7500\n",
      "Epoch 1263/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 494.9280 - val_loss: 550462.8750\n",
      "Epoch 1264/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 430.6468 - val_loss: 546648.0625\n",
      "Epoch 1265/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 437.5711 - val_loss: 549048.7500\n",
      "Epoch 1266/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 293.1289 - val_loss: 548910.0625\n",
      "Epoch 1267/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 416.6045 - val_loss: 550759.2500\n",
      "Epoch 1268/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 454.0869 - val_loss: 547793.4375\n",
      "Epoch 1269/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 452.7152 - val_loss: 548721.0625\n",
      "Epoch 1270/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 371.4091 - val_loss: 548716.7500\n",
      "Epoch 1271/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 255.8709 - val_loss: 548719.8125\n",
      "Epoch 1272/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 289.1966 - val_loss: 548491.7500\n",
      "Epoch 1273/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 310.3307 - val_loss: 547635.0000\n",
      "Epoch 1274/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 241.7253 - val_loss: 545553.6875\n",
      "Epoch 1275/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 335.1746 - val_loss: 546397.8125\n",
      "Epoch 1276/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 545.5399 - val_loss: 545562.2500\n",
      "Epoch 1277/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 718.0389 - val_loss: 543438.7500\n",
      "Epoch 1278/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 958.4763 - val_loss: 544926.6250\n",
      "Epoch 1279/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 346.0223 - val_loss: 545498.6250\n",
      "Epoch 1280/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 655.6768 - val_loss: 545801.3750\n",
      "Epoch 1281/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 339.0924 - val_loss: 545306.1875\n",
      "Epoch 1282/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1184.0073 - val_loss: 544638.0000\n",
      "Epoch 1283/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1630.3785 - val_loss: 538840.0625\n",
      "Epoch 1284/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 717.9575 - val_loss: 540000.1250\n",
      "Epoch 1285/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1796.3420 - val_loss: 544279.0000\n",
      "Epoch 1286/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 788.8214 - val_loss: 539515.8750\n",
      "Epoch 1287/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 487.0357 - val_loss: 540080.8750\n",
      "Epoch 1288/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1525.1207 - val_loss: 538653.5000\n",
      "Epoch 1289/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 437.1356 - val_loss: 543227.3750\n",
      "Epoch 1290/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 590.4821 - val_loss: 545889.3125\n",
      "Epoch 1291/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 435.7005 - val_loss: 542897.1875\n",
      "Epoch 1292/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 827.8431 - val_loss: 535764.3125\n",
      "Epoch 1293/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 610.1326 - val_loss: 538053.9375\n",
      "Epoch 1294/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 5215.5068 - val_loss: 538523.1875\n",
      "Epoch 1295/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1520.7336 - val_loss: 530816.5625\n",
      "Epoch 1296/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1794.1349 - val_loss: 542450.0000\n",
      "Epoch 1297/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1095.0265 - val_loss: 539377.6875\n",
      "Epoch 1298/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 5106.3511 - val_loss: 533313.7500\n",
      "Epoch 1299/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 5855.5850 - val_loss: 556078.6875\n",
      "Epoch 1300/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2119.9773 - val_loss: 539389.9375\n",
      "Epoch 1301/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1499.4556 - val_loss: 539140.5625\n",
      "Epoch 1302/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 782.8526 - val_loss: 534518.9375\n",
      "Epoch 1303/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 568.6714 - val_loss: 533166.1875\n",
      "Epoch 1304/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 580.3265 - val_loss: 529521.5000\n",
      "Epoch 1305/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 483.8531 - val_loss: 534408.8750\n",
      "Epoch 1306/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 324.3156 - val_loss: 528825.1250\n",
      "Epoch 1307/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 560.8756 - val_loss: 534221.6875\n",
      "Epoch 1308/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 542.4744 - val_loss: 537911.1250\n",
      "Epoch 1309/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 819.2443 - val_loss: 531035.3125\n",
      "Epoch 1310/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 781.9494 - val_loss: 532894.8750\n",
      "Epoch 1311/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 813.0286 - val_loss: 529673.7500\n",
      "Epoch 1312/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 905.5207 - val_loss: 529639.0625\n",
      "Epoch 1313/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 461.0740 - val_loss: 526286.8750\n",
      "Epoch 1314/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1148.7278 - val_loss: 532246.5000\n",
      "Epoch 1315/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1019.1556 - val_loss: 526523.4375\n",
      "Epoch 1316/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 541.1969 - val_loss: 532146.0000\n",
      "Epoch 1317/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 690.5945 - val_loss: 525024.0000\n",
      "Epoch 1318/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 785.8594 - val_loss: 529902.7500\n",
      "Epoch 1319/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 538.2416 - val_loss: 535036.8125\n",
      "Epoch 1320/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 413.6797 - val_loss: 531244.7500\n",
      "Epoch 1321/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 664.7618 - val_loss: 526397.2500\n",
      "Epoch 1322/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 456.0426 - val_loss: 524223.7188\n",
      "Epoch 1323/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 421.5187 - val_loss: 526327.1250\n",
      "Epoch 1324/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 551.5920 - val_loss: 527764.5625\n",
      "Epoch 1325/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 319.0678 - val_loss: 528396.0000\n",
      "Epoch 1326/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 314.7974 - val_loss: 528104.4375\n",
      "Epoch 1327/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 453.3611 - val_loss: 527534.6250\n",
      "Epoch 1328/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 302.1875 - val_loss: 528610.3750\n",
      "Epoch 1329/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 204.2312 - val_loss: 525308.4375\n",
      "Epoch 1330/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 216.4940 - val_loss: 525499.1875\n",
      "Epoch 1331/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 188.2891 - val_loss: 525867.3125\n",
      "Epoch 1332/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 214.4104 - val_loss: 523487.5625\n",
      "Epoch 1333/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 186.4457 - val_loss: 522044.6875\n",
      "Epoch 1334/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 218.4037 - val_loss: 523827.3125\n",
      "Epoch 1335/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 252.4545 - val_loss: 520115.3125\n",
      "Epoch 1336/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 248.1643 - val_loss: 526967.0625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1337/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 204.5421 - val_loss: 523064.9062\n",
      "Epoch 1338/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 192.6931 - val_loss: 526720.5625\n",
      "Epoch 1339/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 239.0214 - val_loss: 521300.0625\n",
      "Epoch 1340/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 247.4454 - val_loss: 524918.6875\n",
      "Epoch 1341/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 307.7495 - val_loss: 523224.6562\n",
      "Epoch 1342/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 168.8857 - val_loss: 525755.8125\n",
      "Epoch 1343/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 417.8550 - val_loss: 521704.5625\n",
      "Epoch 1344/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 433.1288 - val_loss: 522547.7812\n",
      "Epoch 1345/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 212.3842 - val_loss: 519028.9062\n",
      "Epoch 1346/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1012.2742 - val_loss: 522736.4688\n",
      "Epoch 1347/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 422.2570 - val_loss: 524287.0312\n",
      "Epoch 1348/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1056.2900 - val_loss: 520841.8125\n",
      "Epoch 1349/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 234.1581 - val_loss: 516342.5312\n",
      "Epoch 1350/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 194.0841 - val_loss: 520514.8750\n",
      "Epoch 1351/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 159.4026 - val_loss: 519142.2188\n",
      "Epoch 1352/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 128.0902 - val_loss: 520742.0625\n",
      "Epoch 1353/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 162.9086 - val_loss: 518108.5625\n",
      "Epoch 1354/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 137.9066 - val_loss: 520753.1562\n",
      "Epoch 1355/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 123.8303 - val_loss: 520705.5000\n",
      "Epoch 1356/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 148.2803 - val_loss: 520041.1562\n",
      "Epoch 1357/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 134.3699 - val_loss: 519440.5312\n",
      "Epoch 1358/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 145.5661 - val_loss: 519339.9688\n",
      "Epoch 1359/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 156.0385 - val_loss: 516906.5000\n",
      "Epoch 1360/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 177.3378 - val_loss: 520365.4688\n",
      "Epoch 1361/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 136.2045 - val_loss: 516180.7188\n",
      "Epoch 1362/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 161.5653 - val_loss: 516810.6562\n",
      "Epoch 1363/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 183.6903 - val_loss: 517183.7812\n",
      "Epoch 1364/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 140.5312 - val_loss: 518562.4375\n",
      "Epoch 1365/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 160.1641 - val_loss: 515708.2500\n",
      "Epoch 1366/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 336.8526 - val_loss: 516117.5000\n",
      "Epoch 1367/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 405.1081 - val_loss: 517312.5312\n",
      "Epoch 1368/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 554.5555 - val_loss: 515310.6250\n",
      "Epoch 1369/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 590.6550 - val_loss: 514684.6875\n",
      "Epoch 1370/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1151.6346 - val_loss: 515426.0625\n",
      "Epoch 1371/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 735.0502 - val_loss: 520455.8438\n",
      "Epoch 1372/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 995.1448 - val_loss: 513283.3125\n",
      "Epoch 1373/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 842.1581 - val_loss: 513743.0938\n",
      "Epoch 1374/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 639.1983 - val_loss: 512364.1875\n",
      "Epoch 1375/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 778.4572 - val_loss: 506722.8438\n",
      "Epoch 1376/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 919.7369 - val_loss: 525104.8750\n",
      "Epoch 1377/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1734.4055 - val_loss: 496156.5625\n",
      "Epoch 1378/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1638.6438 - val_loss: 515736.4688\n",
      "Epoch 1379/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1359.7252 - val_loss: 508104.6250\n",
      "Epoch 1380/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1124.2278 - val_loss: 513630.8125\n",
      "Epoch 1381/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 639.1838 - val_loss: 508823.8438\n",
      "Epoch 1382/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 562.1579 - val_loss: 513586.1250\n",
      "Epoch 1383/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 401.8881 - val_loss: 509808.5312\n",
      "Epoch 1384/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 367.5974 - val_loss: 512651.9062\n",
      "Epoch 1385/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 364.4163 - val_loss: 506078.3125\n",
      "Epoch 1386/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 320.4226 - val_loss: 512157.0938\n",
      "Epoch 1387/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 180.5838 - val_loss: 509933.0312\n",
      "Epoch 1388/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1151.6599 - val_loss: 512614.6250\n",
      "Epoch 1389/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 826.0766 - val_loss: 512851.7188\n",
      "Epoch 1390/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 227.6993 - val_loss: 509936.7812\n",
      "Epoch 1391/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 244.7454 - val_loss: 508505.0938\n",
      "Epoch 1392/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 231.8363 - val_loss: 508659.8125\n",
      "Epoch 1393/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 216.5015 - val_loss: 509485.4688\n",
      "Epoch 1394/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 276.5035 - val_loss: 508417.5938\n",
      "Epoch 1395/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 245.7116 - val_loss: 510618.9688\n",
      "Epoch 1396/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 171.4914 - val_loss: 508819.9688\n",
      "Epoch 1397/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 211.5658 - val_loss: 509771.8438\n",
      "Epoch 1398/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 218.1409 - val_loss: 506547.6250\n",
      "Epoch 1399/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 295.5221 - val_loss: 510058.0625\n",
      "Epoch 1400/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 330.9357 - val_loss: 506225.4375\n",
      "Epoch 1401/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 291.7217 - val_loss: 504871.3438\n",
      "Epoch 1402/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 271.5388 - val_loss: 505360.3750\n",
      "Epoch 1403/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 271.0618 - val_loss: 508342.5312\n",
      "Epoch 1404/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 229.4090 - val_loss: 504941.9375\n",
      "Epoch 1405/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 166.2563 - val_loss: 506780.9062\n",
      "Epoch 1406/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 196.8569 - val_loss: 502600.2188\n",
      "Epoch 1407/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 255.5890 - val_loss: 506351.2500\n",
      "Epoch 1408/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 359.7359 - val_loss: 508522.2188\n",
      "Epoch 1409/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 542.7214 - val_loss: 502179.2812\n",
      "Epoch 1410/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 623.0835 - val_loss: 512617.1875\n",
      "Epoch 1411/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 740.6684 - val_loss: 508200.2188\n",
      "Epoch 1412/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 538.9822 - val_loss: 507798.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1413/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 618.8911 - val_loss: 499898.8125\n",
      "Epoch 1414/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 702.2332 - val_loss: 505238.6875\n",
      "Epoch 1415/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 350.4185 - val_loss: 497637.4062\n",
      "Epoch 1416/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 695.8873 - val_loss: 499585.4062\n",
      "Epoch 1417/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 743.8935 - val_loss: 502301.8125\n",
      "Epoch 1418/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 633.7617 - val_loss: 498382.6875\n",
      "Epoch 1419/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 404.0935 - val_loss: 506364.0625\n",
      "Epoch 1420/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 454.5861 - val_loss: 505438.6562\n",
      "Epoch 1421/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 408.4438 - val_loss: 511273.8750\n",
      "Epoch 1422/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 444.0025 - val_loss: 502448.9688\n",
      "Epoch 1423/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 579.7850 - val_loss: 516828.7500\n",
      "Epoch 1424/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 607.9857 - val_loss: 500007.3750\n",
      "Epoch 1425/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 658.3957 - val_loss: 516459.3125\n",
      "Epoch 1426/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 559.9655 - val_loss: 507826.9062\n",
      "Epoch 1427/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 650.6354 - val_loss: 501155.2500\n",
      "Epoch 1428/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 409.6476 - val_loss: 499903.5312\n",
      "Epoch 1429/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 421.3106 - val_loss: 495017.9062\n",
      "Epoch 1430/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 584.6160 - val_loss: 495712.9688\n",
      "Epoch 1431/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 949.4061 - val_loss: 503689.1250\n",
      "Epoch 1432/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1458.5426 - val_loss: 493031.8438\n",
      "Epoch 1433/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 921.2830 - val_loss: 505547.0312\n",
      "Epoch 1434/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 663.5422 - val_loss: 499684.5000\n",
      "Epoch 1435/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 889.1765 - val_loss: 504478.9688\n",
      "Epoch 1436/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1410.0637 - val_loss: 493994.8438\n",
      "Epoch 1437/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1669.6016 - val_loss: 490223.8125\n",
      "Epoch 1438/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1524.0568 - val_loss: 495862.6250\n",
      "Epoch 1439/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 5657.6963 - val_loss: 513269.4688\n",
      "Epoch 1440/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2923.0493 - val_loss: 493085.6562\n",
      "Epoch 1441/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2646.4131 - val_loss: 522115.8125\n",
      "Epoch 1442/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4132.5356 - val_loss: 502636.9375\n",
      "Epoch 1443/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3562.5720 - val_loss: 479626.0938\n",
      "Epoch 1444/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2055.3306 - val_loss: 500864.3750\n",
      "Epoch 1445/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1533.4841 - val_loss: 504834.5312\n",
      "Epoch 1446/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1468.4050 - val_loss: 491369.7812\n",
      "Epoch 1447/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 946.9603 - val_loss: 501868.6562\n",
      "Epoch 1448/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 758.4543 - val_loss: 490648.5000\n",
      "Epoch 1449/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 792.6398 - val_loss: 492459.2812\n",
      "Epoch 1450/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1321.7036 - val_loss: 502865.9688\n",
      "Epoch 1451/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 872.7570 - val_loss: 492237.4062\n",
      "Epoch 1452/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1505.5043 - val_loss: 493426.2188\n",
      "Epoch 1453/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1132.9956 - val_loss: 502085.3438\n",
      "Epoch 1454/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1796.5516 - val_loss: 492150.1250\n",
      "Epoch 1455/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1435.9937 - val_loss: 491258.5000\n",
      "Epoch 1456/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1304.5586 - val_loss: 493312.2812\n",
      "Epoch 1457/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1612.8047 - val_loss: 502711.0312\n",
      "Epoch 1458/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1726.3948 - val_loss: 483179.9062\n",
      "Epoch 1459/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1119.0859 - val_loss: 495938.3438\n",
      "Epoch 1460/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 929.1750 - val_loss: 481108.8438\n",
      "Epoch 1461/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1680.5002 - val_loss: 498023.0625\n",
      "Epoch 1462/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1802.5354 - val_loss: 489299.0312\n",
      "Epoch 1463/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 680.1933 - val_loss: 486182.6562\n",
      "Epoch 1464/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 698.3143 - val_loss: 490452.2188\n",
      "Epoch 1465/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 722.1941 - val_loss: 500214.2188\n",
      "Epoch 1466/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 991.7140 - val_loss: 498860.1875\n",
      "Epoch 1467/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1915.8588 - val_loss: 495560.0938\n",
      "Epoch 1468/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1658.0682 - val_loss: 493035.3438\n",
      "Epoch 1469/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1426.8378 - val_loss: 495035.0000\n",
      "Epoch 1470/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2265.6167 - val_loss: 485030.5000\n",
      "Epoch 1471/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1258.6980 - val_loss: 476976.8438\n",
      "Epoch 1472/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2445.5903 - val_loss: 477521.6562\n",
      "Epoch 1473/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1635.1177 - val_loss: 472411.8125\n",
      "Epoch 1474/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1555.6833 - val_loss: 485791.1250\n",
      "Epoch 1475/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 950.8798 - val_loss: 470874.2812\n",
      "Epoch 1476/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1166.8882 - val_loss: 487337.1875\n",
      "Epoch 1477/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 649.7771 - val_loss: 487833.5938\n",
      "Epoch 1478/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 519.7249 - val_loss: 483590.7500\n",
      "Epoch 1479/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 338.2870 - val_loss: 488766.1250\n",
      "Epoch 1480/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 431.2331 - val_loss: 480604.9375\n",
      "Epoch 1481/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 305.2238 - val_loss: 485193.7188\n",
      "Epoch 1482/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 197.7509 - val_loss: 486945.3125\n",
      "Epoch 1483/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 210.5107 - val_loss: 487701.9375\n",
      "Epoch 1484/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 194.8360 - val_loss: 486405.5625\n",
      "Epoch 1485/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 108.6347 - val_loss: 481417.4062\n",
      "Epoch 1486/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 334.2036 - val_loss: 484824.9375\n",
      "Epoch 1487/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 485.9268 - val_loss: 487315.5938\n",
      "Epoch 1488/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 242.4927 - val_loss: 483208.1875\n",
      "Epoch 1489/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 179.7537 - val_loss: 480632.4688\n",
      "Epoch 1490/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 176.7640 - val_loss: 486541.0000\n",
      "Epoch 1491/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 168.2372 - val_loss: 482271.9062\n",
      "Epoch 1492/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 132.6433 - val_loss: 485809.5625\n",
      "Epoch 1493/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 90.0610 - val_loss: 484169.6250\n",
      "Epoch 1494/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 73.4799 - val_loss: 483682.3438\n",
      "Epoch 1495/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 60.3731 - val_loss: 484488.4688\n",
      "Epoch 1496/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 52.9887 - val_loss: 483831.2500\n",
      "Epoch 1497/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 47.4187 - val_loss: 485053.4062\n",
      "Epoch 1498/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 46.8986 - val_loss: 483511.2188\n",
      "Epoch 1499/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 62.5649 - val_loss: 483075.2500\n",
      "Epoch 1500/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 67.3203 - val_loss: 484927.6875\n",
      "Epoch 1501/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 71.5897 - val_loss: 483004.8750\n",
      "Epoch 1502/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 75.2479 - val_loss: 482424.8438\n",
      "Epoch 1503/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 65.7312 - val_loss: 483231.6250\n",
      "Epoch 1504/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 65.0631 - val_loss: 482121.8750\n",
      "Epoch 1505/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 67.3557 - val_loss: 483673.4375\n",
      "Epoch 1506/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 85.5350 - val_loss: 482836.0000\n",
      "Epoch 1507/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 134.6356 - val_loss: 481739.8438\n",
      "Epoch 1508/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 140.1779 - val_loss: 479086.7812\n",
      "Epoch 1509/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 163.6178 - val_loss: 481120.7812\n",
      "Epoch 1510/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 160.2714 - val_loss: 484170.0938\n",
      "Epoch 1511/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 170.6220 - val_loss: 483973.2500\n",
      "Epoch 1512/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 446.2137 - val_loss: 480215.9375\n",
      "Epoch 1513/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 235.3873 - val_loss: 487586.6875\n",
      "Epoch 1514/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 230.4421 - val_loss: 484982.6250\n",
      "Epoch 1515/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 230.3327 - val_loss: 482722.3438\n",
      "Epoch 1516/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 288.4640 - val_loss: 477364.9688\n",
      "Epoch 1517/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 249.5473 - val_loss: 477298.9062\n",
      "Epoch 1518/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 297.6027 - val_loss: 480933.9062\n",
      "Epoch 1519/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 323.5868 - val_loss: 482451.4688\n",
      "Epoch 1520/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 251.2809 - val_loss: 479923.8438\n",
      "Epoch 1521/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 536.0947 - val_loss: 482491.5938\n",
      "Epoch 1522/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 907.2258 - val_loss: 481751.6875\n",
      "Epoch 1523/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 773.2429 - val_loss: 481141.5000\n",
      "Epoch 1524/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 560.3730 - val_loss: 484235.7500\n",
      "Epoch 1525/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 529.2468 - val_loss: 476589.4375\n",
      "Epoch 1526/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 759.5307 - val_loss: 478347.0938\n",
      "Epoch 1527/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 509.7455 - val_loss: 488288.7500\n",
      "Epoch 1528/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1118.1233 - val_loss: 482289.8750\n",
      "Epoch 1529/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1283.2568 - val_loss: 491000.0312\n",
      "Epoch 1530/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 914.5211 - val_loss: 487680.3125\n",
      "Epoch 1531/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1365.7827 - val_loss: 476843.8438\n",
      "Epoch 1532/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1419.5503 - val_loss: 472825.9062\n",
      "Epoch 1533/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1056.5243 - val_loss: 477098.9688\n",
      "Epoch 1534/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 638.1852 - val_loss: 482615.5312\n",
      "Epoch 1535/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 541.8108 - val_loss: 477155.7500\n",
      "Epoch 1536/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 399.7566 - val_loss: 475476.5625\n",
      "Epoch 1537/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 313.8933 - val_loss: 479470.6562\n",
      "Epoch 1538/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 448.5705 - val_loss: 479114.9062\n",
      "Epoch 1539/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 469.9116 - val_loss: 473324.3125\n",
      "Epoch 1540/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 427.2943 - val_loss: 483155.2500\n",
      "Epoch 1541/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 380.8349 - val_loss: 477704.8750\n",
      "Epoch 1542/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 366.6279 - val_loss: 479743.6875\n",
      "Epoch 1543/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 575.3984 - val_loss: 483825.0312\n",
      "Epoch 1544/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 506.3249 - val_loss: 476975.6875\n",
      "Epoch 1545/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 393.1896 - val_loss: 484590.5000\n",
      "Epoch 1546/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 539.2161 - val_loss: 488489.2500\n",
      "Epoch 1547/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 417.4761 - val_loss: 478485.6250\n",
      "Epoch 1548/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 816.3244 - val_loss: 469083.7188\n",
      "Epoch 1549/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 863.5095 - val_loss: 475511.4375\n",
      "Epoch 1550/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 695.0408 - val_loss: 468734.3125\n",
      "Epoch 1551/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 710.6780 - val_loss: 471515.7188\n",
      "Epoch 1552/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1881.9426 - val_loss: 481915.0938\n",
      "Epoch 1553/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1850.8914 - val_loss: 475019.1562\n",
      "Epoch 1554/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1755.6790 - val_loss: 489335.5312\n",
      "Epoch 1555/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1882.3479 - val_loss: 475088.2500\n",
      "Epoch 1556/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1739.3331 - val_loss: 457991.1562\n",
      "Epoch 1557/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2755.4197 - val_loss: 468145.9375\n",
      "Epoch 1558/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2641.0569 - val_loss: 480630.0312\n",
      "Epoch 1559/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1985.8119 - val_loss: 463467.5625\n",
      "Epoch 1560/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 5257.2217 - val_loss: 483590.4375\n",
      "Epoch 1561/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3312.5803 - val_loss: 480480.0312\n",
      "Epoch 1562/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1970.4874 - val_loss: 453904.7812\n",
      "Epoch 1563/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1253.7749 - val_loss: 466257.3750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1564/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 855.7054 - val_loss: 470909.0000\n",
      "Epoch 1565/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1278.5640 - val_loss: 467398.0938\n",
      "Epoch 1566/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1202.0875 - val_loss: 466080.1875\n",
      "Epoch 1567/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1202.7384 - val_loss: 461782.6875\n",
      "Epoch 1568/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1888.7904 - val_loss: 465568.9062\n",
      "Epoch 1569/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1732.5847 - val_loss: 486322.9688\n",
      "Epoch 1570/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1734.2097 - val_loss: 472987.2500\n",
      "Epoch 1571/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 5975.2671 - val_loss: 462792.0938\n",
      "Epoch 1572/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1817.1199 - val_loss: 466678.8438\n",
      "Epoch 1573/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 6651.9746 - val_loss: 496222.3750\n",
      "Epoch 1574/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2578.4863 - val_loss: 465796.2500\n",
      "Epoch 1575/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3553.7683 - val_loss: 467641.5625\n",
      "Epoch 1576/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2225.5032 - val_loss: 465331.6875\n",
      "Epoch 1577/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2600.3335 - val_loss: 471180.0938\n",
      "Epoch 1578/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3432.3096 - val_loss: 471458.0938\n",
      "Epoch 1579/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3540.4636 - val_loss: 450563.1250\n",
      "Epoch 1580/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2826.4194 - val_loss: 454322.9062\n",
      "Epoch 1581/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1818.5295 - val_loss: 469329.7812\n",
      "Epoch 1582/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1795.4187 - val_loss: 449663.7812\n",
      "Epoch 1583/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1274.9391 - val_loss: 461572.0625\n",
      "Epoch 1584/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1112.1483 - val_loss: 455460.0938\n",
      "Epoch 1585/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 945.7715 - val_loss: 450860.7500\n",
      "Epoch 1586/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 609.0568 - val_loss: 456129.6562\n",
      "Epoch 1587/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 562.6984 - val_loss: 450295.0312\n",
      "Epoch 1588/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 758.0073 - val_loss: 464984.9375\n",
      "Epoch 1589/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 867.2271 - val_loss: 465244.7812\n",
      "Epoch 1590/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 396.4088 - val_loss: 455150.5938\n",
      "Epoch 1591/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 819.1832 - val_loss: 452573.1250\n",
      "Epoch 1592/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 595.7442 - val_loss: 457998.9062\n",
      "Epoch 1593/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1016.2437 - val_loss: 459201.5625\n",
      "Epoch 1594/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 472.2024 - val_loss: 450588.4688\n",
      "Epoch 1595/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 455.0485 - val_loss: 455756.6875\n",
      "Epoch 1596/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 291.0249 - val_loss: 455036.2188\n",
      "Epoch 1597/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 343.1082 - val_loss: 454376.5625\n",
      "Epoch 1598/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 585.7091 - val_loss: 462752.5312\n",
      "Epoch 1599/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 645.2255 - val_loss: 457396.7188\n",
      "Epoch 1600/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 440.6599 - val_loss: 453941.8125\n",
      "Epoch 1601/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 283.7736 - val_loss: 455628.7188\n",
      "Epoch 1602/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 196.7564 - val_loss: 447377.8125\n",
      "Epoch 1603/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 184.3558 - val_loss: 449883.8438\n",
      "Epoch 1604/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 197.5082 - val_loss: 456576.5312\n",
      "Epoch 1605/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 132.0400 - val_loss: 457708.4062\n",
      "Epoch 1606/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 156.5595 - val_loss: 453203.9688\n",
      "Epoch 1607/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 118.2570 - val_loss: 455064.2812\n",
      "Epoch 1608/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 102.0972 - val_loss: 457172.3750\n",
      "Epoch 1609/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 66.6065 - val_loss: 454639.6875\n",
      "Epoch 1610/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 63.0972 - val_loss: 454008.9688\n",
      "Epoch 1611/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 67.8403 - val_loss: 454630.8438\n",
      "Epoch 1612/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 41.3895 - val_loss: 452977.8438\n",
      "Epoch 1613/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 51.8671 - val_loss: 453831.3750\n",
      "Epoch 1614/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 82.8346 - val_loss: 455014.7500\n",
      "Epoch 1615/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 44.1309 - val_loss: 454137.3750\n",
      "Epoch 1616/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 65.8866 - val_loss: 452340.0938\n",
      "Epoch 1617/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 52.0240 - val_loss: 452375.3750\n",
      "Epoch 1618/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 96.6849 - val_loss: 456052.8750\n",
      "Epoch 1619/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 129.3412 - val_loss: 458200.9062\n",
      "Epoch 1620/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 249.7895 - val_loss: 455348.5625\n",
      "Epoch 1621/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 311.7026 - val_loss: 453614.0625\n",
      "Epoch 1622/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 277.9464 - val_loss: 449573.7812\n",
      "Epoch 1623/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 202.1232 - val_loss: 450582.2812\n",
      "Epoch 1624/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 144.7284 - val_loss: 453859.1562\n",
      "Epoch 1625/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 120.7676 - val_loss: 456053.2500\n",
      "Epoch 1626/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 108.0053 - val_loss: 451642.5625\n",
      "Epoch 1627/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 114.9006 - val_loss: 456021.7812\n",
      "Epoch 1628/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 142.6840 - val_loss: 456158.0625\n",
      "Epoch 1629/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 149.1480 - val_loss: 453913.0938\n",
      "Epoch 1630/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 88.9643 - val_loss: 453985.8125\n",
      "Epoch 1631/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 104.0153 - val_loss: 451159.0312\n",
      "Epoch 1632/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 184.3070 - val_loss: 451138.0312\n",
      "Epoch 1633/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 321.7202 - val_loss: 455248.6875\n",
      "Epoch 1634/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 436.6714 - val_loss: 446620.0938\n",
      "Epoch 1635/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 529.2621 - val_loss: 447758.9062\n",
      "Epoch 1636/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 564.0685 - val_loss: 457592.0312\n",
      "Epoch 1637/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 479.1036 - val_loss: 454638.0625\n",
      "Epoch 1638/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 395.0900 - val_loss: 456873.9375\n",
      "Epoch 1639/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 419.0354 - val_loss: 451819.9062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1640/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 417.7962 - val_loss: 449918.0938\n",
      "Epoch 1641/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 354.1868 - val_loss: 450524.5000\n",
      "Epoch 1642/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 443.6867 - val_loss: 453217.4062\n",
      "Epoch 1643/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 522.6724 - val_loss: 455536.3750\n",
      "Epoch 1644/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 491.0636 - val_loss: 448616.4375\n",
      "Epoch 1645/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 440.9793 - val_loss: 437508.3750\n",
      "Epoch 1646/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 664.1256 - val_loss: 450718.4062\n",
      "Epoch 1647/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 876.5165 - val_loss: 456551.2500\n",
      "Epoch 1648/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 723.0137 - val_loss: 457963.0938\n",
      "Epoch 1649/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1054.5245 - val_loss: 446059.5312\n",
      "Epoch 1650/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 622.4665 - val_loss: 444124.6875\n",
      "Epoch 1651/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 699.7139 - val_loss: 452435.7500\n",
      "Epoch 1652/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1079.1383 - val_loss: 448439.6250\n",
      "Epoch 1653/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1056.1349 - val_loss: 442849.7188\n",
      "Epoch 1654/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2405.9038 - val_loss: 448524.8750\n",
      "Epoch 1655/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2560.3015 - val_loss: 456261.1250\n",
      "Epoch 1656/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2133.4121 - val_loss: 439018.4062\n",
      "Epoch 1657/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2206.6565 - val_loss: 456209.4062\n",
      "Epoch 1658/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3130.7817 - val_loss: 464694.3438\n",
      "Epoch 1659/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1982.2064 - val_loss: 447830.3750\n",
      "Epoch 1660/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1786.7986 - val_loss: 442675.6250\n",
      "Epoch 1661/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1818.2964 - val_loss: 459100.6875\n",
      "Epoch 1662/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1592.2828 - val_loss: 433407.8438\n",
      "Epoch 1663/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1427.9366 - val_loss: 446493.6250\n",
      "Epoch 1664/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1895.8259 - val_loss: 459825.1250\n",
      "Epoch 1665/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1548.5780 - val_loss: 457448.8750\n",
      "Epoch 1666/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1661.9836 - val_loss: 448462.3750\n",
      "Epoch 1667/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1054.1171 - val_loss: 422960.0312\n",
      "Epoch 1668/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1820.5105 - val_loss: 444274.8750\n",
      "Epoch 1669/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2084.4109 - val_loss: 455456.2812\n",
      "Epoch 1670/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1126.3171 - val_loss: 440731.4375\n",
      "Epoch 1671/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1486.9623 - val_loss: 457821.7188\n",
      "Epoch 1672/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1009.2751 - val_loss: 443631.2812\n",
      "Epoch 1673/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1806.1421 - val_loss: 430471.1250\n",
      "Epoch 1674/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 965.7893 - val_loss: 431750.2812\n",
      "Epoch 1675/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 764.0547 - val_loss: 437842.4375\n",
      "Epoch 1676/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 498.3801 - val_loss: 442350.5625\n",
      "Epoch 1677/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 547.5613 - val_loss: 443348.7812\n",
      "Epoch 1678/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 404.9176 - val_loss: 443718.0625\n",
      "Epoch 1679/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 488.4103 - val_loss: 443607.0938\n",
      "Epoch 1680/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 522.5494 - val_loss: 434295.0000\n",
      "Epoch 1681/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 486.6869 - val_loss: 431907.6250\n",
      "Epoch 1682/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 542.7056 - val_loss: 435765.7812\n",
      "Epoch 1683/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 289.4972 - val_loss: 430690.6250\n",
      "Epoch 1684/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 236.8342 - val_loss: 438418.1562\n",
      "Epoch 1685/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 199.4951 - val_loss: 444444.0312\n",
      "Epoch 1686/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 244.9023 - val_loss: 438389.8750\n",
      "Epoch 1687/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 273.6669 - val_loss: 431565.8125\n",
      "Epoch 1688/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 314.2106 - val_loss: 441240.4688\n",
      "Epoch 1689/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 272.5823 - val_loss: 441821.1875\n",
      "Epoch 1690/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 349.9980 - val_loss: 434074.1562\n",
      "Epoch 1691/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 503.2144 - val_loss: 434413.8438\n",
      "Epoch 1692/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 402.2785 - val_loss: 437690.6562\n",
      "Epoch 1693/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 849.9982 - val_loss: 435612.4688\n",
      "Epoch 1694/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 832.3419 - val_loss: 428460.3750\n",
      "Epoch 1695/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 609.5137 - val_loss: 436871.5625\n",
      "Epoch 1696/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 573.5161 - val_loss: 433942.0938\n",
      "Epoch 1697/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 625.7433 - val_loss: 444702.4062\n",
      "Epoch 1698/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1518.4507 - val_loss: 445731.9062\n",
      "Epoch 1699/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1257.8412 - val_loss: 430180.6875\n",
      "Epoch 1700/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 609.5369 - val_loss: 439790.5938\n",
      "Epoch 1701/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 737.3274 - val_loss: 434373.0000\n",
      "Epoch 1702/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 592.3331 - val_loss: 431436.2812\n",
      "Epoch 1703/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 595.9950 - val_loss: 442376.0938\n",
      "Epoch 1704/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 595.3499 - val_loss: 436994.4062\n",
      "Epoch 1705/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 428.4480 - val_loss: 436522.0312\n",
      "Epoch 1706/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 578.5289 - val_loss: 437124.2188\n",
      "Epoch 1707/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 413.3182 - val_loss: 427930.1250\n",
      "Epoch 1708/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 257.4602 - val_loss: 431749.6250\n",
      "Epoch 1709/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 400.2861 - val_loss: 429391.6250\n",
      "Epoch 1710/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 472.5804 - val_loss: 427740.1875\n",
      "Epoch 1711/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 605.3068 - val_loss: 433927.2500\n",
      "Epoch 1712/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1362.1165 - val_loss: 423475.5625\n",
      "Epoch 1713/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 788.6226 - val_loss: 437441.3750\n",
      "Epoch 1714/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 682.0362 - val_loss: 436431.0312\n",
      "Epoch 1715/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 779.9858 - val_loss: 433321.6562\n",
      "Epoch 1716/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 459.3841 - val_loss: 437661.7812\n",
      "Epoch 1717/2000\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 641.8419 - val_loss: 436683.8438\n",
      "Epoch 1718/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 519.8440 - val_loss: 435363.2500\n",
      "Epoch 1719/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 600.3887 - val_loss: 422462.8750\n",
      "Epoch 1720/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 581.9250 - val_loss: 429895.0625\n",
      "Epoch 1721/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 461.4043 - val_loss: 430587.1250\n",
      "Epoch 1722/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 519.3523 - val_loss: 433691.2188\n",
      "Epoch 1723/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 368.7635 - val_loss: 440496.2500\n",
      "Epoch 1724/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 271.1376 - val_loss: 430595.2188\n",
      "Epoch 1725/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 313.5259 - val_loss: 428633.0312\n",
      "Epoch 1726/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 251.3256 - val_loss: 434269.8750\n",
      "Epoch 1727/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 204.4850 - val_loss: 434946.5000\n",
      "Epoch 1728/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 177.0007 - val_loss: 435918.5000\n",
      "Epoch 1729/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 203.4438 - val_loss: 431804.6562\n",
      "Epoch 1730/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 186.5233 - val_loss: 426895.0938\n",
      "Epoch 1731/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 157.8576 - val_loss: 428582.3750\n",
      "Epoch 1732/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 241.9564 - val_loss: 430535.2812\n",
      "Epoch 1733/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 258.7637 - val_loss: 433877.1562\n",
      "Epoch 1734/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 397.4645 - val_loss: 429196.1562\n",
      "Epoch 1735/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 621.1175 - val_loss: 437918.6250\n",
      "Epoch 1736/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 869.7177 - val_loss: 435227.9375\n",
      "Epoch 1737/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 653.2903 - val_loss: 434951.5312\n",
      "Epoch 1738/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1051.6066 - val_loss: 425903.5312\n",
      "Epoch 1739/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1596.1230 - val_loss: 438028.5625\n",
      "Epoch 1740/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2309.6714 - val_loss: 408487.3125\n",
      "Epoch 1741/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2055.2454 - val_loss: 430872.8750\n",
      "Epoch 1742/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 7927.0879 - val_loss: 416346.3750\n",
      "Epoch 1743/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2947.1255 - val_loss: 436319.1250\n",
      "Epoch 1744/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1763.4495 - val_loss: 430252.9062\n",
      "Epoch 1745/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1609.8420 - val_loss: 409359.1250\n",
      "Epoch 1746/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1488.5399 - val_loss: 431514.8750\n",
      "Epoch 1747/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1437.7239 - val_loss: 429601.1562\n",
      "Epoch 1748/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1009.1152 - val_loss: 425809.3750\n",
      "Epoch 1749/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 842.0834 - val_loss: 430408.0625\n",
      "Epoch 1750/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 600.4445 - val_loss: 432364.7500\n",
      "Epoch 1751/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 529.0499 - val_loss: 417388.4688\n",
      "Epoch 1752/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 385.2081 - val_loss: 408735.0312\n",
      "Epoch 1753/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 457.0433 - val_loss: 420995.5938\n",
      "Epoch 1754/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 566.9785 - val_loss: 420705.4062\n",
      "Epoch 1755/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 546.4312 - val_loss: 425094.5625\n",
      "Epoch 1756/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 440.8724 - val_loss: 427448.2500\n",
      "Epoch 1757/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 457.4781 - val_loss: 417633.5938\n",
      "Epoch 1758/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 352.8202 - val_loss: 426879.0938\n",
      "Epoch 1759/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 366.3594 - val_loss: 430173.3125\n",
      "Epoch 1760/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 894.8071 - val_loss: 410010.6250\n",
      "Epoch 1761/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1532.8279 - val_loss: 423803.4375\n",
      "Epoch 1762/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 988.2517 - val_loss: 423911.3125\n",
      "Epoch 1763/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 812.1295 - val_loss: 438489.5000\n",
      "Epoch 1764/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 974.2020 - val_loss: 418242.5938\n",
      "Epoch 1765/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 861.8788 - val_loss: 420699.9375\n",
      "Epoch 1766/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1006.7639 - val_loss: 423540.7188\n",
      "Epoch 1767/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 972.0293 - val_loss: 413127.2188\n",
      "Epoch 1768/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 558.4149 - val_loss: 422627.6250\n",
      "Epoch 1769/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 591.5702 - val_loss: 432952.2812\n",
      "Epoch 1770/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 495.8791 - val_loss: 422552.4062\n",
      "Epoch 1771/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 384.4147 - val_loss: 414592.2188\n",
      "Epoch 1772/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 539.7528 - val_loss: 415491.2500\n",
      "Epoch 1773/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 306.9284 - val_loss: 417706.9062\n",
      "Epoch 1774/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 692.3740 - val_loss: 402815.8125\n",
      "Epoch 1775/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 941.2452 - val_loss: 419642.6875\n",
      "Epoch 1776/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 679.5209 - val_loss: 429526.9688\n",
      "Epoch 1777/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 804.0682 - val_loss: 428931.9375\n",
      "Epoch 1778/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 624.6362 - val_loss: 411948.9688\n",
      "Epoch 1779/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 607.5557 - val_loss: 411394.7500\n",
      "Epoch 1780/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 557.9616 - val_loss: 412421.3438\n",
      "Epoch 1781/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 593.0103 - val_loss: 411190.2812\n",
      "Epoch 1782/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 846.2021 - val_loss: 421484.1875\n",
      "Epoch 1783/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 806.6898 - val_loss: 406259.2812\n",
      "Epoch 1784/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 672.1765 - val_loss: 407904.1875\n",
      "Epoch 1785/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 566.9805 - val_loss: 419785.0312\n",
      "Epoch 1786/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 967.0203 - val_loss: 420830.5938\n",
      "Epoch 1787/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 716.9653 - val_loss: 421476.6875\n",
      "Epoch 1788/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1437.8274 - val_loss: 411317.6250\n",
      "Epoch 1789/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1347.0812 - val_loss: 404312.2188\n",
      "Epoch 1790/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1184.6284 - val_loss: 424678.4062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1791/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 989.0994 - val_loss: 419865.9062\n",
      "Epoch 1792/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1094.3547 - val_loss: 391581.0312\n",
      "Epoch 1793/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 943.6257 - val_loss: 397050.0938\n",
      "Epoch 1794/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1287.9355 - val_loss: 411360.0625\n",
      "Epoch 1795/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1075.6147 - val_loss: 405316.9062\n",
      "Epoch 1796/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1863.8547 - val_loss: 420171.1250\n",
      "Epoch 1797/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1891.4866 - val_loss: 405631.7188\n",
      "Epoch 1798/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2169.1772 - val_loss: 404381.0000\n",
      "Epoch 1799/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1604.8441 - val_loss: 404443.4688\n",
      "Epoch 1800/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1473.0640 - val_loss: 397801.2188\n",
      "Epoch 1801/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1570.1677 - val_loss: 415402.7812\n",
      "Epoch 1802/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1980.8452 - val_loss: 416028.3125\n",
      "Epoch 1803/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1504.6074 - val_loss: 397405.7812\n",
      "Epoch 1804/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1253.6366 - val_loss: 407158.1250\n",
      "Epoch 1805/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 778.1539 - val_loss: 404058.4062\n",
      "Epoch 1806/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 971.9254 - val_loss: 386892.3750\n",
      "Epoch 1807/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 922.7808 - val_loss: 404817.0312\n",
      "Epoch 1808/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 616.5815 - val_loss: 409449.6562\n",
      "Epoch 1809/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 591.7653 - val_loss: 409297.6875\n",
      "Epoch 1810/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 440.2042 - val_loss: 401686.6562\n",
      "Epoch 1811/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 452.0670 - val_loss: 406299.1562\n",
      "Epoch 1812/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 372.3875 - val_loss: 400718.5312\n",
      "Epoch 1813/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 256.4418 - val_loss: 399626.7500\n",
      "Epoch 1814/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 240.0359 - val_loss: 397179.9688\n",
      "Epoch 1815/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 239.7259 - val_loss: 399636.2812\n",
      "Epoch 1816/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 163.7941 - val_loss: 402021.3125\n",
      "Epoch 1817/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 433.1933 - val_loss: 409095.2812\n",
      "Epoch 1818/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 319.0754 - val_loss: 408889.8750\n",
      "Epoch 1819/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 300.3459 - val_loss: 394904.1562\n",
      "Epoch 1820/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 406.2812 - val_loss: 402674.5312\n",
      "Epoch 1821/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 430.3494 - val_loss: 406176.0625\n",
      "Epoch 1822/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 367.8699 - val_loss: 405682.8750\n",
      "Epoch 1823/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 393.3994 - val_loss: 405012.2188\n",
      "Epoch 1824/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 324.6624 - val_loss: 403857.1250\n",
      "Epoch 1825/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 349.8742 - val_loss: 397604.1875\n",
      "Epoch 1826/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 354.2661 - val_loss: 393413.7812\n",
      "Epoch 1827/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 466.9573 - val_loss: 391141.0938\n",
      "Epoch 1828/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 531.7363 - val_loss: 401010.3125\n",
      "Epoch 1829/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 430.7684 - val_loss: 406044.1562\n",
      "Epoch 1830/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 363.9521 - val_loss: 396392.1562\n",
      "Epoch 1831/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 438.7423 - val_loss: 401864.6250\n",
      "Epoch 1832/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 390.7326 - val_loss: 415274.6875\n",
      "Epoch 1833/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 474.1609 - val_loss: 402021.4375\n",
      "Epoch 1834/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 312.7188 - val_loss: 400627.1562\n",
      "Epoch 1835/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1030.9413 - val_loss: 386464.5312\n",
      "Epoch 1836/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1441.8436 - val_loss: 388524.0625\n",
      "Epoch 1837/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2020.8230 - val_loss: 410245.2188\n",
      "Epoch 1838/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2169.5564 - val_loss: 402051.6250\n",
      "Epoch 1839/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2446.4265 - val_loss: 387752.6875\n",
      "Epoch 1840/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1937.0437 - val_loss: 385933.3750\n",
      "Epoch 1841/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2051.5283 - val_loss: 386061.2500\n",
      "Epoch 1842/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2150.5278 - val_loss: 395216.0000\n",
      "Epoch 1843/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2099.9658 - val_loss: 423831.2188\n",
      "Epoch 1844/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2139.9778 - val_loss: 405628.3125\n",
      "Epoch 1845/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1652.8251 - val_loss: 391716.4062\n",
      "Epoch 1846/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1263.3615 - val_loss: 390319.7188\n",
      "Epoch 1847/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1575.0530 - val_loss: 389821.3750\n",
      "Epoch 1848/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1199.9634 - val_loss: 390390.1562\n",
      "Epoch 1849/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 839.2834 - val_loss: 403963.8438\n",
      "Epoch 1850/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 908.3220 - val_loss: 394871.4688\n",
      "Epoch 1851/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 750.5212 - val_loss: 392814.9688\n",
      "Epoch 1852/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 676.7576 - val_loss: 394249.4375\n",
      "Epoch 1853/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 485.0899 - val_loss: 389408.5625\n",
      "Epoch 1854/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 860.7122 - val_loss: 401372.4375\n",
      "Epoch 1855/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 740.9210 - val_loss: 396974.5000\n",
      "Epoch 1856/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 871.4355 - val_loss: 396736.6875\n",
      "Epoch 1857/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1046.6860 - val_loss: 395438.5938\n",
      "Epoch 1858/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 796.6853 - val_loss: 393497.9375\n",
      "Epoch 1859/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 734.8398 - val_loss: 384448.5625\n",
      "Epoch 1860/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2201.0413 - val_loss: 386357.0938\n",
      "Epoch 1861/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1403.8132 - val_loss: 397886.3438\n",
      "Epoch 1862/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 924.3253 - val_loss: 394662.8750\n",
      "Epoch 1863/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 965.9254 - val_loss: 400616.9688\n",
      "Epoch 1864/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 622.1425 - val_loss: 394058.4375\n",
      "Epoch 1865/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 436.5926 - val_loss: 389788.8750\n",
      "Epoch 1866/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 379.8027 - val_loss: 397313.9062\n",
      "Epoch 1867/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 212.8786 - val_loss: 392066.1562\n",
      "Epoch 1868/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 169.1407 - val_loss: 383713.9375\n",
      "Epoch 1869/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 146.5173 - val_loss: 381061.5000\n",
      "Epoch 1870/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 147.6806 - val_loss: 387744.7188\n",
      "Epoch 1871/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 185.9731 - val_loss: 389359.3750\n",
      "Epoch 1872/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 219.2717 - val_loss: 387956.2500\n",
      "Epoch 1873/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 445.0314 - val_loss: 388582.3750\n",
      "Epoch 1874/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 393.3886 - val_loss: 382278.7500\n",
      "Epoch 1875/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 166.1540 - val_loss: 389012.6562\n",
      "Epoch 1876/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 148.1080 - val_loss: 389061.0000\n",
      "Epoch 1877/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 120.4605 - val_loss: 387562.5625\n",
      "Epoch 1878/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 342.6914 - val_loss: 391401.0312\n",
      "Epoch 1879/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 200.9303 - val_loss: 387728.7500\n",
      "Epoch 1880/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 98.2385 - val_loss: 390484.9062\n",
      "Epoch 1881/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 85.4980 - val_loss: 385396.2812\n",
      "Epoch 1882/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 77.8090 - val_loss: 384768.4375\n",
      "Epoch 1883/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 56.6817 - val_loss: 387093.9062\n",
      "Epoch 1884/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 53.2669 - val_loss: 386959.4375\n",
      "Epoch 1885/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 51.2266 - val_loss: 385317.7188\n",
      "Epoch 1886/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 61.9031 - val_loss: 387376.7188\n",
      "Epoch 1887/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 88.6768 - val_loss: 386619.6875\n",
      "Epoch 1888/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 86.8162 - val_loss: 387946.9062\n",
      "Epoch 1889/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 72.4351 - val_loss: 384843.9062\n",
      "Epoch 1890/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 80.1991 - val_loss: 387281.5000\n",
      "Epoch 1891/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 234.6043 - val_loss: 384554.3750\n",
      "Epoch 1892/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 180.3114 - val_loss: 383891.0312\n",
      "Epoch 1893/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 505.1401 - val_loss: 391514.6875\n",
      "Epoch 1894/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 706.8800 - val_loss: 382527.5000\n",
      "Epoch 1895/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 611.9251 - val_loss: 382646.3750\n",
      "Epoch 1896/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 412.9966 - val_loss: 380086.7812\n",
      "Epoch 1897/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 318.7892 - val_loss: 385904.6250\n",
      "Epoch 1898/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 273.5624 - val_loss: 377559.8125\n",
      "Epoch 1899/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 267.5602 - val_loss: 382515.1250\n",
      "Epoch 1900/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 304.4721 - val_loss: 384223.7812\n",
      "Epoch 1901/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 287.5470 - val_loss: 391555.4688\n",
      "Epoch 1902/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 443.5537 - val_loss: 381617.7812\n",
      "Epoch 1903/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 412.0028 - val_loss: 382733.7812\n",
      "Epoch 1904/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 381.0470 - val_loss: 389188.0625\n",
      "Epoch 1905/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 354.2938 - val_loss: 386734.6875\n",
      "Epoch 1906/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 279.4681 - val_loss: 381194.7812\n",
      "Epoch 1907/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 259.6932 - val_loss: 381116.1875\n",
      "Epoch 1908/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 248.5742 - val_loss: 385252.5625\n",
      "Epoch 1909/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 286.0859 - val_loss: 384334.9688\n",
      "Epoch 1910/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 469.8904 - val_loss: 386257.2188\n",
      "Epoch 1911/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 533.8928 - val_loss: 391559.4375\n",
      "Epoch 1912/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 482.7273 - val_loss: 385980.2812\n",
      "Epoch 1913/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 618.5599 - val_loss: 389717.4375\n",
      "Epoch 1914/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 525.4050 - val_loss: 384626.5312\n",
      "Epoch 1915/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 391.8559 - val_loss: 392449.0312\n",
      "Epoch 1916/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 450.9252 - val_loss: 390374.3438\n",
      "Epoch 1917/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 590.9397 - val_loss: 386919.0312\n",
      "Epoch 1918/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 625.9579 - val_loss: 382074.5938\n",
      "Epoch 1919/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 594.2094 - val_loss: 377169.9688\n",
      "Epoch 1920/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 489.4719 - val_loss: 372575.1562\n",
      "Epoch 1921/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 486.4606 - val_loss: 379381.1250\n",
      "Epoch 1922/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 475.5761 - val_loss: 374564.5625\n",
      "Epoch 1923/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 639.0720 - val_loss: 384653.3438\n",
      "Epoch 1924/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 635.8817 - val_loss: 397113.3750\n",
      "Epoch 1925/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1791.2172 - val_loss: 380670.3438\n",
      "Epoch 1926/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1386.4580 - val_loss: 363408.6250\n",
      "Epoch 1927/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1703.8899 - val_loss: 375666.3750\n",
      "Epoch 1928/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1709.0941 - val_loss: 390508.7188\n",
      "Epoch 1929/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1746.0751 - val_loss: 388173.6562\n",
      "Epoch 1930/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1788.7732 - val_loss: 396091.0312\n",
      "Epoch 1931/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2201.3430 - val_loss: 376170.4375\n",
      "Epoch 1932/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2081.5361 - val_loss: 357892.4375\n",
      "Epoch 1933/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1932.7747 - val_loss: 355225.1875\n",
      "Epoch 1934/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3306.5833 - val_loss: 376595.6250\n",
      "Epoch 1935/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4442.5913 - val_loss: 338467.5000\n",
      "Epoch 1936/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4133.2202 - val_loss: 348422.8438\n",
      "Epoch 1937/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2952.1394 - val_loss: 371148.4375\n",
      "Epoch 1938/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1866.8132 - val_loss: 368682.3750\n",
      "Epoch 1939/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2004.0304 - val_loss: 365361.8750\n",
      "Epoch 1940/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1485.7241 - val_loss: 362482.6875\n",
      "Epoch 1941/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1073.0244 - val_loss: 351514.2812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1942/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 983.8611 - val_loss: 367480.5000\n",
      "Epoch 1943/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1005.9696 - val_loss: 365213.1250\n",
      "Epoch 1944/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 802.0586 - val_loss: 367209.2500\n",
      "Epoch 1945/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 606.7014 - val_loss: 359187.1250\n",
      "Epoch 1946/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 562.3105 - val_loss: 364230.1875\n",
      "Epoch 1947/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 564.7396 - val_loss: 366723.9375\n",
      "Epoch 1948/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 388.9337 - val_loss: 372625.8438\n",
      "Epoch 1949/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 482.5229 - val_loss: 371250.5000\n",
      "Epoch 1950/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 746.6857 - val_loss: 361622.6875\n",
      "Epoch 1951/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 816.4228 - val_loss: 354977.2188\n",
      "Epoch 1952/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 867.1277 - val_loss: 364985.0000\n",
      "Epoch 1953/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 655.7052 - val_loss: 371843.0625\n",
      "Epoch 1954/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 676.7600 - val_loss: 368485.1562\n",
      "Epoch 1955/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1242.2870 - val_loss: 354584.9062\n",
      "Epoch 1956/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 849.1107 - val_loss: 344570.5000\n",
      "Epoch 1957/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 851.9269 - val_loss: 354781.9062\n",
      "Epoch 1958/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1506.1814 - val_loss: 373040.1562\n",
      "Epoch 1959/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1146.3949 - val_loss: 360493.3750\n",
      "Epoch 1960/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2681.8413 - val_loss: 378186.9062\n",
      "Epoch 1961/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1879.4703 - val_loss: 375716.7188\n",
      "Epoch 1962/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 971.6730 - val_loss: 368688.0938\n",
      "Epoch 1963/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 775.3893 - val_loss: 359564.4688\n",
      "Epoch 1964/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 700.5509 - val_loss: 375486.1875\n",
      "Epoch 1965/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 612.1745 - val_loss: 371103.3125\n",
      "Epoch 1966/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 484.5494 - val_loss: 360115.4375\n",
      "Epoch 1967/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 406.5670 - val_loss: 359708.6875\n",
      "Epoch 1968/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 399.8777 - val_loss: 353110.7500\n",
      "Epoch 1969/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 394.3484 - val_loss: 359814.5312\n",
      "Epoch 1970/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 234.5549 - val_loss: 352741.8750\n",
      "Epoch 1971/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 522.0385 - val_loss: 356299.9688\n",
      "Epoch 1972/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 309.9041 - val_loss: 361190.6250\n",
      "Epoch 1973/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 287.3487 - val_loss: 361522.3438\n",
      "Epoch 1974/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 217.0707 - val_loss: 355643.8125\n",
      "Epoch 1975/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 252.0971 - val_loss: 352726.9688\n",
      "Epoch 1976/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 174.3345 - val_loss: 358312.7188\n",
      "Epoch 1977/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 147.3157 - val_loss: 359626.2188\n",
      "Epoch 1978/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 132.1889 - val_loss: 361209.9688\n",
      "Epoch 1979/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 135.1110 - val_loss: 354272.8438\n",
      "Epoch 1980/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 133.5757 - val_loss: 360871.9688\n",
      "Epoch 1981/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 158.8876 - val_loss: 355279.0938\n",
      "Epoch 1982/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 147.2303 - val_loss: 355775.1250\n",
      "Epoch 1983/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 218.0161 - val_loss: 354481.9688\n",
      "Epoch 1984/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 223.8128 - val_loss: 356822.1562\n",
      "Epoch 1985/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 177.6388 - val_loss: 357132.4062\n",
      "Epoch 1986/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 131.3250 - val_loss: 356340.0625\n",
      "Epoch 1987/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 88.0022 - val_loss: 354610.6562\n",
      "Epoch 1988/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 73.9691 - val_loss: 355363.0625\n",
      "Epoch 1989/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 73.5850 - val_loss: 355793.2500\n",
      "Epoch 1990/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 72.3876 - val_loss: 357600.8750\n",
      "Epoch 1991/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 90.0649 - val_loss: 357469.7812\n",
      "Epoch 1992/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 83.1496 - val_loss: 353929.4688\n",
      "Epoch 1993/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 83.6688 - val_loss: 356394.6250\n",
      "Epoch 1994/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 97.4695 - val_loss: 358161.7812\n",
      "Epoch 1995/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 93.2219 - val_loss: 356024.0312\n",
      "Epoch 1996/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 83.2288 - val_loss: 357804.9062\n",
      "Epoch 1997/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 83.1156 - val_loss: 357305.4375\n",
      "Epoch 1998/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 85.4134 - val_loss: 359178.5938\n",
      "Epoch 1999/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 86.6707 - val_loss: 358328.7500\n",
      "Epoch 2000/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 105.8701 - val_loss: 358319.4375\n",
      "CPU times: user 2min 3s, sys: 6.04 s, total: 2min 10s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(\n",
    "    standardized, std_y,\n",
    "    epochs=2000,\n",
    "    batch_size = 100,\n",
    "    verbose=1,\n",
    "    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -15.432102],\n",
       "       [ 297.6093  ],\n",
       "       [ 373.1502  ],\n",
       "       [ 227.10942 ],\n",
       "       [ 642.4638  ],\n",
       "       [ 102.028496],\n",
       "       [ 108.44912 ],\n",
       "       [-123.269745],\n",
       "       [ -81.30785 ]], dtype=float32)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized_test = scaler.transform(BTC_test_x)\n",
    "\n",
    "pred = model.predict(standardized_test)\n",
    "pred[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd409bbe490>]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pred[1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd409e2afa0>]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(BTC_test_y[1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    " keras.layers.Reshape((1,1)),\n",
    " keras.layers.SimpleRNN(1, return_sequences=False),\n",
    " keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
    "    loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "561/561 [==============================] - 1s 861us/step - loss: 3111542336.6833 - val_loss: 2888495616.0000\n",
      "Epoch 2/250\n",
      "561/561 [==============================] - 0s 637us/step - loss: 3098593049.0534 - val_loss: 2876461824.0000\n",
      "Epoch 3/250\n",
      "561/561 [==============================] - 0s 638us/step - loss: 3086175480.2562 - val_loss: 2864463360.0000\n",
      "Epoch 4/250\n",
      "561/561 [==============================] - 0s 630us/step - loss: 3073912424.3132 - val_loss: 2852495104.0000\n",
      "Epoch 5/250\n",
      "561/561 [==============================] - 0s 631us/step - loss: 3062032983.0036 - val_loss: 2840556800.0000\n",
      "Epoch 6/250\n",
      "561/561 [==============================] - 0s 639us/step - loss: 3048887410.3345 - val_loss: 2828646144.0000\n",
      "Epoch 7/250\n",
      "561/561 [==============================] - 0s 639us/step - loss: 3037192880.7402 - val_loss: 2816763136.0000\n",
      "Epoch 8/250\n",
      "561/561 [==============================] - 0s 634us/step - loss: 3024417486.3488 - val_loss: 2804906240.0000\n",
      "Epoch 9/250\n",
      "561/561 [==============================] - 0s 632us/step - loss: 3012350877.6085 - val_loss: 2793076224.0000\n",
      "Epoch 10/250\n",
      "561/561 [==============================] - 0s 632us/step - loss: 2999211010.7331 - val_loss: 2781271552.0000\n",
      "Epoch 11/250\n",
      "561/561 [==============================] - 0s 633us/step - loss: 2987559440.8541 - val_loss: 2769491456.0000\n",
      "Epoch 12/250\n",
      "561/561 [==============================] - 0s 644us/step - loss: 2975597452.2989 - val_loss: 2757737728.0000\n",
      "Epoch 13/250\n",
      "561/561 [==============================] - 1s 975us/step - loss: 2963238326.6619 - val_loss: 2746008320.0000\n",
      "Epoch 14/250\n",
      "561/561 [==============================] - 0s 637us/step - loss: 2950731503.1459 - val_loss: 2734305536.0000\n",
      "Epoch 15/250\n",
      "561/561 [==============================] - 0s 636us/step - loss: 2938987923.5872 - val_loss: 2722626560.0000\n",
      "Epoch 16/250\n",
      "561/561 [==============================] - 0s 642us/step - loss: 2927067928.1423 - val_loss: 2710972928.0000\n",
      "Epoch 17/250\n",
      "561/561 [==============================] - 0s 638us/step - loss: 2914495101.2669 - val_loss: 2699344384.0000\n",
      "Epoch 18/250\n",
      "561/561 [==============================] - 0s 638us/step - loss: 2902761087.0890 - val_loss: 2687742464.0000\n",
      "Epoch 19/250\n",
      "561/561 [==============================] - 0s 634us/step - loss: 2890154795.7295 - val_loss: 2676164608.0000\n",
      "Epoch 20/250\n",
      "561/561 [==============================] - 0s 642us/step - loss: 2879258855.8577 - val_loss: 2664611328.0000\n",
      "Epoch 21/250\n",
      "561/561 [==============================] - 0s 637us/step - loss: 2866755717.4662 - val_loss: 2653083904.0000\n",
      "Epoch 22/250\n",
      "561/561 [==============================] - 0s 638us/step - loss: 2854546651.1032 - val_loss: 2641581312.0000\n",
      "Epoch 23/250\n",
      "561/561 [==============================] - 0s 647us/step - loss: 2843377301.8648 - val_loss: 2630103296.0000\n",
      "Epoch 24/250\n",
      "561/561 [==============================] - 0s 634us/step - loss: 2830945822.5196 - val_loss: 2618650880.0000\n",
      "Epoch 25/250\n",
      "561/561 [==============================] - 0s 642us/step - loss: 2819438859.3879 - val_loss: 2607223552.0000\n",
      "Epoch 26/250\n",
      "561/561 [==============================] - 0s 635us/step - loss: 2807804773.1246 - val_loss: 2595821056.0000\n",
      "Epoch 27/250\n",
      "561/561 [==============================] - 0s 638us/step - loss: 2794818114.5053 - val_loss: 2584443392.0000\n",
      "Epoch 28/250\n",
      "561/561 [==============================] - 0s 643us/step - loss: 2783087144.9964 - val_loss: 2573091840.0000\n",
      "Epoch 29/250\n",
      "561/561 [==============================] - 0s 628us/step - loss: 2771421320.1993 - val_loss: 2561765632.0000\n",
      "Epoch 30/250\n",
      "561/561 [==============================] - 0s 647us/step - loss: 2759821217.7082 - val_loss: 2550462464.0000\n",
      "Epoch 31/250\n",
      "561/561 [==============================] - 0s 641us/step - loss: 2747661025.9359 - val_loss: 2539185664.0000\n",
      "Epoch 32/250\n",
      "561/561 [==============================] - 0s 644us/step - loss: 2736754078.0641 - val_loss: 2527934208.0000\n",
      "Epoch 33/250\n",
      "561/561 [==============================] - 0s 645us/step - loss: 2724998181.8078 - val_loss: 2516708352.0000\n",
      "Epoch 34/250\n",
      "561/561 [==============================] - 0s 645us/step - loss: 2712818019.3025 - val_loss: 2505505280.0000\n",
      "Epoch 35/250\n",
      "561/561 [==============================] - 0s 655us/step - loss: 2702217896.5409 - val_loss: 2494328832.0000\n",
      "Epoch 36/250\n",
      "561/561 [==============================] - 0s 647us/step - loss: 2689553623.4591 - val_loss: 2483177216.0000\n",
      "Epoch 37/250\n",
      "561/561 [==============================] - 0s 647us/step - loss: 2678085502.6335 - val_loss: 2472050944.0000\n",
      "Epoch 38/250\n",
      "561/561 [==============================] - 0s 630us/step - loss: 2667359249.7651 - val_loss: 2460949760.0000\n",
      "Epoch 39/250\n",
      "561/561 [==============================] - 0s 641us/step - loss: 2655825673.1103 - val_loss: 2449875200.0000\n",
      "Epoch 40/250\n",
      "561/561 [==============================] - 0s 641us/step - loss: 2643403935.4306 - val_loss: 2438823936.0000\n",
      "Epoch 41/250\n",
      "561/561 [==============================] - 0s 638us/step - loss: 2632749808.5125 - val_loss: 2427799040.0000\n",
      "Epoch 42/250\n",
      "561/561 [==============================] - 0s 638us/step - loss: 2621129102.1210 - val_loss: 2416797952.0000\n",
      "Epoch 43/250\n",
      "561/561 [==============================] - 0s 640us/step - loss: 2609345055.4306 - val_loss: 2405822720.0000\n",
      "Epoch 44/250\n",
      "561/561 [==============================] - 0s 638us/step - loss: 2598105377.2527 - val_loss: 2394871808.0000\n",
      "Epoch 45/250\n",
      "561/561 [==============================] - 0s 643us/step - loss: 2586213262.5765 - val_loss: 2383945728.0000\n",
      "Epoch 46/250\n",
      "561/561 [==============================] - 0s 641us/step - loss: 2575420976.2847 - val_loss: 2373044736.0000\n",
      "Epoch 47/250\n",
      "561/561 [==============================] - 0s 635us/step - loss: 2563849864.1993 - val_loss: 2362169344.0000\n",
      "Epoch 48/250\n",
      "561/561 [==============================] - 0s 639us/step - loss: 2552573135.2598 - val_loss: 2351317504.0000\n",
      "Epoch 49/250\n",
      "561/561 [==============================] - 0s 632us/step - loss: 2541543342.4626 - val_loss: 2340492288.0000\n",
      "Epoch 50/250\n",
      "561/561 [==============================] - 0s 658us/step - loss: 2529973679.3737 - val_loss: 2329691392.0000\n",
      "Epoch 51/250\n",
      "561/561 [==============================] - 0s 643us/step - loss: 2518696874.8185 - val_loss: 2318915840.0000\n",
      "Epoch 52/250\n",
      "561/561 [==============================] - 0s 642us/step - loss: 2508461504.2278 - val_loss: 2308165376.0000\n",
      "Epoch 53/250\n",
      "561/561 [==============================] - 0s 636us/step - loss: 2495719361.1388 - val_loss: 2297440256.0000\n",
      "Epoch 54/250\n",
      "561/561 [==============================] - 0s 634us/step - loss: 2485638088.8826 - val_loss: 2286739200.0000\n",
      "Epoch 55/250\n",
      "561/561 [==============================] - 0s 628us/step - loss: 2474159665.1957 - val_loss: 2276063744.0000\n",
      "Epoch 56/250\n",
      "561/561 [==============================] - 0s 631us/step - loss: 2462907175.1744 - val_loss: 2265413120.0000\n",
      "Epoch 57/250\n",
      "561/561 [==============================] - 0s 629us/step - loss: 2452081349.2384 - val_loss: 2254787072.0000\n",
      "Epoch 58/250\n",
      "561/561 [==============================] - 0s 637us/step - loss: 2440869236.1566 - val_loss: 2244186112.0000\n",
      "Epoch 59/250\n",
      "561/561 [==============================] - 0s 633us/step - loss: 2429420236.9822 - val_loss: 2233610240.0000\n",
      "Epoch 60/250\n",
      "561/561 [==============================] - 0s 637us/step - loss: 2418341426.1068 - val_loss: 2223059456.0000\n",
      "Epoch 61/250\n",
      "561/561 [==============================] - 0s 638us/step - loss: 2408293288.0854 - val_loss: 2212533760.0000\n",
      "Epoch 62/250\n",
      "561/561 [==============================] - 0s 629us/step - loss: 2397185782.8897 - val_loss: 2202033664.0000\n",
      "Epoch 63/250\n",
      "561/561 [==============================] - 0s 632us/step - loss: 2386217838.6904 - val_loss: 2191556352.0000\n",
      "Epoch 64/250\n",
      "561/561 [==============================] - 0s 631us/step - loss: 2375540591.6014 - val_loss: 2181106176.0000\n",
      "Epoch 65/250\n",
      "561/561 [==============================] - 0s 637us/step - loss: 2364970916.4413 - val_loss: 2170680320.0000\n",
      "Epoch 66/250\n",
      "561/561 [==============================] - 0s 641us/step - loss: 2353585324.1851 - val_loss: 2160280064.0000\n",
      "Epoch 67/250\n",
      "561/561 [==============================] - 0s 636us/step - loss: 2342147392.2278 - val_loss: 2149904384.0000\n",
      "Epoch 68/250\n",
      "561/561 [==============================] - 0s 628us/step - loss: 2331581131.1601 - val_loss: 2139555072.0000\n",
      "Epoch 69/250\n",
      "561/561 [==============================] - 0s 633us/step - loss: 2320446183.4021 - val_loss: 2129228288.0000\n",
      "Epoch 70/250\n",
      "561/561 [==============================] - 0s 631us/step - loss: 2310230686.9751 - val_loss: 2118927616.0000\n",
      "Epoch 71/250\n",
      "561/561 [==============================] - 0s 628us/step - loss: 2299337623.6868 - val_loss: 2108652416.0000\n",
      "Epoch 72/250\n",
      "561/561 [==============================] - 0s 627us/step - loss: 2288440456.6548 - val_loss: 2098402176.0000\n",
      "Epoch 73/250\n",
      "561/561 [==============================] - 0s 636us/step - loss: 2278599039.0890 - val_loss: 2088175360.0000\n",
      "Epoch 74/250\n",
      "561/561 [==============================] - 0s 625us/step - loss: 2266896874.5907 - val_loss: 2077975424.0000\n",
      "Epoch 75/250\n",
      "561/561 [==============================] - 0s 627us/step - loss: 2256624704.2278 - val_loss: 2067798784.0000\n",
      "Epoch 76/250\n",
      "561/561 [==============================] - 0s 631us/step - loss: 2246356991.5445 - val_loss: 2057647488.0000\n",
      "Epoch 77/250\n",
      "561/561 [==============================] - 0s 626us/step - loss: 2235256196.5552 - val_loss: 2047521024.0000\n",
      "Epoch 78/250\n",
      "561/561 [==============================] - 0s 638us/step - loss: 2225599539.9288 - val_loss: 2037420544.0000\n",
      "Epoch 79/250\n",
      "561/561 [==============================] - 0s 632us/step - loss: 2214255636.4982 - val_loss: 2027343360.0000\n",
      "Epoch 80/250\n",
      "561/561 [==============================] - 0s 625us/step - loss: 2204257873.5374 - val_loss: 2017292160.0000\n",
      "Epoch 81/250\n",
      "561/561 [==============================] - 0s 630us/step - loss: 2194274309.4662 - val_loss: 2007266560.0000\n",
      "Epoch 82/250\n",
      "561/561 [==============================] - 0s 637us/step - loss: 2183505002.1352 - val_loss: 1997263488.0000\n",
      "Epoch 83/250\n",
      "561/561 [==============================] - 0s 626us/step - loss: 2172173135.2598 - val_loss: 1987288448.0000\n",
      "Epoch 84/250\n",
      "561/561 [==============================] - 0s 630us/step - loss: 2162523368.3132 - val_loss: 1977337216.0000\n",
      "Epoch 85/250\n",
      "561/561 [==============================] - 0s 627us/step - loss: 2152350821.1246 - val_loss: 1967410432.0000\n",
      "Epoch 86/250\n",
      "561/561 [==============================] - 0s 630us/step - loss: 2141629717.6370 - val_loss: 1957509376.0000\n",
      "Epoch 87/250\n",
      "561/561 [==============================] - 0s 629us/step - loss: 2132586212.6690 - val_loss: 1947632384.0000\n",
      "Epoch 88/250\n",
      "561/561 [==============================] - 0s 630us/step - loss: 2120770322.6762 - val_loss: 1937781632.0000\n",
      "Epoch 89/250\n",
      "561/561 [==============================] - 0s 628us/step - loss: 2110470850.7331 - val_loss: 1927953792.0000\n",
      "Epoch 90/250\n",
      "561/561 [==============================] - 0s 627us/step - loss: 2100371388.1281 - val_loss: 1918152704.0000\n",
      "Epoch 91/250\n",
      "561/561 [==============================] - 0s 631us/step - loss: 2091106630.3772 - val_loss: 1908376448.0000\n",
      "Epoch 92/250\n",
      "561/561 [==============================] - 0s 627us/step - loss: 2080038292.2705 - val_loss: 1898625408.0000\n",
      "Epoch 93/250\n",
      "561/561 [==============================] - 0s 631us/step - loss: 2069513072.9680 - val_loss: 1888898176.0000\n",
      "Epoch 94/250\n",
      "561/561 [==============================] - 0s 624us/step - loss: 2059503457.0249 - val_loss: 1879196544.0000\n",
      "Epoch 95/250\n",
      "561/561 [==============================] - 0s 629us/step - loss: 2049226203.7865 - val_loss: 1869519744.0000\n",
      "Epoch 96/250\n",
      "561/561 [==============================] - 0s 637us/step - loss: 2039395208.4270 - val_loss: 1859868928.0000\n",
      "Epoch 97/250\n",
      "561/561 [==============================] - 0s 628us/step - loss: 2029729779.4733 - val_loss: 1850241536.0000\n",
      "Epoch 98/250\n",
      "561/561 [==============================] - 0s 625us/step - loss: 2019728307.7011 - val_loss: 1840639872.0000\n",
      "Epoch 99/250\n",
      "561/561 [==============================] - 0s 630us/step - loss: 2009428172.2989 - val_loss: 1831062912.0000\n",
      "Epoch 100/250\n",
      "561/561 [==============================] - 0s 630us/step - loss: 1999210574.3488 - val_loss: 1821511680.0000\n",
      "Epoch 101/250\n",
      "561/561 [==============================] - 0s 637us/step - loss: 1989561129.9075 - val_loss: 1811985152.0000\n",
      "Epoch 102/250\n",
      "561/561 [==============================] - 0s 624us/step - loss: 1979384835.1886 - val_loss: 1802483328.0000\n",
      "Epoch 103/250\n",
      "561/561 [==============================] - 0s 637us/step - loss: 1969734422.0925 - val_loss: 1793006336.0000\n",
      "Epoch 104/250\n",
      "561/561 [==============================] - 0s 630us/step - loss: 1958884601.3950 - val_loss: 1783555072.0000\n",
      "Epoch 105/250\n",
      "561/561 [==============================] - 0s 627us/step - loss: 1948896587.8434 - val_loss: 1774128128.0000\n",
      "Epoch 106/250\n",
      "561/561 [==============================] - 0s 623us/step - loss: 1940131215.7153 - val_loss: 1764726528.0000\n",
      "Epoch 107/250\n",
      "561/561 [==============================] - 0s 639us/step - loss: 1929242240.9110 - val_loss: 1755349760.0000\n",
      "Epoch 108/250\n",
      "561/561 [==============================] - 0s 629us/step - loss: 1920218109.9502 - val_loss: 1745997312.0000\n",
      "Epoch 109/250\n",
      "561/561 [==============================] - 0s 628us/step - loss: 1909864330.0214 - val_loss: 1736670976.0000\n",
      "Epoch 110/250\n",
      "561/561 [==============================] - 0s 621us/step - loss: 1901192737.4804 - val_loss: 1727368704.0000\n",
      "Epoch 111/250\n",
      "561/561 [==============================] - 0s 630us/step - loss: 1890970110.1779 - val_loss: 1718092032.0000\n",
      "Epoch 112/250\n",
      "561/561 [==============================] - 0s 631us/step - loss: 1880255651.5302 - val_loss: 1708840064.0000\n",
      "Epoch 113/250\n",
      "561/561 [==============================] - 0s 633us/step - loss: 1871635178.5907 - val_loss: 1699613568.0000\n",
      "Epoch 114/250\n",
      "561/561 [==============================] - 0s 625us/step - loss: 1862509576.1993 - val_loss: 1690411392.0000\n",
      "Epoch 115/250\n",
      "561/561 [==============================] - 0s 617us/step - loss: 1852685759.7722 - val_loss: 1681233664.0000\n",
      "Epoch 116/250\n",
      "561/561 [==============================] - 0s 621us/step - loss: 1842185478.1495 - val_loss: 1672082304.0000\n",
      "Epoch 117/250\n",
      "561/561 [==============================] - 0s 629us/step - loss: 1833189991.6299 - val_loss: 1662955648.0000\n",
      "Epoch 118/250\n",
      "561/561 [==============================] - 0s 622us/step - loss: 1822684870.1495 - val_loss: 1653853696.0000\n",
      "Epoch 119/250\n",
      "561/561 [==============================] - 0s 635us/step - loss: 1814948609.8221 - val_loss: 1644776320.0000\n",
      "Epoch 120/250\n",
      "561/561 [==============================] - 0s 623us/step - loss: 1804686030.1210 - val_loss: 1635724288.0000\n",
      "Epoch 121/250\n",
      "561/561 [==============================] - 0s 630us/step - loss: 1795305450.5907 - val_loss: 1626697728.0000\n",
      "Epoch 122/250\n",
      "561/561 [==============================] - 0s 625us/step - loss: 1785637463.2313 - val_loss: 1617695872.0000\n",
      "Epoch 123/250\n",
      "561/561 [==============================] - 0s 625us/step - loss: 1776239459.0747 - val_loss: 1608718720.0000\n",
      "Epoch 124/250\n",
      "561/561 [==============================] - 0s 627us/step - loss: 1766590803.1317 - val_loss: 1599766144.0000\n",
      "Epoch 125/250\n",
      "561/561 [==============================] - 0s 624us/step - loss: 1756343045.2384 - val_loss: 1590839040.0000\n",
      "Epoch 126/250\n",
      "561/561 [==============================] - 0s 630us/step - loss: 1748075753.2242 - val_loss: 1581937792.0000\n",
      "Epoch 127/250\n",
      "561/561 [==============================] - 0s 638us/step - loss: 1739337522.5623 - val_loss: 1573060352.0000\n",
      "Epoch 128/250\n",
      "561/561 [==============================] - 0s 631us/step - loss: 1729384680.3132 - val_loss: 1564208000.0000\n",
      "Epoch 129/250\n",
      "561/561 [==============================] - 0s 644us/step - loss: 1719341155.9858 - val_loss: 1555381120.0000\n",
      "Epoch 130/250\n",
      "561/561 [==============================] - 0s 640us/step - loss: 1711019864.3701 - val_loss: 1546578560.0000\n",
      "Epoch 131/250\n",
      "561/561 [==============================] - 0s 628us/step - loss: 1701510172.0142 - val_loss: 1537803264.0000\n",
      "Epoch 132/250\n",
      "561/561 [==============================] - 0s 626us/step - loss: 1692082298.0783 - val_loss: 1529051392.0000\n",
      "Epoch 133/250\n",
      "561/561 [==============================] - 0s 630us/step - loss: 1683157741.3238 - val_loss: 1520324096.0000\n",
      "Epoch 134/250\n",
      "561/561 [==============================] - 0s 638us/step - loss: 1674244675.4164 - val_loss: 1511621504.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/250\n",
      "561/561 [==============================] - 0s 624us/step - loss: 1664486578.1068 - val_loss: 1502945664.0000\n",
      "Epoch 136/250\n",
      "561/561 [==============================] - 0s 626us/step - loss: 1656060745.5658 - val_loss: 1494292864.0000\n",
      "Epoch 137/250\n",
      "561/561 [==============================] - 0s 631us/step - loss: 1647751118.8043 - val_loss: 1485666432.0000\n",
      "Epoch 138/250\n",
      "561/561 [==============================] - 0s 638us/step - loss: 1636647279.6014 - val_loss: 1477064704.0000\n",
      "Epoch 139/250\n",
      "561/561 [==============================] - 0s 623us/step - loss: 1628731874.3915 - val_loss: 1468487040.0000\n",
      "Epoch 140/250\n",
      "561/561 [==============================] - 0s 620us/step - loss: 1620048661.8648 - val_loss: 1459934976.0000\n",
      "Epoch 141/250\n",
      "561/561 [==============================] - 0s 624us/step - loss: 1611021236.1566 - val_loss: 1451408000.0000\n",
      "Epoch 142/250\n",
      "561/561 [==============================] - 0s 622us/step - loss: 1602245009.7651 - val_loss: 1442905088.0000\n",
      "Epoch 143/250\n",
      "561/561 [==============================] - 0s 626us/step - loss: 1592634269.8363 - val_loss: 1434428288.0000\n",
      "Epoch 144/250\n",
      "561/561 [==============================] - 0s 623us/step - loss: 1583622839.8007 - val_loss: 1425975680.0000\n",
      "Epoch 145/250\n",
      "561/561 [==============================] - 0s 628us/step - loss: 1575019729.0819 - val_loss: 1417548416.0000\n",
      "Epoch 146/250\n",
      "561/561 [==============================] - 0s 625us/step - loss: 1566085866.8185 - val_loss: 1409146496.0000\n",
      "Epoch 147/250\n",
      "561/561 [==============================] - 0s 634us/step - loss: 1557054051.9858 - val_loss: 1400768768.0000\n",
      "Epoch 148/250\n",
      "561/561 [==============================] - 0s 619us/step - loss: 1548383267.9858 - val_loss: 1392415744.0000\n",
      "Epoch 149/250\n",
      "561/561 [==============================] - 0s 621us/step - loss: 1539835859.1317 - val_loss: 1384088320.0000\n",
      "Epoch 150/250\n",
      "561/561 [==============================] - 0s 630us/step - loss: 1531072526.1210 - val_loss: 1375786240.0000\n",
      "Epoch 151/250\n",
      "561/561 [==============================] - 0s 622us/step - loss: 1522294129.8790 - val_loss: 1367508480.0000\n",
      "Epoch 152/250\n",
      "561/561 [==============================] - 0s 627us/step - loss: 1513649549.4377 - val_loss: 1359255424.0000\n",
      "Epoch 153/250\n",
      "561/561 [==============================] - 0s 625us/step - loss: 1505174262.2064 - val_loss: 1351027584.0000\n",
      "Epoch 154/250\n",
      "561/561 [==============================] - 0s 627us/step - loss: 1496287042.7331 - val_loss: 1342824576.0000\n",
      "Epoch 155/250\n",
      "561/561 [==============================] - 0s 628us/step - loss: 1487932324.6690 - val_loss: 1334647552.0000\n",
      "Epoch 156/250\n",
      "561/561 [==============================] - 0s 619us/step - loss: 1479593673.1103 - val_loss: 1326494848.0000\n",
      "Epoch 157/250\n",
      "561/561 [==============================] - 0s 623us/step - loss: 1470348310.5480 - val_loss: 1318366592.0000\n",
      "Epoch 158/250\n",
      "561/561 [==============================] - 0s 635us/step - loss: 1461266017.7082 - val_loss: 1310263936.0000\n",
      "Epoch 159/250\n",
      "561/561 [==============================] - 0s 630us/step - loss: 1453117121.1388 - val_loss: 1302186368.0000\n",
      "Epoch 160/250\n",
      "561/561 [==============================] - 0s 628us/step - loss: 1444553304.8256 - val_loss: 1294132608.0000\n",
      "Epoch 161/250\n",
      "561/561 [==============================] - 0s 628us/step - loss: 1435860658.3345 - val_loss: 1286105216.0000\n",
      "Epoch 162/250\n",
      "561/561 [==============================] - 0s 625us/step - loss: 1427327477.9786 - val_loss: 1278102016.0000\n",
      "Epoch 163/250\n",
      "561/561 [==============================] - 0s 626us/step - loss: 1419408131.8719 - val_loss: 1270124032.0000\n",
      "Epoch 164/250\n",
      "561/561 [==============================] - 0s 623us/step - loss: 1410761104.1708 - val_loss: 1262171648.0000\n",
      "Epoch 165/250\n",
      "561/561 [==============================] - 0s 625us/step - loss: 1402576837.2384 - val_loss: 1254243584.0000\n",
      "Epoch 166/250\n",
      "561/561 [==============================] - 0s 623us/step - loss: 1394649643.0463 - val_loss: 1246340224.0000\n",
      "Epoch 167/250\n",
      "561/561 [==============================] - 0s 629us/step - loss: 1386652421.2384 - val_loss: 1238462464.0000\n",
      "Epoch 168/250\n",
      "561/561 [==============================] - 0s 621us/step - loss: 1376897367.6868 - val_loss: 1230609664.0000\n",
      "Epoch 169/250\n",
      "561/561 [==============================] - 0s 634us/step - loss: 1369424397.4377 - val_loss: 1222781696.0000\n",
      "Epoch 170/250\n",
      "561/561 [==============================] - 0s 623us/step - loss: 1361396579.3025 - val_loss: 1214978176.0000\n",
      "Epoch 171/250\n",
      "561/561 [==============================] - 0s 624us/step - loss: 1353350197.2954 - val_loss: 1207200768.0000\n",
      "Epoch 172/250\n",
      "561/561 [==============================] - 0s 629us/step - loss: 1344010251.1601 - val_loss: 1199447040.0000\n",
      "Epoch 173/250\n",
      "561/561 [==============================] - 0s 623us/step - loss: 1336346250.0214 - val_loss: 1191719424.0000\n",
      "Epoch 174/250\n",
      "561/561 [==============================] - 0s 624us/step - loss: 1328277355.5018 - val_loss: 1184015744.0000\n",
      "Epoch 175/250\n",
      "561/561 [==============================] - 0s 628us/step - loss: 1320980443.5587 - val_loss: 1176337920.0000\n",
      "Epoch 176/250\n",
      "561/561 [==============================] - 0s 623us/step - loss: 1311979144.8826 - val_loss: 1168684928.0000\n",
      "Epoch 177/250\n",
      "561/561 [==============================] - 0s 625us/step - loss: 1303677102.4626 - val_loss: 1161056512.0000\n",
      "Epoch 178/250\n",
      "561/561 [==============================] - 0s 626us/step - loss: 1296029021.3808 - val_loss: 1153453696.0000\n",
      "Epoch 179/250\n",
      "561/561 [==============================] - 0s 621us/step - loss: 1288677456.8541 - val_loss: 1145875328.0000\n",
      "Epoch 180/250\n",
      "561/561 [==============================] - 0s 632us/step - loss: 1279478881.2527 - val_loss: 1138321792.0000\n",
      "Epoch 181/250\n",
      "561/561 [==============================] - 0s 629us/step - loss: 1271588296.8826 - val_loss: 1130793728.0000\n",
      "Epoch 182/250\n",
      "561/561 [==============================] - 0s 626us/step - loss: 1264436915.2456 - val_loss: 1123290624.0000\n",
      "Epoch 183/250\n",
      "561/561 [==============================] - 0s 624us/step - loss: 1256061672.9964 - val_loss: 1115812352.0000\n",
      "Epoch 184/250\n",
      "561/561 [==============================] - 0s 627us/step - loss: 1247818251.3879 - val_loss: 1108358912.0000\n",
      "Epoch 185/250\n",
      "561/561 [==============================] - 0s 623us/step - loss: 1240607008.5694 - val_loss: 1100930816.0000\n",
      "Epoch 186/250\n",
      "561/561 [==============================] - 0s 628us/step - loss: 1232781464.8256 - val_loss: 1093527296.0000\n",
      "Epoch 187/250\n",
      "561/561 [==============================] - 0s 625us/step - loss: 1224050518.0925 - val_loss: 1086149376.0000\n",
      "Epoch 188/250\n",
      "561/561 [==============================] - 0s 625us/step - loss: 1217015237.9217 - val_loss: 1078796032.0000\n",
      "Epoch 189/250\n",
      "561/561 [==============================] - 0s 628us/step - loss: 1208543736.7117 - val_loss: 1071466944.0000\n",
      "Epoch 190/250\n",
      "561/561 [==============================] - 0s 623us/step - loss: 1200951801.6228 - val_loss: 1064164096.0000\n",
      "Epoch 191/250\n",
      "561/561 [==============================] - 0s 627us/step - loss: 1193717150.2918 - val_loss: 1056885440.0000\n",
      "Epoch 192/250\n",
      "561/561 [==============================] - 0s 629us/step - loss: 1185563839.5445 - val_loss: 1049631616.0000\n",
      "Epoch 193/250\n",
      "561/561 [==============================] - 0s 625us/step - loss: 1177834773.4093 - val_loss: 1042403392.0000\n",
      "Epoch 194/250\n",
      "561/561 [==============================] - 0s 618us/step - loss: 1170517372.8114 - val_loss: 1035200000.0000\n",
      "Epoch 195/250\n",
      "561/561 [==============================] - 0s 624us/step - loss: 1163279598.0071 - val_loss: 1028021568.0000\n",
      "Epoch 196/250\n",
      "561/561 [==============================] - 0s 621us/step - loss: 1154832355.0747 - val_loss: 1020867968.0000\n",
      "Epoch 197/250\n",
      "561/561 [==============================] - 0s 622us/step - loss: 1148361600.6833 - val_loss: 1013738944.0000\n",
      "Epoch 198/250\n",
      "561/561 [==============================] - 0s 627us/step - loss: 1139674155.2740 - val_loss: 1006635712.0000\n",
      "Epoch 199/250\n",
      "561/561 [==============================] - 0s 625us/step - loss: 1132384904.6548 - val_loss: 999556992.0000\n",
      "Epoch 200/250\n",
      "561/561 [==============================] - 0s 623us/step - loss: 1124781563.4448 - val_loss: 992503680.0000\n",
      "Epoch 201/250\n",
      "561/561 [==============================] - 0s 622us/step - loss: 1117044324.2135 - val_loss: 985474944.0000\n",
      "Epoch 202/250\n",
      "561/561 [==============================] - 0s 623us/step - loss: 1110571341.6655 - val_loss: 978471168.0000\n",
      "Epoch 203/250\n",
      "561/561 [==============================] - 0s 629us/step - loss: 1103157326.8043 - val_loss: 971492928.0000\n",
      "Epoch 204/250\n",
      "561/561 [==============================] - 0s 633us/step - loss: 1095532867.4164 - val_loss: 964538816.0000\n",
      "Epoch 205/250\n",
      "561/561 [==============================] - 0s 630us/step - loss: 1087935738.7616 - val_loss: 957610240.0000\n",
      "Epoch 206/250\n",
      "561/561 [==============================] - 0s 632us/step - loss: 1080583766.3203 - val_loss: 950706304.0000\n",
      "Epoch 207/250\n",
      "561/561 [==============================] - 0s 628us/step - loss: 1073357935.4875 - val_loss: 943827648.0000\n",
      "Epoch 208/250\n",
      "561/561 [==============================] - 0s 624us/step - loss: 1066066480.2847 - val_loss: 936974336.0000\n",
      "Epoch 209/250\n",
      "561/561 [==============================] - 0s 634us/step - loss: 1058571799.0036 - val_loss: 930145600.0000\n",
      "Epoch 210/250\n",
      "561/561 [==============================] - 0s 620us/step - loss: 1051674597.3523 - val_loss: 923342080.0000\n",
      "Epoch 211/250\n",
      "561/561 [==============================] - 0s 623us/step - loss: 1044002599.2883 - val_loss: 916563328.0000\n",
      "Epoch 212/250\n",
      "561/561 [==============================] - 0s 625us/step - loss: 1036909652.4982 - val_loss: 909809728.0000\n",
      "Epoch 213/250\n",
      "561/561 [==============================] - 0s 620us/step - loss: 1029052445.0391 - val_loss: 903080576.0000\n",
      "Epoch 214/250\n",
      "561/561 [==============================] - 0s 626us/step - loss: 1022927420.9253 - val_loss: 896376896.0000\n",
      "Epoch 215/250\n",
      "561/561 [==============================] - 0s 632us/step - loss: 1015105377.3665 - val_loss: 889697920.0000\n",
      "Epoch 216/250\n",
      "561/561 [==============================] - 0s 624us/step - loss: 1008579016.6548 - val_loss: 883043904.0000\n",
      "Epoch 217/250\n",
      "561/561 [==============================] - 0s 622us/step - loss: 1001367395.9858 - val_loss: 876415296.0000\n",
      "Epoch 218/250\n",
      "561/561 [==============================] - 0s 622us/step - loss: 994456358.0356 - val_loss: 869811136.0000\n",
      "Epoch 219/250\n",
      "561/561 [==============================] - 0s 624us/step - loss: 986819138.2776 - val_loss: 863232064.0000\n",
      "Epoch 220/250\n",
      "561/561 [==============================] - 0s 625us/step - loss: 980409310.1779 - val_loss: 856677824.0000\n",
      "Epoch 221/250\n",
      "561/561 [==============================] - 0s 624us/step - loss: 973614122.0214 - val_loss: 850149312.0000\n",
      "Epoch 222/250\n",
      "561/561 [==============================] - 0s 626us/step - loss: 966494370.1637 - val_loss: 843644992.0000\n",
      "Epoch 223/250\n",
      "561/561 [==============================] - 0s 627us/step - loss: 958935020.4128 - val_loss: 837166464.0000\n",
      "Epoch 224/250\n",
      "561/561 [==============================] - 0s 633us/step - loss: 952578707.0178 - val_loss: 830712640.0000\n",
      "Epoch 225/250\n",
      "561/561 [==============================] - 0s 628us/step - loss: 945528657.8790 - val_loss: 824283648.0000\n",
      "Epoch 226/250\n",
      "561/561 [==============================] - 0s 631us/step - loss: 939256389.5801 - val_loss: 817880384.0000\n",
      "Epoch 227/250\n",
      "561/561 [==============================] - 0s 620us/step - loss: 932554953.9075 - val_loss: 811501440.0000\n",
      "Epoch 228/250\n",
      "561/561 [==============================] - 0s 622us/step - loss: 925548150.4342 - val_loss: 805147968.0000\n",
      "Epoch 229/250\n",
      "561/561 [==============================] - 0s 627us/step - loss: 918037854.8612 - val_loss: 798818624.0000\n",
      "Epoch 230/250\n",
      "561/561 [==============================] - 0s 622us/step - loss: 910970463.5445 - val_loss: 792514432.0000\n",
      "Epoch 231/250\n",
      "561/561 [==============================] - 0s 630us/step - loss: 905803088.1708 - val_loss: 786235264.0000\n",
      "Epoch 232/250\n",
      "561/561 [==============================] - 0s 626us/step - loss: 898038596.2135 - val_loss: 779981312.0000\n",
      "Epoch 233/250\n",
      "561/561 [==============================] - 0s 626us/step - loss: 891649440.3416 - val_loss: 773752512.0000\n",
      "Epoch 234/250\n",
      "561/561 [==============================] - 0s 624us/step - loss: 884943329.1388 - val_loss: 767549568.0000\n",
      "Epoch 235/250\n",
      "561/561 [==============================] - 0s 628us/step - loss: 878225599.4306 - val_loss: 761370432.0000\n",
      "Epoch 236/250\n",
      "561/561 [==============================] - 0s 624us/step - loss: 871251205.9217 - val_loss: 755216576.0000\n",
      "Epoch 237/250\n",
      "561/561 [==============================] - 0s 625us/step - loss: 865002376.9964 - val_loss: 749089536.0000\n",
      "Epoch 238/250\n",
      "561/561 [==============================] - 0s 625us/step - loss: 858690332.9253 - val_loss: 742985024.0000\n",
      "Epoch 239/250\n",
      "561/561 [==============================] - 0s 625us/step - loss: 851373395.7011 - val_loss: 736907136.0000\n",
      "Epoch 240/250\n",
      "561/561 [==============================] - 0s 623us/step - loss: 845531936.6833 - val_loss: 730854016.0000\n",
      "Epoch 241/250\n",
      "561/561 [==============================] - 0s 628us/step - loss: 838746998.5480 - val_loss: 724825920.0000\n",
      "Epoch 242/250\n",
      "561/561 [==============================] - 0s 633us/step - loss: 831982277.3523 - val_loss: 718821952.0000\n",
      "Epoch 243/250\n",
      "561/561 [==============================] - 0s 626us/step - loss: 826240890.3060 - val_loss: 712842560.0000\n",
      "Epoch 244/250\n",
      "561/561 [==============================] - 0s 626us/step - loss: 819789150.1779 - val_loss: 706889600.0000\n",
      "Epoch 245/250\n",
      "561/561 [==============================] - 0s 624us/step - loss: 813185858.9609 - val_loss: 700960896.0000\n",
      "Epoch 246/250\n",
      "561/561 [==============================] - 0s 630us/step - loss: 806691544.1423 - val_loss: 695057472.0000\n",
      "Epoch 247/250\n",
      "561/561 [==============================] - 0s 618us/step - loss: 800639093.6370 - val_loss: 689179392.0000\n",
      "Epoch 248/250\n",
      "561/561 [==============================] - 0s 633us/step - loss: 793949132.2989 - val_loss: 683326656.0000\n",
      "Epoch 249/250\n",
      "561/561 [==============================] - 0s 626us/step - loss: 787825181.8363 - val_loss: 677497792.0000\n",
      "Epoch 250/250\n",
      "561/561 [==============================] - 0s 622us/step - loss: 781244509.9502 - val_loss: 671694464.0000\n",
      "CPU times: user 2min 49s, sys: 21.3 s, total: 3min 10s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(\n",
    "    X_train['midpoint'], BTC_train_y,\n",
    "    epochs=250,\n",
    "    batch_size = 100,\n",
    "    verbose=1,\n",
    "    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-25c596f1309b>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['RV'][(i+freq)] = sum(df['midpoint'][i:(freq+i)]**2)\n"
     ]
    }
   ],
   "source": [
    "df_with_RV = RealizedVolatility(BTC_df, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f70b2a83c70>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_with_RV[\"RV\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-e83118769f35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'midpoint'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pls' is not defined"
     ]
    }
   ],
   "source": [
    "pls.plot('midpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = BTC_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"test\"] = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        123\n",
       "1        123\n",
       "2        123\n",
       "3        123\n",
       "4        123\n",
       "        ... \n",
       "87575    123\n",
       "87576    123\n",
       "87577    123\n",
       "87578    123\n",
       "87579    123\n",
       "Name: test, Length: 87580, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'test2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'test2'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-45b1ed401cbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m123\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'test2'"
     ]
    }
   ],
   "source": [
    "test_df[\"test2\"][1] = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(\n",
    "    input_dim=layers[0],\n",
    "    output_dim=layers[1],\n",
    "    return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(\n",
    "    layers[2],\n",
    "    return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(\n",
    "    output_dim=layers[3]))\n",
    "model.add(Activation(\"tanh\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
